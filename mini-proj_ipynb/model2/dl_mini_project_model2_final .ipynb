{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twDv2eW6ERW_"
   },
   "outputs": [],
   "source": [
    "'''ResNet in PyTorch.\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "    \n",
    "[2] Train CIFAR10 with PyTorch  \n",
    "https://github.com/kuangliu/pytorch-cifar\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x_size: \", x.size())\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # print(\"out1_size: \", out.size())\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # print(\"out2_size: \", out.size())\n",
    "        out += self.shortcut(x)\n",
    "        # print(\"out3_size: \", out.size())\n",
    "        out = F.relu(out)\n",
    "        # print(\"out4_size: \", out.size())\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x_size: \", x.size())\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # print(\"out1_size: \", out.size())\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        # print(\"out2_size: \", out.size())\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        # print(\"out3_size: \", out.size())\n",
    "        out += self.shortcut(x)\n",
    "        # print(\"out4_size: \", out.size())\n",
    "        out = F.relu(out)\n",
    "        # print(\"out5_size: \", out.size())\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        # print(strides)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x_size: \", x.size())\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # print(\"out1_size: \", out.size())\n",
    "        out = self.layer1(out)\n",
    "        # print(\"out2_size: \", out.size())\n",
    "        out = self.layer2(out)\n",
    "        # print(\"out3_size: \", out.size())\n",
    "        out = self.layer3(out)\n",
    "        # print(\"out4_size: \", out.size())\n",
    "        out = self.layer4(out)\n",
    "        # print(\"out5_size: \", out.size())\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        # print(\"out6_size: \", out.size())\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(\"out7_size: \", out.size())\n",
    "        out = self.linear(out)\n",
    "        # print(\"out8_size: \", out.size())\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEc1dexLKWRM"
   },
   "outputs": [],
   "source": [
    "# only 3 layer\n",
    "class ResNet_3_layer(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet_3_layer, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        # self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        # print(strides)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # print(\"out1_size: \", out.size())\n",
    "        out = self.layer1(out)\n",
    "        # print(\"out2_size: \", out.size())\n",
    "        out = self.layer2(out)\n",
    "        # print(\"out3_size: \", out.size())\n",
    "        out = self.layer3(out)\n",
    "        # print(\"out4_size: \", out.size())\n",
    "        # out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        # print(\"out5_size: \", out.size())\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(\"out6_size: \", out.size())\n",
    "        out = self.linear(out)\n",
    "        # print(\"out7_size: \", out.size())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOYea9DYLQOy",
    "outputId": "6f978d80-6cec-46e4-ad9e-694716d2659d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# net = ResNet_3_layer(BasicBlock, [2, 2, 2, 2])\n",
    "# y = net(torch.randn(1, 3, 32, 32))\n",
    "# print(y.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bDWSvEpFdms"
   },
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMCfLzKTFieJ"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "  net = ResNet18()\n",
    "  y = net(torch.randn(1, 3, 32, 32))\n",
    "  print(y.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3DmY1ktGDj0"
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# model1 = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "# # model2 = ResNet34()\n",
    "# # model3 = ResNet50()\n",
    "# # model4 = ResNet101()\n",
    "# # model5 = ResNet152()\n",
    "# y = model1(torch.randn(1, 3, 32, 32))\n",
    "# print(y.size())\n",
    "# summary(model1,(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPla4sMGAVSP"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCx33GwEAm5L"
   },
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5EICfQJAp4c"
   },
   "outputs": [],
   "source": [
    "'''Some helper functions for PyTorch, including:\n",
    "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
    "    - msr_init: net parameter initialization.\n",
    "    - progress_bar: progress bar mimic xlua.progress.\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "\n",
    "# _, term_width = os.popen('stty size', 'r').read().split()\n",
    "import shutil\n",
    "_, term_width = shutil.get_terminal_size()\n",
    "term_width = int(term_width)\n",
    "\n",
    "# term_width = 80\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNGTpMnIAvM9"
   },
   "source": [
    "## load dataset and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myzukNr9Juoc"
   },
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiSCNiu8Jr21"
   },
   "outputs": [],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "parser.add_argument('--resume', '-r', action='store_true',\n",
    "                    help='resume from checkpoint')\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "args.resume = True\n",
    "\n",
    "\n",
    "# modify this if train on another platform.\n",
    "google_colab = True\n",
    "model_save_path = '/checkpoint/ckpt.pth'\n",
    "if google_colab:\n",
    "  model_save_path = \"/content/drive/MyDrive/ECE7123-deeplearning/mini-proj/checkpoint/ckpt.pth\"\n",
    "\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyxjzPCiLVpT"
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MO36UnksLafp",
    "outputId": "7a1ef1ba-af97-4dfd-d6ca-f43a7bd8c21a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vb0QqKuYLexY"
   },
   "source": [
    "## model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tp6Uepc6Lgq8",
    "outputId": "738c7b01-7e8d-43f6-bf98-67e1f751c3d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = ResNet18()\n",
    "# net = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "net = ResNet_3_layer(BasicBlock, [2, 2, 4, 0])\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "args.resume = False\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    # checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    checkpoint = torch.load(model_save_path)\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2QKjWzaLiua"
   },
   "source": [
    "## training and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Il3wtN7PLlf7"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        # torch.save(state, './checkpoint/ckpt.pth')\n",
    "        torch.save(state, model_save_path)\n",
    "        best_acc = acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeazF8cyFHqi",
    "outputId": "9f947826-d747-4a71-a4b9-fd1061eae8a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [128, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2          [128, 64, 32, 32]             128\n",
      "            Conv2d-3          [128, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4          [128, 64, 32, 32]             128\n",
      "            Conv2d-5          [128, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6          [128, 64, 32, 32]             128\n",
      "        BasicBlock-7          [128, 64, 32, 32]               0\n",
      "            Conv2d-8          [128, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9          [128, 64, 32, 32]             128\n",
      "           Conv2d-10          [128, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11          [128, 64, 32, 32]             128\n",
      "       BasicBlock-12          [128, 64, 32, 32]               0\n",
      "           Conv2d-13         [128, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14         [128, 128, 16, 16]             256\n",
      "           Conv2d-15         [128, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16         [128, 128, 16, 16]             256\n",
      "           Conv2d-17         [128, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18         [128, 128, 16, 16]             256\n",
      "       BasicBlock-19         [128, 128, 16, 16]               0\n",
      "           Conv2d-20         [128, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21         [128, 128, 16, 16]             256\n",
      "           Conv2d-22         [128, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23         [128, 128, 16, 16]             256\n",
      "       BasicBlock-24         [128, 128, 16, 16]               0\n",
      "           Conv2d-25           [128, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26           [128, 256, 8, 8]             512\n",
      "           Conv2d-27           [128, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28           [128, 256, 8, 8]             512\n",
      "           Conv2d-29           [128, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30           [128, 256, 8, 8]             512\n",
      "       BasicBlock-31           [128, 256, 8, 8]               0\n",
      "           Conv2d-32           [128, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33           [128, 256, 8, 8]             512\n",
      "           Conv2d-34           [128, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35           [128, 256, 8, 8]             512\n",
      "       BasicBlock-36           [128, 256, 8, 8]               0\n",
      "           Conv2d-37           [128, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-38           [128, 256, 8, 8]             512\n",
      "           Conv2d-39           [128, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-40           [128, 256, 8, 8]             512\n",
      "       BasicBlock-41           [128, 256, 8, 8]               0\n",
      "           Conv2d-42           [128, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-43           [128, 256, 8, 8]             512\n",
      "           Conv2d-44           [128, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-45           [128, 256, 8, 8]             512\n",
      "       BasicBlock-46           [128, 256, 8, 8]               0\n",
      "           Linear-47                  [128, 10]           2,570\n",
      "   ResNet_3_layer-48                  [128, 10]               0\n",
      "================================================================\n",
      "Total params: 5,139,018\n",
      "Trainable params: 5,139,018\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 1504.02\n",
      "Params size (MB): 19.60\n",
      "Estimated Total Size (MB): 1525.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(start_epoch)\n",
    "print(best_acc)\n",
    "from torchsummary import summary\n",
    "summary(net,(3,32,32),trainloader.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm1u05-iLoHw"
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDfk4THvAZO8",
    "outputId": "eef77195-a515-49c8-a2d3-5522ae46196c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_epoch:  0\n",
      "\n",
      "Epoch: 0\n",
      " [================================================================>]  Step: 109ms | Tot: 13s445ms | Loss: 1.869 | Acc: 32.222% (16111/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s72ms | Loss: 1.562 | Acc: 41.830% (4183/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      " [================================================================>]  Step: 30ms | Tot: 13s918ms | Loss: 1.358 | Acc: 50.462% (25231/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 2s103ms | Loss: 1.308 | Acc: 53.520% (5352/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      " [================================================================>]  Step: 35ms | Tot: 13s314ms | Loss: 1.065 | Acc: 61.940% (30970/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s868ms | Loss: 1.028 | Acc: 63.930% (6393/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      " [================================================================>]  Step: 34ms | Tot: 13s770ms | Loss: 0.860 | Acc: 69.572% (34786/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s185ms | Loss: 0.850 | Acc: 71.110% (7111/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      " [================================================================>]  Step: 35ms | Tot: 13s781ms | Loss: 0.710 | Acc: 75.210% (37605/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s102ms | Loss: 0.916 | Acc: 70.020% (7002/10000) 100/100 \n",
      "\n",
      "Epoch: 5\n",
      " [================================================================>]  Step: 30ms | Tot: 13s151ms | Loss: 0.619 | Acc: 78.694% (39347/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s36ms | Loss: 1.045 | Acc: 67.730% (6773/10000) 100/100 \n",
      "\n",
      "Epoch: 6\n",
      " [================================================================>]  Step: 28ms | Tot: 13s317ms | Loss: 0.562 | Acc: 80.714% (40357/50000) 391/391 \n",
      " [================================================================>]  Step: 25ms | Tot: 1s967ms | Loss: 0.590 | Acc: 80.010% (8001/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      " [================================================================>]  Step: 33ms | Tot: 13s467ms | Loss: 0.517 | Acc: 82.328% (41164/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s90ms | Loss: 0.596 | Acc: 80.470% (8047/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      " [================================================================>]  Step: 28ms | Tot: 13s994ms | Loss: 0.483 | Acc: 83.526% (41763/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s200ms | Loss: 0.812 | Acc: 74.090% (7409/10000) 100/100 \n",
      "\n",
      "Epoch: 9\n",
      " [================================================================>]  Step: 28ms | Tot: 13s663ms | Loss: 0.464 | Acc: 84.204% (42102/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 1s949ms | Loss: 0.586 | Acc: 81.190% (8119/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      " [================================================================>]  Step: 25ms | Tot: 13s704ms | Loss: 0.444 | Acc: 84.738% (42369/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s70ms | Loss: 0.626 | Acc: 78.440% (7844/10000) 100/100 \n",
      "\n",
      "Epoch: 11\n",
      " [================================================================>]  Step: 33ms | Tot: 13s284ms | Loss: 0.436 | Acc: 85.154% (42577/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s103ms | Loss: 0.450 | Acc: 84.570% (8457/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 12\n",
      " [================================================================>]  Step: 29ms | Tot: 14s16ms | Loss: 0.408 | Acc: 85.848% (42924/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s236ms | Loss: 0.560 | Acc: 82.260% (8226/10000) 100/100 \n",
      "\n",
      "Epoch: 13\n",
      " [================================================================>]  Step: 23ms | Tot: 13s650ms | Loss: 0.404 | Acc: 86.084% (43042/50000) 391/391 \n",
      " [================================================================>]  Step: 24ms | Tot: 1s965ms | Loss: 0.582 | Acc: 80.940% (8094/10000) 100/100 \n",
      "\n",
      "Epoch: 14\n",
      " [================================================================>]  Step: 28ms | Tot: 13s740ms | Loss: 0.393 | Acc: 86.378% (43189/50000) 391/391 \n",
      " [================================================================>]  Step: 11ms | Tot: 1s941ms | Loss: 0.481 | Acc: 83.390% (8339/10000) 100/100 \n",
      "\n",
      "Epoch: 15\n",
      " [================================================================>]  Step: 28ms | Tot: 13s242ms | Loss: 0.384 | Acc: 86.776% (43388/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s54ms | Loss: 0.570 | Acc: 81.210% (8121/10000) 100/100 \n",
      "\n",
      "Epoch: 16\n",
      " [================================================================>]  Step: 28ms | Tot: 13s688ms | Loss: 0.375 | Acc: 86.988% (43494/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s208ms | Loss: 0.552 | Acc: 81.840% (8184/10000) 100/100 \n",
      "\n",
      "Epoch: 17\n",
      " [================================================================>]  Step: 30ms | Tot: 13s715ms | Loss: 0.370 | Acc: 87.200% (43600/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s81ms | Loss: 0.726 | Acc: 78.220% (7822/10000) 100/100 \n",
      "\n",
      "Epoch: 18\n",
      " [================================================================>]  Step: 30ms | Tot: 13s848ms | Loss: 0.364 | Acc: 87.422% (43711/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s207ms | Loss: 0.472 | Acc: 84.670% (8467/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      " [================================================================>]  Step: 25ms | Tot: 13s311ms | Loss: 0.356 | Acc: 87.712% (43856/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s54ms | Loss: 0.696 | Acc: 77.410% (7741/10000) 100/100 \n",
      "\n",
      "Epoch: 20\n",
      " [================================================================>]  Step: 26ms | Tot: 13s178ms | Loss: 0.352 | Acc: 87.852% (43926/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s53ms | Loss: 0.465 | Acc: 84.190% (8419/10000) 100/100 \n",
      "\n",
      "Epoch: 21\n",
      " [================================================================>]  Step: 38ms | Tot: 13s825ms | Loss: 0.342 | Acc: 88.128% (44064/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s934ms | Loss: 0.493 | Acc: 83.010% (8301/10000) 100/100 \n",
      "\n",
      "Epoch: 22\n",
      " [================================================================>]  Step: 24ms | Tot: 13s572ms | Loss: 0.341 | Acc: 88.312% (44156/50000) 391/391 \n",
      " [================================================================>]  Step: 27ms | Tot: 2s136ms | Loss: 0.502 | Acc: 82.880% (8288/10000) 100/100 \n",
      "\n",
      "Epoch: 23\n",
      " [================================================================>]  Step: 30ms | Tot: 13s657ms | Loss: 0.337 | Acc: 88.422% (44211/50000) 391/391 \n",
      " [================================================================>]  Step: 10ms | Tot: 2s46ms | Loss: 0.707 | Acc: 78.340% (7834/10000) 100/100 \n",
      "\n",
      "Epoch: 24\n",
      " [================================================================>]  Step: 26ms | Tot: 13s89ms | Loss: 0.331 | Acc: 88.668% (44334/50000) 391/391 \n",
      " [================================================================>]  Step: 25ms | Tot: 1s994ms | Loss: 0.503 | Acc: 83.560% (8356/10000) 100/100 \n",
      "\n",
      "Epoch: 25\n",
      " [================================================================>]  Step: 28ms | Tot: 13s436ms | Loss: 0.324 | Acc: 88.852% (44426/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s51ms | Loss: 0.500 | Acc: 84.120% (8412/10000) 100/100 \n",
      "\n",
      "Epoch: 26\n",
      " [================================================================>]  Step: 31ms | Tot: 13s459ms | Loss: 0.327 | Acc: 88.728% (44364/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s105ms | Loss: 0.639 | Acc: 78.920% (7892/10000) 100/100 \n",
      "\n",
      "Epoch: 27\n",
      " [================================================================>]  Step: 27ms | Tot: 13s505ms | Loss: 0.318 | Acc: 89.098% (44549/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 1s988ms | Loss: 0.662 | Acc: 79.160% (7916/10000) 100/100 \n",
      "\n",
      "Epoch: 28\n",
      " [================================================================>]  Step: 26ms | Tot: 13s87ms | Loss: 0.312 | Acc: 89.288% (44644/50000) 391/391 \n",
      " [================================================================>]  Step: 13ms | Tot: 2s29ms | Loss: 0.548 | Acc: 81.750% (8175/10000) 100/100 \n",
      "\n",
      "Epoch: 29\n",
      " [================================================================>]  Step: 28ms | Tot: 13s999ms | Loss: 0.309 | Acc: 89.350% (44675/50000) 391/391 \n",
      " [================================================================>]  Step: 24ms | Tot: 2s4ms | Loss: 0.445 | Acc: 85.590% (8559/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 30\n",
      " [================================================================>]  Step: 27ms | Tot: 13s674ms | Loss: 0.316 | Acc: 89.202% (44601/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 1s992ms | Loss: 0.581 | Acc: 81.980% (8198/10000) 100/100 \n",
      "\n",
      "Epoch: 31\n",
      " [================================================================>]  Step: 32ms | Tot: 13s921ms | Loss: 0.305 | Acc: 89.586% (44793/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 1s898ms | Loss: 0.432 | Acc: 85.490% (8549/10000) 100/100 \n",
      "\n",
      "Epoch: 32\n",
      " [================================================================>]  Step: 40ms | Tot: 13s413ms | Loss: 0.305 | Acc: 89.524% (44762/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 2s172ms | Loss: 0.680 | Acc: 79.410% (7941/10000) 100/100 \n",
      "\n",
      "Epoch: 33\n",
      " [================================================================>]  Step: 42ms | Tot: 13s532ms | Loss: 0.306 | Acc: 89.538% (44769/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 1s988ms | Loss: 0.434 | Acc: 85.650% (8565/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 34\n",
      " [================================================================>]  Step: 27ms | Tot: 13s626ms | Loss: 0.303 | Acc: 89.408% (44704/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s148ms | Loss: 0.745 | Acc: 77.220% (7722/10000) 100/100 \n",
      "\n",
      "Epoch: 35\n",
      " [================================================================>]  Step: 33ms | Tot: 13s629ms | Loss: 0.302 | Acc: 89.676% (44838/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s161ms | Loss: 0.554 | Acc: 83.030% (8303/10000) 100/100 \n",
      "\n",
      "Epoch: 36\n",
      " [================================================================>]  Step: 28ms | Tot: 13s410ms | Loss: 0.296 | Acc: 89.952% (44976/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s941ms | Loss: 0.493 | Acc: 83.840% (8384/10000) 100/100 \n",
      "\n",
      "Epoch: 37\n",
      " [================================================================>]  Step: 31ms | Tot: 13s482ms | Loss: 0.292 | Acc: 89.998% (44999/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s80ms | Loss: 0.464 | Acc: 84.280% (8428/10000) 100/100 \n",
      "\n",
      "Epoch: 38\n",
      " [================================================================>]  Step: 29ms | Tot: 13s601ms | Loss: 0.293 | Acc: 89.932% (44966/50000) 391/391 \n",
      " [================================================================>]  Step: 9ms | Tot: 2s44ms | Loss: 0.566 | Acc: 81.760% (8176/10000) 100/100 \n",
      "\n",
      "Epoch: 39\n",
      " [================================================================>]  Step: 29ms | Tot: 13s767ms | Loss: 0.293 | Acc: 89.934% (44967/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 1s981ms | Loss: 0.478 | Acc: 84.760% (8476/10000) 100/100 \n",
      "\n",
      "Epoch: 40\n",
      " [================================================================>]  Step: 35ms | Tot: 13s205ms | Loss: 0.290 | Acc: 90.124% (45062/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 1s973ms | Loss: 0.580 | Acc: 82.030% (8203/10000) 100/100 \n",
      "\n",
      "Epoch: 41\n",
      " [================================================================>]  Step: 28ms | Tot: 13s422ms | Loss: 0.290 | Acc: 90.102% (45051/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s124ms | Loss: 0.423 | Acc: 85.550% (8555/10000) 100/100 \n",
      "\n",
      "Epoch: 42\n",
      " [================================================================>]  Step: 27ms | Tot: 13s661ms | Loss: 0.281 | Acc: 90.430% (45215/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s158ms | Loss: 0.500 | Acc: 83.360% (8336/10000) 100/100 \n",
      "\n",
      "Epoch: 43\n",
      " [================================================================>]  Step: 22ms | Tot: 13s805ms | Loss: 0.281 | Acc: 90.428% (45214/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s165ms | Loss: 0.533 | Acc: 83.200% (8320/10000) 100/100 \n",
      "\n",
      "Epoch: 44\n",
      " [================================================================>]  Step: 28ms | Tot: 13s652ms | Loss: 0.281 | Acc: 90.382% (45191/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 1s997ms | Loss: 0.686 | Acc: 80.370% (8037/10000) 100/100 \n",
      "\n",
      "Epoch: 45\n",
      " [================================================================>]  Step: 20ms | Tot: 13s641ms | Loss: 0.278 | Acc: 90.460% (45230/50000) 391/391 \n",
      " [================================================================>]  Step: 11ms | Tot: 1s975ms | Loss: 0.439 | Acc: 85.630% (8563/10000) 100/100 \n",
      "\n",
      "Epoch: 46\n",
      " [================================================================>]  Step: 30ms | Tot: 13s333ms | Loss: 0.281 | Acc: 90.306% (45153/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s87ms | Loss: 0.474 | Acc: 85.340% (8534/10000) 100/100 \n",
      "\n",
      "Epoch: 47\n",
      " [================================================================>]  Step: 29ms | Tot: 13s653ms | Loss: 0.273 | Acc: 90.600% (45300/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 2s2ms | Loss: 0.421 | Acc: 86.350% (8635/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 48\n",
      " [================================================================>]  Step: 26ms | Tot: 13s268ms | Loss: 0.275 | Acc: 90.634% (45317/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 1s951ms | Loss: 0.470 | Acc: 84.430% (8443/10000) 100/100 \n",
      "\n",
      "Epoch: 49\n",
      " [================================================================>]  Step: 29ms | Tot: 13s107ms | Loss: 0.269 | Acc: 90.756% (45378/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s10ms | Loss: 0.493 | Acc: 83.500% (8350/10000) 100/100 \n",
      "\n",
      "Epoch: 50\n",
      " [================================================================>]  Step: 29ms | Tot: 13s628ms | Loss: 0.268 | Acc: 90.738% (45369/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 1s949ms | Loss: 0.631 | Acc: 80.910% (8091/10000) 100/100 \n",
      "\n",
      "Epoch: 51\n",
      " [================================================================>]  Step: 21ms | Tot: 13s260ms | Loss: 0.267 | Acc: 90.926% (45463/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s | Loss: 0.396 | Acc: 86.920% (8692/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 52\n",
      " [================================================================>]  Step: 29ms | Tot: 13s133ms | Loss: 0.263 | Acc: 90.952% (45476/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s884ms | Loss: 0.359 | Acc: 87.940% (8794/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 53\n",
      " [================================================================>]  Step: 31ms | Tot: 13s137ms | Loss: 0.259 | Acc: 91.138% (45569/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s964ms | Loss: 0.482 | Acc: 84.160% (8416/10000) 100/100 \n",
      "\n",
      "Epoch: 54\n",
      " [================================================================>]  Step: 28ms | Tot: 13s282ms | Loss: 0.269 | Acc: 90.748% (45374/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 1s947ms | Loss: 0.383 | Acc: 87.180% (8718/10000) 100/100 \n",
      "\n",
      "Epoch: 55\n",
      " [================================================================>]  Step: 25ms | Tot: 13s250ms | Loss: 0.261 | Acc: 91.152% (45576/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s978ms | Loss: 0.554 | Acc: 82.690% (8269/10000) 100/100 \n",
      "\n",
      "Epoch: 56\n",
      " [================================================================>]  Step: 26ms | Tot: 13s70ms | Loss: 0.261 | Acc: 90.928% (45464/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 2s2ms | Loss: 0.482 | Acc: 84.190% (8419/10000) 100/100 \n",
      "\n",
      "Epoch: 57\n",
      " [================================================================>]  Step: 26ms | Tot: 13s245ms | Loss: 0.258 | Acc: 91.070% (45535/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 1s903ms | Loss: 0.339 | Acc: 88.770% (8877/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 58\n",
      " [================================================================>]  Step: 33ms | Tot: 13s8ms | Loss: 0.255 | Acc: 91.304% (45652/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s5ms | Loss: 0.431 | Acc: 86.250% (8625/10000) 100/100 \n",
      "\n",
      "Epoch: 59\n",
      " [================================================================>]  Step: 29ms | Tot: 13s137ms | Loss: 0.253 | Acc: 91.178% (45589/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s69ms | Loss: 0.499 | Acc: 84.200% (8420/10000) 100/100 \n",
      "\n",
      "Epoch: 60\n",
      " [================================================================>]  Step: 38ms | Tot: 13s220ms | Loss: 0.250 | Acc: 91.404% (45702/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 2s85ms | Loss: 0.372 | Acc: 87.890% (8789/10000) 100/100 \n",
      "\n",
      "Epoch: 61\n",
      " [================================================================>]  Step: 23ms | Tot: 13s138ms | Loss: 0.249 | Acc: 91.596% (45798/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s113ms | Loss: 0.388 | Acc: 87.600% (8760/10000) 100/100 \n",
      "\n",
      "Epoch: 62\n",
      " [================================================================>]  Step: 26ms | Tot: 13s306ms | Loss: 0.247 | Acc: 91.484% (45742/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s44ms | Loss: 0.379 | Acc: 87.770% (8777/10000) 100/100 \n",
      "\n",
      "Epoch: 63\n",
      " [================================================================>]  Step: 28ms | Tot: 12s982ms | Loss: 0.242 | Acc: 91.798% (45899/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 1s891ms | Loss: 0.418 | Acc: 86.180% (8618/10000) 100/100 \n",
      "\n",
      "Epoch: 64\n",
      " [================================================================>]  Step: 29ms | Tot: 13s299ms | Loss: 0.240 | Acc: 91.846% (45923/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 1s945ms | Loss: 0.422 | Acc: 86.270% (8627/10000) 100/100 \n",
      "\n",
      "Epoch: 65\n",
      " [================================================================>]  Step: 31ms | Tot: 13s211ms | Loss: 0.236 | Acc: 91.982% (45991/50000) 391/391 \n",
      " [================================================================>]  Step: 22ms | Tot: 2s113ms | Loss: 0.437 | Acc: 86.400% (8640/10000) 100/100 \n",
      "\n",
      "Epoch: 66\n",
      " [================================================================>]  Step: 29ms | Tot: 13s318ms | Loss: 0.246 | Acc: 91.490% (45745/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 1s991ms | Loss: 0.388 | Acc: 87.230% (8723/10000) 100/100 \n",
      "\n",
      "Epoch: 67\n",
      " [================================================================>]  Step: 31ms | Tot: 13s870ms | Loss: 0.237 | Acc: 91.872% (45936/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s108ms | Loss: 0.401 | Acc: 86.770% (8677/10000) 100/100 \n",
      "\n",
      "Epoch: 68\n",
      " [================================================================>]  Step: 32ms | Tot: 13s169ms | Loss: 0.234 | Acc: 91.998% (45999/50000) 391/391 \n",
      " [================================================================>]  Step: 24ms | Tot: 1s951ms | Loss: 0.400 | Acc: 87.290% (8729/10000) 100/100 \n",
      "\n",
      "Epoch: 69\n",
      " [================================================================>]  Step: 25ms | Tot: 13s320ms | Loss: 0.229 | Acc: 92.104% (46052/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s124ms | Loss: 0.402 | Acc: 87.100% (8710/10000) 100/100 \n",
      "\n",
      "Epoch: 70\n",
      " [================================================================>]  Step: 30ms | Tot: 13s749ms | Loss: 0.232 | Acc: 91.956% (45978/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s14ms | Loss: 0.359 | Acc: 88.030% (8803/10000) 100/100 \n",
      "\n",
      "Epoch: 71\n",
      " [================================================================>]  Step: 34ms | Tot: 13s277ms | Loss: 0.235 | Acc: 91.918% (45959/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 1s927ms | Loss: 0.393 | Acc: 87.300% (8730/10000) 100/100 \n",
      "\n",
      "Epoch: 72\n",
      " [================================================================>]  Step: 30ms | Tot: 13s167ms | Loss: 0.227 | Acc: 92.124% (46062/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 1s922ms | Loss: 0.418 | Acc: 86.830% (8683/10000) 100/100 \n",
      "\n",
      "Epoch: 73\n",
      " [================================================================>]  Step: 19ms | Tot: 13s211ms | Loss: 0.224 | Acc: 92.296% (46148/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s83ms | Loss: 0.442 | Acc: 85.830% (8583/10000) 100/100 \n",
      "\n",
      "Epoch: 74\n",
      " [================================================================>]  Step: 26ms | Tot: 13s997ms | Loss: 0.221 | Acc: 92.356% (46178/50000) 391/391 \n",
      " [================================================================>]  Step: 25ms | Tot: 2s271ms | Loss: 0.488 | Acc: 84.650% (8465/10000) 100/100 \n",
      "\n",
      "Epoch: 75\n",
      " [================================================================>]  Step: 28ms | Tot: 13s917ms | Loss: 0.223 | Acc: 92.242% (46121/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 1s915ms | Loss: 0.438 | Acc: 86.580% (8658/10000) 100/100 \n",
      "\n",
      "Epoch: 76\n",
      " [================================================================>]  Step: 24ms | Tot: 13s651ms | Loss: 0.217 | Acc: 92.572% (46286/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s61ms | Loss: 0.346 | Acc: 88.650% (8865/10000) 100/100 \n",
      "\n",
      "Epoch: 77\n",
      " [================================================================>]  Step: 23ms | Tot: 13s471ms | Loss: 0.218 | Acc: 92.516% (46258/50000) 391/391 \n",
      " [================================================================>]  Step: 27ms | Tot: 1s987ms | Loss: 0.441 | Acc: 86.100% (8610/10000) 100/100 \n",
      "\n",
      "Epoch: 78\n",
      " [================================================================>]  Step: 29ms | Tot: 13s706ms | Loss: 0.214 | Acc: 92.748% (46374/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s181ms | Loss: 0.402 | Acc: 87.610% (8761/10000) 100/100 \n",
      "\n",
      "Epoch: 79\n",
      " [================================================================>]  Step: 31ms | Tot: 13s604ms | Loss: 0.213 | Acc: 92.740% (46370/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s203ms | Loss: 0.443 | Acc: 85.720% (8572/10000) 100/100 \n",
      "\n",
      "Epoch: 80\n",
      " [================================================================>]  Step: 32ms | Tot: 13s591ms | Loss: 0.212 | Acc: 92.786% (46393/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 1s917ms | Loss: 0.336 | Acc: 89.260% (8926/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 81\n",
      " [================================================================>]  Step: 28ms | Tot: 13s360ms | Loss: 0.203 | Acc: 93.038% (46519/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s65ms | Loss: 0.512 | Acc: 84.460% (8446/10000) 100/100 \n",
      "\n",
      "Epoch: 82\n",
      " [================================================================>]  Step: 28ms | Tot: 13s170ms | Loss: 0.202 | Acc: 92.986% (46493/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s132ms | Loss: 0.336 | Acc: 89.140% (8914/10000) 100/100 \n",
      "\n",
      "Epoch: 83\n",
      " [================================================================>]  Step: 27ms | Tot: 13s407ms | Loss: 0.200 | Acc: 92.990% (46495/50000) 391/391 \n",
      " [================================================================>]  Step: 9ms | Tot: 2s102ms | Loss: 0.315 | Acc: 89.720% (8972/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 84\n",
      " [================================================================>]  Step: 27ms | Tot: 13s464ms | Loss: 0.202 | Acc: 93.024% (46512/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s244ms | Loss: 0.355 | Acc: 87.880% (8788/10000) 100/100 \n",
      "\n",
      "Epoch: 85\n",
      " [================================================================>]  Step: 31ms | Tot: 13s809ms | Loss: 0.201 | Acc: 93.046% (46523/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s86ms | Loss: 0.333 | Acc: 89.160% (8916/10000) 100/100 \n",
      "\n",
      "Epoch: 86\n",
      " [================================================================>]  Step: 22ms | Tot: 13s649ms | Loss: 0.194 | Acc: 93.340% (46670/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s46ms | Loss: 0.466 | Acc: 85.430% (8543/10000) 100/100 \n",
      "\n",
      "Epoch: 87\n",
      " [================================================================>]  Step: 30ms | Tot: 13s692ms | Loss: 0.195 | Acc: 93.368% (46684/50000) 391/391 \n",
      " [================================================================>]  Step: 22ms | Tot: 2s185ms | Loss: 0.344 | Acc: 88.910% (8891/10000) 100/100 \n",
      "\n",
      "Epoch: 88\n",
      " [================================================================>]  Step: 28ms | Tot: 13s620ms | Loss: 0.192 | Acc: 93.484% (46742/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s20ms | Loss: 0.460 | Acc: 86.290% (8629/10000) 100/100 \n",
      "\n",
      "Epoch: 89\n",
      " [================================================================>]  Step: 31ms | Tot: 13s380ms | Loss: 0.191 | Acc: 93.508% (46754/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 2s67ms | Loss: 0.402 | Acc: 87.210% (8721/10000) 100/100 \n",
      "\n",
      "Epoch: 90\n",
      " [================================================================>]  Step: 23ms | Tot: 13s152ms | Loss: 0.190 | Acc: 93.526% (46763/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s48ms | Loss: 0.349 | Acc: 88.720% (8872/10000) 100/100 \n",
      "\n",
      "Epoch: 91\n",
      " [================================================================>]  Step: 37ms | Tot: 13s899ms | Loss: 0.179 | Acc: 93.790% (46895/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 1s989ms | Loss: 0.399 | Acc: 87.370% (8737/10000) 100/100 \n",
      "\n",
      "Epoch: 92\n",
      " [================================================================>]  Step: 27ms | Tot: 13s648ms | Loss: 0.181 | Acc: 93.830% (46915/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s24ms | Loss: 0.567 | Acc: 83.790% (8379/10000) 100/100 \n",
      "\n",
      "Epoch: 93\n",
      " [================================================================>]  Step: 26ms | Tot: 13s555ms | Loss: 0.182 | Acc: 93.826% (46913/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s202ms | Loss: 0.329 | Acc: 89.490% (8949/10000) 100/100 \n",
      "\n",
      "Epoch: 94\n",
      " [================================================================>]  Step: 28ms | Tot: 13s404ms | Loss: 0.178 | Acc: 93.846% (46923/50000) 391/391 \n",
      " [================================================================>]  Step: 12ms | Tot: 1s960ms | Loss: 0.446 | Acc: 86.520% (8652/10000) 100/100 \n",
      "\n",
      "Epoch: 95\n",
      " [================================================================>]  Step: 26ms | Tot: 13s920ms | Loss: 0.176 | Acc: 93.874% (46937/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 2s75ms | Loss: 0.375 | Acc: 87.930% (8793/10000) 100/100 \n",
      "\n",
      "Epoch: 96\n",
      " [================================================================>]  Step: 35ms | Tot: 13s714ms | Loss: 0.171 | Acc: 94.178% (47089/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s924ms | Loss: 0.349 | Acc: 88.830% (8883/10000) 100/100 \n",
      "\n",
      "Epoch: 97\n",
      " [================================================================>]  Step: 35ms | Tot: 13s644ms | Loss: 0.169 | Acc: 94.262% (47131/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 2s27ms | Loss: 0.324 | Acc: 89.490% (8949/10000) 100/100 \n",
      "\n",
      "Epoch: 98\n",
      " [================================================================>]  Step: 30ms | Tot: 13s386ms | Loss: 0.169 | Acc: 94.242% (47121/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s40ms | Loss: 0.366 | Acc: 88.630% (8863/10000) 100/100 \n",
      "\n",
      "Epoch: 99\n",
      " [================================================================>]  Step: 32ms | Tot: 13s659ms | Loss: 0.168 | Acc: 94.266% (47133/50000) 391/391 \n",
      " [================================================================>]  Step: 12ms | Tot: 2s175ms | Loss: 0.406 | Acc: 87.060% (8706/10000) 100/100 \n",
      "\n",
      "Epoch: 100\n",
      " [================================================================>]  Step: 32ms | Tot: 13s808ms | Loss: 0.166 | Acc: 94.398% (47199/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s151ms | Loss: 0.342 | Acc: 89.270% (8927/10000) 100/100 \n",
      "\n",
      "Epoch: 101\n",
      " [================================================================>]  Step: 29ms | Tot: 13s784ms | Loss: 0.162 | Acc: 94.396% (47198/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s41ms | Loss: 0.337 | Acc: 89.310% (8931/10000) 100/100 \n",
      "\n",
      "Epoch: 102\n",
      " [================================================================>]  Step: 32ms | Tot: 13s162ms | Loss: 0.153 | Acc: 94.860% (47430/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 1s980ms | Loss: 0.344 | Acc: 89.140% (8914/10000) 100/100 \n",
      "\n",
      "Epoch: 103\n",
      " [================================================================>]  Step: 31ms | Tot: 13s585ms | Loss: 0.156 | Acc: 94.600% (47300/50000) 391/391 \n",
      " [================================================================>]  Step: 25ms | Tot: 2s130ms | Loss: 0.394 | Acc: 87.640% (8764/10000) 100/100 \n",
      "\n",
      "Epoch: 104\n",
      " [================================================================>]  Step: 29ms | Tot: 13s964ms | Loss: 0.155 | Acc: 94.706% (47353/50000) 391/391 \n",
      " [================================================================>]  Step: 26ms | Tot: 2s172ms | Loss: 0.329 | Acc: 89.290% (8929/10000) 100/100 \n",
      "\n",
      "Epoch: 105\n",
      " [================================================================>]  Step: 31ms | Tot: 13s849ms | Loss: 0.145 | Acc: 95.134% (47567/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 1s970ms | Loss: 0.306 | Acc: 90.390% (9039/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 106\n",
      " [================================================================>]  Step: 28ms | Tot: 13s384ms | Loss: 0.149 | Acc: 94.926% (47463/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 2s84ms | Loss: 0.410 | Acc: 87.540% (8754/10000) 100/100 \n",
      "\n",
      "Epoch: 107\n",
      " [================================================================>]  Step: 40ms | Tot: 13s140ms | Loss: 0.141 | Acc: 95.222% (47611/50000) 391/391 \n",
      " [================================================================>]  Step: 13ms | Tot: 2s41ms | Loss: 0.342 | Acc: 89.200% (8920/10000) 100/100 \n",
      "\n",
      "Epoch: 108\n",
      " [================================================================>]  Step: 30ms | Tot: 13s669ms | Loss: 0.140 | Acc: 95.226% (47613/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s48ms | Loss: 0.388 | Acc: 88.280% (8828/10000) 100/100 \n",
      "\n",
      "Epoch: 109\n",
      " [================================================================>]  Step: 28ms | Tot: 13s670ms | Loss: 0.139 | Acc: 95.252% (47626/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s245ms | Loss: 0.316 | Acc: 90.150% (9015/10000) 100/100 \n",
      "\n",
      "Epoch: 110\n",
      " [================================================================>]  Step: 27ms | Tot: 13s607ms | Loss: 0.136 | Acc: 95.278% (47639/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s11ms | Loss: 0.326 | Acc: 89.630% (8963/10000) 100/100 \n",
      "\n",
      "Epoch: 111\n",
      " [================================================================>]  Step: 28ms | Tot: 13s171ms | Loss: 0.134 | Acc: 95.458% (47729/50000) 391/391 \n",
      " [================================================================>]  Step: 27ms | Tot: 1s976ms | Loss: 0.301 | Acc: 90.460% (9046/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 112\n",
      " [================================================================>]  Step: 31ms | Tot: 13s516ms | Loss: 0.135 | Acc: 95.394% (47697/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s61ms | Loss: 0.425 | Acc: 87.460% (8746/10000) 100/100 \n",
      "\n",
      "Epoch: 113\n",
      " [================================================================>]  Step: 30ms | Tot: 13s737ms | Loss: 0.124 | Acc: 95.784% (47892/50000) 391/391 \n",
      " [================================================================>]  Step: 13ms | Tot: 1s994ms | Loss: 0.321 | Acc: 89.800% (8980/10000) 100/100 \n",
      "\n",
      "Epoch: 114\n",
      " [================================================================>]  Step: 31ms | Tot: 13s582ms | Loss: 0.129 | Acc: 95.536% (47768/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 1s967ms | Loss: 0.320 | Acc: 90.350% (9035/10000) 100/100 \n",
      "\n",
      "Epoch: 115\n",
      " [================================================================>]  Step: 30ms | Tot: 13s378ms | Loss: 0.120 | Acc: 95.922% (47961/50000) 391/391 \n",
      " [================================================================>]  Step: 22ms | Tot: 2s140ms | Loss: 0.317 | Acc: 90.130% (9013/10000) 100/100 \n",
      "\n",
      "Epoch: 116\n",
      " [================================================================>]  Step: 35ms | Tot: 13s138ms | Loss: 0.120 | Acc: 95.876% (47938/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s954ms | Loss: 0.304 | Acc: 90.700% (9070/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 117\n",
      " [================================================================>]  Step: 29ms | Tot: 13s274ms | Loss: 0.114 | Acc: 96.126% (48063/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s975ms | Loss: 0.294 | Acc: 90.680% (9068/10000) 100/100 \n",
      "\n",
      "Epoch: 118\n",
      " [================================================================>]  Step: 29ms | Tot: 13s74ms | Loss: 0.117 | Acc: 96.092% (48046/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s76ms | Loss: 0.299 | Acc: 90.320% (9032/10000) 100/100 \n",
      "\n",
      "Epoch: 119\n",
      " [================================================================>]  Step: 31ms | Tot: 13s640ms | Loss: 0.114 | Acc: 96.236% (48118/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 1s962ms | Loss: 0.306 | Acc: 90.530% (9053/10000) 100/100 \n",
      "\n",
      "Epoch: 120\n",
      " [================================================================>]  Step: 28ms | Tot: 13s332ms | Loss: 0.109 | Acc: 96.386% (48193/50000) 391/391 \n",
      " [================================================================>]  Step: 12ms | Tot: 1s943ms | Loss: 0.357 | Acc: 90.010% (9001/10000) 100/100 \n",
      "\n",
      "Epoch: 121\n",
      " [================================================================>]  Step: 27ms | Tot: 13s217ms | Loss: 0.110 | Acc: 96.160% (48080/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 1s930ms | Loss: 0.335 | Acc: 89.510% (8951/10000) 100/100 \n",
      "\n",
      "Epoch: 122\n",
      " [================================================================>]  Step: 23ms | Tot: 13s351ms | Loss: 0.103 | Acc: 96.618% (48309/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 1s966ms | Loss: 0.310 | Acc: 90.840% (9084/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 123\n",
      " [================================================================>]  Step: 33ms | Tot: 13s203ms | Loss: 0.107 | Acc: 96.322% (48161/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 1s937ms | Loss: 0.348 | Acc: 89.450% (8945/10000) 100/100 \n",
      "\n",
      "Epoch: 124\n",
      " [================================================================>]  Step: 25ms | Tot: 13s282ms | Loss: 0.100 | Acc: 96.662% (48331/50000) 391/391 \n",
      " [================================================================>]  Step: 24ms | Tot: 2s57ms | Loss: 0.372 | Acc: 89.110% (8911/10000) 100/100 \n",
      "\n",
      "Epoch: 125\n",
      " [================================================================>]  Step: 30ms | Tot: 13s753ms | Loss: 0.093 | Acc: 96.936% (48468/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s18ms | Loss: 0.326 | Acc: 90.110% (9011/10000) 100/100 \n",
      "\n",
      "Epoch: 126\n",
      " [================================================================>]  Step: 29ms | Tot: 13s348ms | Loss: 0.095 | Acc: 96.832% (48416/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s204ms | Loss: 0.331 | Acc: 89.690% (8969/10000) 100/100 \n",
      "\n",
      "Epoch: 127\n",
      " [================================================================>]  Step: 25ms | Tot: 13s377ms | Loss: 0.095 | Acc: 96.816% (48408/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s73ms | Loss: 0.326 | Acc: 90.350% (9035/10000) 100/100 \n",
      "\n",
      "Epoch: 128\n",
      " [================================================================>]  Step: 35ms | Tot: 13s235ms | Loss: 0.087 | Acc: 97.082% (48541/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s18ms | Loss: 0.320 | Acc: 90.770% (9077/10000) 100/100 \n",
      "\n",
      "Epoch: 129\n",
      " [================================================================>]  Step: 27ms | Tot: 13s151ms | Loss: 0.084 | Acc: 97.194% (48597/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 1s960ms | Loss: 0.248 | Acc: 92.430% (9243/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 130\n",
      " [================================================================>]  Step: 33ms | Tot: 13s335ms | Loss: 0.085 | Acc: 97.096% (48548/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 1s984ms | Loss: 0.324 | Acc: 90.050% (9005/10000) 100/100 \n",
      "\n",
      "Epoch: 131\n",
      " [================================================================>]  Step: 28ms | Tot: 13s280ms | Loss: 0.084 | Acc: 97.106% (48553/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 1s895ms | Loss: 0.302 | Acc: 91.050% (9105/10000) 100/100 \n",
      "\n",
      "Epoch: 132\n",
      " [================================================================>]  Step: 25ms | Tot: 13s432ms | Loss: 0.080 | Acc: 97.290% (48645/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 1s940ms | Loss: 0.265 | Acc: 91.970% (9197/10000) 100/100 \n",
      "\n",
      "Epoch: 133\n",
      " [================================================================>]  Step: 28ms | Tot: 14s48ms | Loss: 0.073 | Acc: 97.568% (48784/50000) 391/391 \n",
      " [================================================================>]  Step: 12ms | Tot: 2s124ms | Loss: 0.275 | Acc: 91.950% (9195/10000) 100/100 \n",
      "\n",
      "Epoch: 134\n",
      " [================================================================>]  Step: 31ms | Tot: 13s706ms | Loss: 0.068 | Acc: 97.810% (48905/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s145ms | Loss: 0.335 | Acc: 90.630% (9063/10000) 100/100 \n",
      "\n",
      "Epoch: 135\n",
      " [================================================================>]  Step: 33ms | Tot: 13s530ms | Loss: 0.072 | Acc: 97.638% (48819/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 1s987ms | Loss: 0.366 | Acc: 90.080% (9008/10000) 100/100 \n",
      "\n",
      "Epoch: 136\n",
      " [================================================================>]  Step: 31ms | Tot: 13s539ms | Loss: 0.066 | Acc: 97.862% (48931/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 1s986ms | Loss: 0.273 | Acc: 91.900% (9190/10000) 100/100 \n",
      "\n",
      "Epoch: 137\n",
      " [================================================================>]  Step: 27ms | Tot: 13s475ms | Loss: 0.063 | Acc: 97.946% (48973/50000) 391/391 \n",
      " [================================================================>]  Step: 13ms | Tot: 2s2ms | Loss: 0.259 | Acc: 92.540% (9254/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 138\n",
      " [================================================================>]  Step: 29ms | Tot: 13s408ms | Loss: 0.061 | Acc: 98.012% (49006/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s36ms | Loss: 0.293 | Acc: 91.850% (9185/10000) 100/100 \n",
      "\n",
      "Epoch: 139\n",
      " [================================================================>]  Step: 31ms | Tot: 13s594ms | Loss: 0.054 | Acc: 98.236% (49118/50000) 391/391 \n",
      " [================================================================>]  Step: 13ms | Tot: 2s14ms | Loss: 0.276 | Acc: 92.340% (9234/10000) 100/100 \n",
      "\n",
      "Epoch: 140\n",
      " [================================================================>]  Step: 30ms | Tot: 13s304ms | Loss: 0.058 | Acc: 98.126% (49063/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s48ms | Loss: 0.267 | Acc: 92.260% (9226/10000) 100/100 \n",
      "\n",
      "Epoch: 141\n",
      " [================================================================>]  Step: 28ms | Tot: 14s11ms | Loss: 0.059 | Acc: 98.078% (49039/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s40ms | Loss: 0.280 | Acc: 91.890% (9189/10000) 100/100 \n",
      "\n",
      "Epoch: 142\n",
      " [================================================================>]  Step: 39ms | Tot: 13s735ms | Loss: 0.052 | Acc: 98.334% (49167/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s65ms | Loss: 0.254 | Acc: 92.860% (9286/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 143\n",
      " [================================================================>]  Step: 27ms | Tot: 13s621ms | Loss: 0.044 | Acc: 98.642% (49321/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 1s956ms | Loss: 0.278 | Acc: 92.190% (9219/10000) 100/100 \n",
      "\n",
      "Epoch: 144\n",
      " [================================================================>]  Step: 24ms | Tot: 13s398ms | Loss: 0.045 | Acc: 98.610% (49305/50000) 391/391 \n",
      " [================================================================>]  Step: 12ms | Tot: 2s164ms | Loss: 0.270 | Acc: 92.420% (9242/10000) 100/100 \n",
      "\n",
      "Epoch: 145\n",
      " [================================================================>]  Step: 28ms | Tot: 14s134ms | Loss: 0.044 | Acc: 98.594% (49297/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s57ms | Loss: 0.256 | Acc: 92.790% (9279/10000) 100/100 \n",
      "\n",
      "Epoch: 146\n",
      " [================================================================>]  Step: 27ms | Tot: 13s905ms | Loss: 0.044 | Acc: 98.638% (49319/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s57ms | Loss: 0.278 | Acc: 92.290% (9229/10000) 100/100 \n",
      "\n",
      "Epoch: 147\n",
      " [================================================================>]  Step: 33ms | Tot: 13s484ms | Loss: 0.043 | Acc: 98.594% (49297/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 1s960ms | Loss: 0.273 | Acc: 92.580% (9258/10000) 100/100 \n",
      "\n",
      "Epoch: 148\n",
      " [================================================================>]  Step: 22ms | Tot: 13s469ms | Loss: 0.039 | Acc: 98.798% (49399/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s86ms | Loss: 0.261 | Acc: 92.630% (9263/10000) 100/100 \n",
      "\n",
      "Epoch: 149\n",
      " [================================================================>]  Step: 35ms | Tot: 13s727ms | Loss: 0.039 | Acc: 98.772% (49386/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s141ms | Loss: 0.253 | Acc: 92.660% (9266/10000) 100/100 \n",
      "\n",
      "Epoch: 150\n",
      " [================================================================>]  Step: 40ms | Tot: 13s499ms | Loss: 0.030 | Acc: 99.080% (49540/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s137ms | Loss: 0.230 | Acc: 93.430% (9343/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 151\n",
      " [================================================================>]  Step: 44ms | Tot: 13s860ms | Loss: 0.026 | Acc: 99.224% (49612/50000) 391/391 \n",
      " [================================================================>]  Step: 27ms | Tot: 2s43ms | Loss: 0.231 | Acc: 93.290% (9329/10000) 100/100 \n",
      "\n",
      "Epoch: 152\n",
      " [================================================================>]  Step: 30ms | Tot: 13s622ms | Loss: 0.027 | Acc: 99.138% (49569/50000) 391/391 \n",
      " [================================================================>]  Step: 12ms | Tot: 2s176ms | Loss: 0.238 | Acc: 93.480% (9348/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 153\n",
      " [================================================================>]  Step: 36ms | Tot: 13s343ms | Loss: 0.024 | Acc: 99.294% (49647/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s72ms | Loss: 0.239 | Acc: 93.450% (9345/10000) 100/100 \n",
      "\n",
      "Epoch: 154\n",
      " [================================================================>]  Step: 30ms | Tot: 13s341ms | Loss: 0.020 | Acc: 99.456% (49728/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s46ms | Loss: 0.236 | Acc: 93.900% (9390/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 155\n",
      " [================================================================>]  Step: 28ms | Tot: 13s573ms | Loss: 0.018 | Acc: 99.488% (49744/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 1s981ms | Loss: 0.216 | Acc: 93.990% (9399/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 156\n",
      " [================================================================>]  Step: 34ms | Tot: 13s774ms | Loss: 0.018 | Acc: 99.552% (49776/50000) 391/391 \n",
      " [================================================================>]  Step: 11ms | Tot: 1s992ms | Loss: 0.249 | Acc: 93.290% (9329/10000) 100/100 \n",
      "\n",
      "Epoch: 157\n",
      " [================================================================>]  Step: 29ms | Tot: 13s411ms | Loss: 0.017 | Acc: 99.562% (49781/50000) 391/391 \n",
      " [================================================================>]  Step: 12ms | Tot: 2s89ms | Loss: 0.230 | Acc: 93.940% (9394/10000) 100/100 \n",
      "\n",
      "Epoch: 158\n",
      " [================================================================>]  Step: 32ms | Tot: 13s423ms | Loss: 0.014 | Acc: 99.654% (49827/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s75ms | Loss: 0.221 | Acc: 94.170% (9417/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 159\n",
      " [================================================================>]  Step: 18ms | Tot: 13s590ms | Loss: 0.012 | Acc: 99.712% (49856/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s49ms | Loss: 0.226 | Acc: 93.960% (9396/10000) 100/100 \n",
      "\n",
      "Epoch: 160\n",
      " [================================================================>]  Step: 30ms | Tot: 13s567ms | Loss: 0.011 | Acc: 99.740% (49870/50000) 391/391 \n",
      " [================================================================>]  Step: 22ms | Tot: 1s981ms | Loss: 0.224 | Acc: 94.090% (9409/10000) 100/100 \n",
      "\n",
      "Epoch: 161\n",
      " [================================================================>]  Step: 32ms | Tot: 13s565ms | Loss: 0.008 | Acc: 99.838% (49919/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s37ms | Loss: 0.197 | Acc: 94.440% (9444/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 162\n",
      " [================================================================>]  Step: 27ms | Tot: 13s432ms | Loss: 0.009 | Acc: 99.806% (49903/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s7ms | Loss: 0.204 | Acc: 94.360% (9436/10000) 100/100 \n",
      "\n",
      "Epoch: 163\n",
      " [================================================================>]  Step: 24ms | Tot: 13s672ms | Loss: 0.007 | Acc: 99.896% (49948/50000) 391/391 \n",
      " [================================================================>]  Step: 22ms | Tot: 2s22ms | Loss: 0.188 | Acc: 94.920% (9492/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 164\n",
      " [================================================================>]  Step: 21ms | Tot: 13s489ms | Loss: 0.005 | Acc: 99.936% (49968/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s140ms | Loss: 0.197 | Acc: 94.730% (9473/10000) 100/100 \n",
      "\n",
      "Epoch: 165\n",
      " [================================================================>]  Step: 29ms | Tot: 13s395ms | Loss: 0.004 | Acc: 99.932% (49966/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s66ms | Loss: 0.197 | Acc: 94.860% (9486/10000) 100/100 \n",
      "\n",
      "Epoch: 166\n",
      " [================================================================>]  Step: 31ms | Tot: 13s608ms | Loss: 0.004 | Acc: 99.962% (49981/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 1s984ms | Loss: 0.211 | Acc: 94.690% (9469/10000) 100/100 \n",
      "\n",
      "Epoch: 167\n",
      " [================================================================>]  Step: 28ms | Tot: 13s408ms | Loss: 0.003 | Acc: 99.968% (49984/50000) 391/391 \n",
      " [================================================================>]  Step: 8ms | Tot: 2s16ms | Loss: 0.193 | Acc: 95.080% (9508/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 168\n",
      " [================================================================>]  Step: 27ms | Tot: 13s414ms | Loss: 0.003 | Acc: 99.968% (49984/50000) 391/391 \n",
      " [================================================================>]  Step: 24ms | Tot: 2s27ms | Loss: 0.192 | Acc: 94.900% (9490/10000) 100/100 \n",
      "\n",
      "Epoch: 169\n",
      " [================================================================>]  Step: 33ms | Tot: 13s608ms | Loss: 0.003 | Acc: 99.976% (49988/50000) 391/391 \n",
      " [================================================================>]  Step: 24ms | Tot: 2s96ms | Loss: 0.185 | Acc: 94.990% (9499/10000) 100/100 \n",
      "\n",
      "Epoch: 170\n",
      " [================================================================>]  Step: 30ms | Tot: 13s233ms | Loss: 0.003 | Acc: 99.984% (49992/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s25ms | Loss: 0.185 | Acc: 95.030% (9503/10000) 100/100 \n",
      "\n",
      "Epoch: 171\n",
      " [================================================================>]  Step: 28ms | Tot: 13s685ms | Loss: 0.003 | Acc: 99.982% (49991/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s125ms | Loss: 0.186 | Acc: 95.030% (9503/10000) 100/100 \n",
      "\n",
      "Epoch: 172\n",
      " [================================================================>]  Step: 29ms | Tot: 13s643ms | Loss: 0.002 | Acc: 99.982% (49991/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s31ms | Loss: 0.182 | Acc: 95.130% (9513/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 173\n",
      " [================================================================>]  Step: 28ms | Tot: 13s629ms | Loss: 0.002 | Acc: 99.982% (49991/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s93ms | Loss: 0.182 | Acc: 94.910% (9491/10000) 100/100 \n",
      "\n",
      "Epoch: 174\n",
      " [================================================================>]  Step: 29ms | Tot: 13s654ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
      " [================================================================>]  Step: 23ms | Tot: 2s60ms | Loss: 0.181 | Acc: 95.150% (9515/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 175\n",
      " [================================================================>]  Step: 32ms | Tot: 13s909ms | Loss: 0.002 | Acc: 99.990% (49995/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s288ms | Loss: 0.179 | Acc: 95.290% (9529/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 176\n",
      " [================================================================>]  Step: 29ms | Tot: 13s712ms | Loss: 0.002 | Acc: 99.990% (49995/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s202ms | Loss: 0.174 | Acc: 95.300% (9530/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 177\n",
      " [================================================================>]  Step: 29ms | Tot: 13s767ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s155ms | Loss: 0.174 | Acc: 95.280% (9528/10000) 100/100 \n",
      "\n",
      "Epoch: 178\n",
      " [================================================================>]  Step: 26ms | Tot: 13s756ms | Loss: 0.002 | Acc: 99.994% (49997/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s120ms | Loss: 0.173 | Acc: 95.260% (9526/10000) 100/100 \n",
      "\n",
      "Epoch: 179\n",
      " [================================================================>]  Step: 31ms | Tot: 14s28ms | Loss: 0.002 | Acc: 99.994% (49997/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s160ms | Loss: 0.172 | Acc: 95.240% (9524/10000) 100/100 \n",
      "\n",
      "Epoch: 180\n",
      " [================================================================>]  Step: 28ms | Tot: 13s677ms | Loss: 0.002 | Acc: 99.992% (49996/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s157ms | Loss: 0.174 | Acc: 95.370% (9537/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 181\n",
      " [================================================================>]  Step: 31ms | Tot: 13s833ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 2s74ms | Loss: 0.173 | Acc: 95.310% (9531/10000) 100/100 \n",
      "\n",
      "Epoch: 182\n",
      " [================================================================>]  Step: 23ms | Tot: 13s846ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 11ms | Tot: 2s56ms | Loss: 0.173 | Acc: 95.450% (9545/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 183\n",
      " [================================================================>]  Step: 41ms | Tot: 13s531ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s125ms | Loss: 0.172 | Acc: 95.400% (9540/10000) 100/100 \n",
      "\n",
      "Epoch: 184\n",
      " [================================================================>]  Step: 36ms | Tot: 13s722ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 2s21ms | Loss: 0.173 | Acc: 95.360% (9536/10000) 100/100 \n",
      "\n",
      "Epoch: 185\n",
      " [================================================================>]  Step: 19ms | Tot: 13s510ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s74ms | Loss: 0.173 | Acc: 95.370% (9537/10000) 100/100 \n",
      "\n",
      "Epoch: 186\n",
      " [================================================================>]  Step: 37ms | Tot: 13s772ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s345ms | Loss: 0.170 | Acc: 95.270% (9527/10000) 100/100 \n",
      "\n",
      "Epoch: 187\n",
      " [================================================================>]  Step: 29ms | Tot: 14s174ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s11ms | Loss: 0.171 | Acc: 95.300% (9530/10000) 100/100 \n",
      "\n",
      "Epoch: 188\n",
      " [================================================================>]  Step: 36ms | Tot: 13s680ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s199ms | Loss: 0.171 | Acc: 95.320% (9532/10000) 100/100 \n",
      "\n",
      "Epoch: 189\n",
      " [================================================================>]  Step: 32ms | Tot: 13s898ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
      " [================================================================>]  Step: 16ms | Tot: 2s99ms | Loss: 0.172 | Acc: 95.460% (9546/10000) 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 190\n",
      " [================================================================>]  Step: 22ms | Tot: 13s641ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 18ms | Tot: 2s47ms | Loss: 0.172 | Acc: 95.350% (9535/10000) 100/100 \n",
      "\n",
      "Epoch: 191\n",
      " [================================================================>]  Step: 27ms | Tot: 13s405ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 20ms | Tot: 2s19ms | Loss: 0.171 | Acc: 95.310% (9531/10000) 100/100 \n",
      "\n",
      "Epoch: 192\n",
      " [================================================================>]  Step: 28ms | Tot: 13s490ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 2s80ms | Loss: 0.170 | Acc: 95.280% (9528/10000) 100/100 \n",
      "\n",
      "Epoch: 193\n",
      " [================================================================>]  Step: 39ms | Tot: 13s517ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
      " [================================================================>]  Step: 21ms | Tot: 2s106ms | Loss: 0.175 | Acc: 95.310% (9531/10000) 100/100 \n",
      "\n",
      "Epoch: 194\n",
      " [================================================================>]  Step: 31ms | Tot: 13s508ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 2s94ms | Loss: 0.171 | Acc: 95.320% (9532/10000) 100/100 \n",
      "\n",
      "Epoch: 195\n",
      " [================================================================>]  Step: 33ms | Tot: 13s465ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 17ms | Tot: 2s202ms | Loss: 0.171 | Acc: 95.330% (9533/10000) 100/100 \n",
      "\n",
      "Epoch: 196\n",
      " [================================================================>]  Step: 39ms | Tot: 13s344ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
      " [================================================================>]  Step: 14ms | Tot: 2s19ms | Loss: 0.170 | Acc: 95.370% (9537/10000) 100/100 \n",
      "\n",
      "Epoch: 197\n",
      " [================================================================>]  Step: 31ms | Tot: 13s699ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
      " [================================================================>]  Step: 15ms | Tot: 2s43ms | Loss: 0.172 | Acc: 95.420% (9542/10000) 100/100 \n",
      "\n",
      "Epoch: 198\n",
      " [================================================================>]  Step: 23ms | Tot: 13s820ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
      " [================================================================>]  Step: 25ms | Tot: 2s94ms | Loss: 0.171 | Acc: 95.400% (9540/10000) 100/100 \n",
      "\n",
      "Epoch: 199\n",
      " [================================================================>]  Step: 37ms | Tot: 13s479ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
      " [================================================================>]  Step: 19ms | Tot: 1s946ms | Loss: 0.171 | Acc: 95.330% (9533/10000) 100/100 \n"
     ]
    }
   ],
   "source": [
    "print(\"start_epoch: \",start_epoch)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNc518fwgBB6"
   },
   "source": [
    "## resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8qrDQShgEn2"
   },
   "outputs": [],
   "source": [
    "# Load checkpoint.\n",
    "resume = False\n",
    "if resume:\n",
    "  print('==> Resuming from checkpoint..')\n",
    "  assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "  # checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "  checkpoint = torch.load(model_save_path)\n",
    "  net.load_state_dict(checkpoint['net'])\n",
    "  best_acc = checkpoint['acc']\n",
    "  start_epoch = checkpoint['epoch']\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Saqk2jBnIX-w",
    "outputId": "92faf0d3-a14e-4540-f060-ebdc231d01b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
