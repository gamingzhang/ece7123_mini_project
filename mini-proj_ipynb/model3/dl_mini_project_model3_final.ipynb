{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# model definition"
      ],
      "metadata": {
        "id": "Cp_GMIufARj9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twDv2eW6ERW_"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "[2] Train CIFAR10 with PyTorch  \n",
        "https://github.com/kuangliu/pytorch-cifar\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"x_size: \", x.size())\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        # print(\"out1_size: \", out.size())\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        # print(\"out2_size: \", out.size())\n",
        "        out += self.shortcut(x)\n",
        "        # print(\"out3_size: \", out.size())\n",
        "        out = F.relu(out)\n",
        "        # print(\"out4_size: \", out.size())\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"x_size: \", x.size())\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        # print(\"out1_size: \", out.size())\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        # print(\"out2_size: \", out.size())\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        # print(\"out3_size: \", out.size())\n",
        "        out += self.shortcut(x)\n",
        "        # print(\"out4_size: \", out.size())\n",
        "        out = F.relu(out)\n",
        "        # print(\"out5_size: \", out.size())\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        # print(strides)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"x_size: \", x.size())\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        # print(\"out1_size: \", out.size())\n",
        "        out = self.layer1(out)\n",
        "        # print(\"out2_size: \", out.size())\n",
        "        out = self.layer2(out)\n",
        "        # print(\"out3_size: \", out.size())\n",
        "        out = self.layer3(out)\n",
        "        # print(\"out4_size: \", out.size())\n",
        "        out = self.layer4(out)\n",
        "        # print(\"out5_size: \", out.size())\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        # print(\"out6_size: \", out.size())\n",
        "        out = out.view(out.size(0), -1)\n",
        "        # print(\"out7_size: \", out.size())\n",
        "        out = self.linear(out)\n",
        "        # print(\"out8_size: \", out.size())\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# only 3 layer\n",
        "class ResNet_3_layer(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet_3_layer, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 250, num_blocks[2], stride=2)\n",
        "        # self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(250*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        # print(strides)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        # print(\"out1_size: \", out.size())\n",
        "        out = self.layer1(out)\n",
        "        # print(\"out2_size: \", out.size())\n",
        "        out = self.layer2(out)\n",
        "        # print(\"out3_size: \", out.size())\n",
        "        out = self.layer3(out)\n",
        "        # print(\"out4_size: \", out.size())\n",
        "        # out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        # print(\"out5_size: \", out.size())\n",
        "        out = out.view(out.size(0), -1)\n",
        "        # print(\"out6_size: \", out.size())\n",
        "        out = self.linear(out)\n",
        "        # print(\"out7_size: \", out.size())\n",
        "        return out"
      ],
      "metadata": {
        "id": "UEc1dexLKWRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet_3_layer(BasicBlock, [2, 2, 2, 2])\n",
        "y = net(torch.randn(1, 3, 32, 32))\n",
        "print(y.size())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOYea9DYLQOy",
        "outputId": "569da38d-16d1-47ff-aa78-92912f35947f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_bDWSvEpFdms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net = ResNet18()\n",
        "  y = net(torch.randn(1, 3, 32, 32))\n",
        "  print(y.size())\n",
        "\n"
      ],
      "metadata": {
        "id": "KMCfLzKTFieJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchsummary import summary\n",
        "# model1 = ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "# # model2 = ResNet34()\n",
        "# # model3 = ResNet50()\n",
        "# # model4 = ResNet101()\n",
        "# # model5 = ResNet152()\n",
        "# y = model1(torch.randn(1, 3, 32, 32))\n",
        "# print(y.size())\n",
        "# summary(model1,(3,32,32))"
      ],
      "metadata": {
        "id": "K3DmY1ktGDj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "gPla4sMGAVSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utils.py"
      ],
      "metadata": {
        "id": "jCx33GwEAm5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Some helper functions for PyTorch, including:\n",
        "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
        "    - msr_init: net parameter initialization.\n",
        "    - progress_bar: progress bar mimic xlua.progress.\n",
        "'''\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "\n",
        "\n",
        "# _, term_width = os.popen('stty size', 'r').read().split()\n",
        "import shutil\n",
        "_, term_width = shutil.get_terminal_size()\n",
        "term_width = int(term_width)\n",
        "\n",
        "# term_width = 80\n",
        "\n",
        "TOTAL_BAR_LENGTH = 65.\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ],
      "metadata": {
        "id": "w5EICfQJAp4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load dataset and training"
      ],
      "metadata": {
        "id": "cNGTpMnIAvM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## libraries"
      ],
      "metadata": {
        "id": "myzukNr9Juoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--resume', '-r', action='store_true',\n",
        "                    help='resume from checkpoint')\n",
        "# args = parser.parse_args()\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "# modify this if train on another platform.\n",
        "google_colab = True\n",
        "model_save_path = '/checkpoint/ckpt.pth'\n",
        "if google_colab:\n",
        "  model_save_path = \"/content/drive/MyDrive/ECE7123-deeplearning/mini-proj/checkpoint/ckpt.pth\"\n",
        "\n",
        "if not os.path.isdir('checkpoint'):\n",
        "    os.mkdir('checkpoint')"
      ],
      "metadata": {
        "id": "LiSCNiu8Jr21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "NyxjzPCiLVpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO36UnksLafp",
        "outputId": "7b2d0d6d-9cc6-45a6-bc7f-f0873aacfc09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model definition"
      ],
      "metadata": {
        "id": "Vb0QqKuYLexY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "# net = ResNet18()\n",
        "# net = ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "net = ResNet_3_layer(BasicBlock, [2, 2, 4, 0])\n",
        "\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "args.resume = False\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    # checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    checkpoint = torch.load(model_save_path)\n",
        "    net.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp6Uepc6Lgq8",
        "outputId": "900d63ce-b8aa-454c-eb2e-784bc50aa4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training and testing function"
      ],
      "metadata": {
        "id": "H2QKjWzaLiua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        # torch.save(state, './checkpoint/ckpt.pth')\n",
        "        torch.save(state, model_save_path)\n",
        "        best_acc = acc\n",
        "\n"
      ],
      "metadata": {
        "id": "Il3wtN7PLlf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"best_epoch: \" ,start_epoch)\n",
        "print(\"best_acc: \",best_acc)\n",
        "from torchsummary import summary\n",
        "summary(net,(3,32,32),trainloader.batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeazF8cyFHqi",
        "outputId": "0c4ebf77-b9e4-4cff-9fc9-dee4bb05c234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_epoch:  0\n",
            "best_acc:  0\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [128, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2          [128, 64, 32, 32]             128\n",
            "            Conv2d-3          [128, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4          [128, 64, 32, 32]             128\n",
            "            Conv2d-5          [128, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6          [128, 64, 32, 32]             128\n",
            "        BasicBlock-7          [128, 64, 32, 32]               0\n",
            "            Conv2d-8          [128, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9          [128, 64, 32, 32]             128\n",
            "           Conv2d-10          [128, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11          [128, 64, 32, 32]             128\n",
            "       BasicBlock-12          [128, 64, 32, 32]               0\n",
            "           Conv2d-13         [128, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14         [128, 128, 16, 16]             256\n",
            "           Conv2d-15         [128, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16         [128, 128, 16, 16]             256\n",
            "           Conv2d-17         [128, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18         [128, 128, 16, 16]             256\n",
            "       BasicBlock-19         [128, 128, 16, 16]               0\n",
            "           Conv2d-20         [128, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21         [128, 128, 16, 16]             256\n",
            "           Conv2d-22         [128, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23         [128, 128, 16, 16]             256\n",
            "       BasicBlock-24         [128, 128, 16, 16]               0\n",
            "           Conv2d-25           [128, 250, 8, 8]         288,000\n",
            "      BatchNorm2d-26           [128, 250, 8, 8]             500\n",
            "           Conv2d-27           [128, 250, 8, 8]         562,500\n",
            "      BatchNorm2d-28           [128, 250, 8, 8]             500\n",
            "           Conv2d-29           [128, 250, 8, 8]          32,000\n",
            "      BatchNorm2d-30           [128, 250, 8, 8]             500\n",
            "       BasicBlock-31           [128, 250, 8, 8]               0\n",
            "           Conv2d-32           [128, 250, 8, 8]         562,500\n",
            "      BatchNorm2d-33           [128, 250, 8, 8]             500\n",
            "           Conv2d-34           [128, 250, 8, 8]         562,500\n",
            "      BatchNorm2d-35           [128, 250, 8, 8]             500\n",
            "       BasicBlock-36           [128, 250, 8, 8]               0\n",
            "           Conv2d-37           [128, 250, 8, 8]         562,500\n",
            "      BatchNorm2d-38           [128, 250, 8, 8]             500\n",
            "           Conv2d-39           [128, 250, 8, 8]         562,500\n",
            "      BatchNorm2d-40           [128, 250, 8, 8]             500\n",
            "       BasicBlock-41           [128, 250, 8, 8]               0\n",
            "           Conv2d-42           [128, 250, 8, 8]         562,500\n",
            "      BatchNorm2d-43           [128, 250, 8, 8]             500\n",
            "           Conv2d-44           [128, 250, 8, 8]         562,500\n",
            "      BatchNorm2d-45           [128, 250, 8, 8]             500\n",
            "       BasicBlock-46           [128, 250, 8, 8]               0\n",
            "           Linear-47                  [128, 10]           2,510\n",
            "   ResNet_3_layer-48                  [128, 10]               0\n",
            "================================================================\n",
            "Total params: 4,939,902\n",
            "Trainable params: 4,939,902\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.50\n",
            "Forward/backward pass size (MB): 1495.77\n",
            "Params size (MB): 18.84\n",
            "Estimated Total Size (MB): 1516.11\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "Dm1u05-iLoHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"start_epoch: \",start_epoch)\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDfk4THvAZO8",
        "outputId": "90e2ceb7-9f03-4f8e-817b-6773f1172cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_epoch:  0\n",
            "\n",
            "Epoch: 0\n",
            " [================================================================>]  Step: 32ms | Tot: 13s978ms | Loss: 1.447 | Acc: 46.320% (23160/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s74ms | Loss: 1.465 | Acc: 48.780% (4878/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 29ms | Tot: 13s947ms | Loss: 1.187 | Acc: 57.324% (28662/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s172ms | Loss: 1.129 | Acc: 60.600% (6060/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 34ms | Tot: 13s870ms | Loss: 0.991 | Acc: 64.880% (32440/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s187ms | Loss: 1.004 | Acc: 65.090% (6509/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [================================================================>]  Step: 31ms | Tot: 14s252ms | Loss: 0.853 | Acc: 69.884% (34942/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 2s206ms | Loss: 1.063 | Acc: 65.230% (6523/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [================================================================>]  Step: 29ms | Tot: 13s711ms | Loss: 0.727 | Acc: 74.738% (37369/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s45ms | Loss: 0.784 | Acc: 72.890% (7289/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [================================================================>]  Step: 21ms | Tot: 13s948ms | Loss: 0.633 | Acc: 78.072% (39036/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s66ms | Loss: 0.748 | Acc: 74.840% (7484/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [================================================================>]  Step: 30ms | Tot: 13s883ms | Loss: 0.573 | Acc: 80.188% (40094/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s104ms | Loss: 0.675 | Acc: 77.750% (7775/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            " [================================================================>]  Step: 37ms | Tot: 13s827ms | Loss: 0.534 | Acc: 81.558% (40779/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s170ms | Loss: 0.720 | Acc: 75.840% (7584/10000) 100/100 \n",
            "\n",
            "Epoch: 8\n",
            " [================================================================>]  Step: 28ms | Tot: 14s190ms | Loss: 0.507 | Acc: 82.718% (41359/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s25ms | Loss: 0.745 | Acc: 75.330% (7533/10000) 100/100 \n",
            "\n",
            "Epoch: 9\n",
            " [================================================================>]  Step: 30ms | Tot: 13s615ms | Loss: 0.484 | Acc: 83.264% (41632/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s173ms | Loss: 0.542 | Acc: 81.240% (8124/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 10\n",
            " [================================================================>]  Step: 36ms | Tot: 14s194ms | Loss: 0.467 | Acc: 83.976% (41988/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s48ms | Loss: 0.748 | Acc: 76.370% (7637/10000) 100/100 \n",
            "\n",
            "Epoch: 11\n",
            " [================================================================>]  Step: 28ms | Tot: 13s877ms | Loss: 0.450 | Acc: 84.714% (42357/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s127ms | Loss: 0.527 | Acc: 82.220% (8222/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            " [================================================================>]  Step: 27ms | Tot: 13s698ms | Loss: 0.431 | Acc: 85.420% (42710/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s62ms | Loss: 0.613 | Acc: 79.860% (7986/10000) 100/100 \n",
            "\n",
            "Epoch: 13\n",
            " [================================================================>]  Step: 25ms | Tot: 13s809ms | Loss: 0.429 | Acc: 85.228% (42614/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s78ms | Loss: 0.602 | Acc: 79.630% (7963/10000) 100/100 \n",
            "\n",
            "Epoch: 14\n",
            " [================================================================>]  Step: 35ms | Tot: 13s619ms | Loss: 0.413 | Acc: 85.772% (42886/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s52ms | Loss: 0.553 | Acc: 81.310% (8131/10000) 100/100 \n",
            "\n",
            "Epoch: 15\n",
            " [================================================================>]  Step: 22ms | Tot: 13s748ms | Loss: 0.404 | Acc: 86.166% (43083/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s137ms | Loss: 0.591 | Acc: 80.460% (8046/10000) 100/100 \n",
            "\n",
            "Epoch: 16\n",
            " [================================================================>]  Step: 27ms | Tot: 13s702ms | Loss: 0.390 | Acc: 86.592% (43296/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s77ms | Loss: 0.518 | Acc: 82.720% (8272/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            " [================================================================>]  Step: 24ms | Tot: 13s685ms | Loss: 0.391 | Acc: 86.644% (43322/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s42ms | Loss: 0.670 | Acc: 78.820% (7882/10000) 100/100 \n",
            "\n",
            "Epoch: 18\n",
            " [================================================================>]  Step: 20ms | Tot: 14s20ms | Loss: 0.385 | Acc: 86.822% (43411/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s207ms | Loss: 0.623 | Acc: 80.470% (8047/10000) 100/100 \n",
            "\n",
            "Epoch: 19\n",
            " [================================================================>]  Step: 21ms | Tot: 14s158ms | Loss: 0.377 | Acc: 87.122% (43561/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s123ms | Loss: 0.661 | Acc: 79.120% (7912/10000) 100/100 \n",
            "\n",
            "Epoch: 20\n",
            " [================================================================>]  Step: 31ms | Tot: 13s646ms | Loss: 0.376 | Acc: 87.110% (43555/50000) 391/391 \n",
            " [================================================================>]  Step: 11ms | Tot: 1s996ms | Loss: 0.473 | Acc: 84.390% (8439/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 21\n",
            " [================================================================>]  Step: 35ms | Tot: 13s587ms | Loss: 0.369 | Acc: 87.536% (43768/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s99ms | Loss: 0.642 | Acc: 79.330% (7933/10000) 100/100 \n",
            "\n",
            "Epoch: 22\n",
            " [================================================================>]  Step: 29ms | Tot: 13s566ms | Loss: 0.369 | Acc: 87.402% (43701/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s48ms | Loss: 0.696 | Acc: 78.380% (7838/10000) 100/100 \n",
            "\n",
            "Epoch: 23\n",
            " [================================================================>]  Step: 30ms | Tot: 13s878ms | Loss: 0.355 | Acc: 87.772% (43886/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s167ms | Loss: 0.567 | Acc: 82.200% (8220/10000) 100/100 \n",
            "\n",
            "Epoch: 24\n",
            " [================================================================>]  Step: 30ms | Tot: 13s919ms | Loss: 0.353 | Acc: 87.808% (43904/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 2s106ms | Loss: 0.462 | Acc: 84.630% (8463/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 25\n",
            " [================================================================>]  Step: 39ms | Tot: 13s600ms | Loss: 0.345 | Acc: 88.214% (44107/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s100ms | Loss: 0.535 | Acc: 83.010% (8301/10000) 100/100 \n",
            "\n",
            "Epoch: 26\n",
            " [================================================================>]  Step: 22ms | Tot: 13s782ms | Loss: 0.350 | Acc: 87.908% (43954/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s299ms | Loss: 0.639 | Acc: 80.140% (8014/10000) 100/100 \n",
            "\n",
            "Epoch: 27\n",
            " [================================================================>]  Step: 27ms | Tot: 13s673ms | Loss: 0.343 | Acc: 88.354% (44177/50000) 391/391 \n",
            " [================================================================>]  Step: 10ms | Tot: 2s69ms | Loss: 0.496 | Acc: 83.510% (8351/10000) 100/100 \n",
            "\n",
            "Epoch: 28\n",
            " [================================================================>]  Step: 38ms | Tot: 14s51ms | Loss: 0.331 | Acc: 88.612% (44306/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s75ms | Loss: 0.518 | Acc: 83.340% (8334/10000) 100/100 \n",
            "\n",
            "Epoch: 29\n",
            " [================================================================>]  Step: 34ms | Tot: 13s931ms | Loss: 0.341 | Acc: 88.362% (44181/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s242ms | Loss: 0.637 | Acc: 79.810% (7981/10000) 100/100 \n",
            "\n",
            "Epoch: 30\n",
            " [================================================================>]  Step: 28ms | Tot: 14s52ms | Loss: 0.333 | Acc: 88.480% (44240/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s157ms | Loss: 0.491 | Acc: 83.700% (8370/10000) 100/100 \n",
            "\n",
            "Epoch: 31\n",
            " [================================================================>]  Step: 25ms | Tot: 13s622ms | Loss: 0.326 | Acc: 88.816% (44408/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s136ms | Loss: 0.607 | Acc: 80.280% (8028/10000) 100/100 \n",
            "\n",
            "Epoch: 32\n",
            " [================================================================>]  Step: 35ms | Tot: 13s831ms | Loss: 0.328 | Acc: 88.696% (44348/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s107ms | Loss: 0.506 | Acc: 83.210% (8321/10000) 100/100 \n",
            "\n",
            "Epoch: 33\n",
            " [================================================================>]  Step: 27ms | Tot: 13s784ms | Loss: 0.326 | Acc: 88.900% (44450/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s94ms | Loss: 0.628 | Acc: 79.420% (7942/10000) 100/100 \n",
            "\n",
            "Epoch: 34\n",
            " [================================================================>]  Step: 25ms | Tot: 13s677ms | Loss: 0.324 | Acc: 88.772% (44386/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s125ms | Loss: 0.407 | Acc: 86.480% (8648/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 35\n",
            " [================================================================>]  Step: 26ms | Tot: 13s934ms | Loss: 0.316 | Acc: 89.240% (44620/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 1s965ms | Loss: 0.461 | Acc: 85.000% (8500/10000) 100/100 \n",
            "\n",
            "Epoch: 36\n",
            " [================================================================>]  Step: 27ms | Tot: 13s412ms | Loss: 0.313 | Acc: 89.198% (44599/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s207ms | Loss: 0.592 | Acc: 81.560% (8156/10000) 100/100 \n",
            "\n",
            "Epoch: 37\n",
            " [================================================================>]  Step: 31ms | Tot: 13s860ms | Loss: 0.318 | Acc: 89.064% (44532/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s219ms | Loss: 0.468 | Acc: 85.040% (8504/10000) 100/100 \n",
            "\n",
            "Epoch: 38\n",
            " [================================================================>]  Step: 34ms | Tot: 13s852ms | Loss: 0.306 | Acc: 89.624% (44812/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s184ms | Loss: 0.555 | Acc: 82.840% (8284/10000) 100/100 \n",
            "\n",
            "Epoch: 39\n",
            " [================================================================>]  Step: 25ms | Tot: 13s753ms | Loss: 0.314 | Acc: 89.200% (44600/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s117ms | Loss: 0.401 | Acc: 86.570% (8657/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 40\n",
            " [================================================================>]  Step: 28ms | Tot: 13s833ms | Loss: 0.307 | Acc: 89.512% (44756/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s103ms | Loss: 0.551 | Acc: 82.590% (8259/10000) 100/100 \n",
            "\n",
            "Epoch: 41\n",
            " [================================================================>]  Step: 28ms | Tot: 13s538ms | Loss: 0.305 | Acc: 89.546% (44773/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s109ms | Loss: 0.395 | Acc: 86.370% (8637/10000) 100/100 \n",
            "\n",
            "Epoch: 42\n",
            " [================================================================>]  Step: 27ms | Tot: 13s695ms | Loss: 0.304 | Acc: 89.574% (44787/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s64ms | Loss: 0.578 | Acc: 80.930% (8093/10000) 100/100 \n",
            "\n",
            "Epoch: 43\n",
            " [================================================================>]  Step: 28ms | Tot: 14s183ms | Loss: 0.301 | Acc: 89.622% (44811/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s95ms | Loss: 0.470 | Acc: 84.330% (8433/10000) 100/100 \n",
            "\n",
            "Epoch: 44\n",
            " [================================================================>]  Step: 21ms | Tot: 13s556ms | Loss: 0.300 | Acc: 89.688% (44844/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s154ms | Loss: 0.416 | Acc: 86.580% (8658/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 45\n",
            " [================================================================>]  Step: 32ms | Tot: 13s801ms | Loss: 0.296 | Acc: 89.770% (44885/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s70ms | Loss: 0.480 | Acc: 83.870% (8387/10000) 100/100 \n",
            "\n",
            "Epoch: 46\n",
            " [================================================================>]  Step: 31ms | Tot: 13s686ms | Loss: 0.293 | Acc: 90.038% (45019/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s62ms | Loss: 0.427 | Acc: 86.110% (8611/10000) 100/100 \n",
            "\n",
            "Epoch: 47\n",
            " [================================================================>]  Step: 28ms | Tot: 14s44ms | Loss: 0.295 | Acc: 89.822% (44911/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s36ms | Loss: 0.544 | Acc: 82.880% (8288/10000) 100/100 \n",
            "\n",
            "Epoch: 48\n",
            " [================================================================>]  Step: 19ms | Tot: 14s199ms | Loss: 0.287 | Acc: 90.100% (45050/50000) 391/391 \n",
            " [================================================================>]  Step: 10ms | Tot: 2s82ms | Loss: 0.404 | Acc: 86.740% (8674/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 49\n",
            " [================================================================>]  Step: 28ms | Tot: 13s605ms | Loss: 0.288 | Acc: 90.182% (45091/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 1s991ms | Loss: 0.461 | Acc: 85.070% (8507/10000) 100/100 \n",
            "\n",
            "Epoch: 50\n",
            " [================================================================>]  Step: 38ms | Tot: 14s234ms | Loss: 0.288 | Acc: 90.164% (45082/50000) 391/391 \n",
            " [================================================================>]  Step: 11ms | Tot: 2s207ms | Loss: 0.450 | Acc: 85.700% (8570/10000) 100/100 \n",
            "\n",
            "Epoch: 51\n",
            " [================================================================>]  Step: 27ms | Tot: 13s791ms | Loss: 0.280 | Acc: 90.500% (45250/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s6ms | Loss: 0.607 | Acc: 81.400% (8140/10000) 100/100 \n",
            "\n",
            "Epoch: 52\n",
            " [================================================================>]  Step: 32ms | Tot: 13s938ms | Loss: 0.273 | Acc: 90.574% (45287/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s116ms | Loss: 0.401 | Acc: 86.750% (8675/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 53\n",
            " [================================================================>]  Step: 26ms | Tot: 13s525ms | Loss: 0.279 | Acc: 90.422% (45211/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s45ms | Loss: 0.429 | Acc: 85.900% (8590/10000) 100/100 \n",
            "\n",
            "Epoch: 54\n",
            " [================================================================>]  Step: 28ms | Tot: 13s903ms | Loss: 0.281 | Acc: 90.456% (45228/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s241ms | Loss: 0.382 | Acc: 86.890% (8689/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 55\n",
            " [================================================================>]  Step: 28ms | Tot: 13s709ms | Loss: 0.273 | Acc: 90.504% (45252/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 2s150ms | Loss: 0.505 | Acc: 84.170% (8417/10000) 100/100 \n",
            "\n",
            "Epoch: 56\n",
            " [================================================================>]  Step: 25ms | Tot: 13s968ms | Loss: 0.272 | Acc: 90.672% (45336/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s168ms | Loss: 0.504 | Acc: 84.280% (8428/10000) 100/100 \n",
            "\n",
            "Epoch: 57\n",
            " [================================================================>]  Step: 27ms | Tot: 13s775ms | Loss: 0.269 | Acc: 90.764% (45382/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s146ms | Loss: 1.138 | Acc: 71.950% (7195/10000) 100/100 \n",
            "\n",
            "Epoch: 58\n",
            " [================================================================>]  Step: 27ms | Tot: 13s566ms | Loss: 0.268 | Acc: 90.752% (45376/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s116ms | Loss: 0.405 | Acc: 87.210% (8721/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 59\n",
            " [================================================================>]  Step: 33ms | Tot: 13s593ms | Loss: 0.266 | Acc: 90.850% (45425/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s84ms | Loss: 0.545 | Acc: 82.660% (8266/10000) 100/100 \n",
            "\n",
            "Epoch: 60\n",
            " [================================================================>]  Step: 22ms | Tot: 13s921ms | Loss: 0.263 | Acc: 90.958% (45479/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s75ms | Loss: 1.023 | Acc: 74.300% (7430/10000) 100/100 \n",
            "\n",
            "Epoch: 61\n",
            " [================================================================>]  Step: 32ms | Tot: 13s641ms | Loss: 0.260 | Acc: 91.062% (45531/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s110ms | Loss: 0.432 | Acc: 86.050% (8605/10000) 100/100 \n",
            "\n",
            "Epoch: 62\n",
            " [================================================================>]  Step: 33ms | Tot: 13s699ms | Loss: 0.256 | Acc: 91.306% (45653/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s65ms | Loss: 0.500 | Acc: 83.920% (8392/10000) 100/100 \n",
            "\n",
            "Epoch: 63\n",
            " [================================================================>]  Step: 29ms | Tot: 13s979ms | Loss: 0.263 | Acc: 90.980% (45490/50000) 391/391 \n",
            " [================================================================>]  Step: 13ms | Tot: 2s256ms | Loss: 0.427 | Acc: 86.130% (8613/10000) 100/100 \n",
            "\n",
            "Epoch: 64\n",
            " [================================================================>]  Step: 26ms | Tot: 13s891ms | Loss: 0.253 | Acc: 91.396% (45698/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s101ms | Loss: 0.364 | Acc: 87.810% (8781/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 65\n",
            " [================================================================>]  Step: 29ms | Tot: 13s780ms | Loss: 0.256 | Acc: 91.314% (45657/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 1s970ms | Loss: 0.469 | Acc: 84.990% (8499/10000) 100/100 \n",
            "\n",
            "Epoch: 66\n",
            " [================================================================>]  Step: 35ms | Tot: 13s488ms | Loss: 0.251 | Acc: 91.376% (45688/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 1s996ms | Loss: 0.427 | Acc: 86.050% (8605/10000) 100/100 \n",
            "\n",
            "Epoch: 67\n",
            " [================================================================>]  Step: 19ms | Tot: 13s401ms | Loss: 0.252 | Acc: 91.416% (45708/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 2s224ms | Loss: 0.583 | Acc: 81.570% (8157/10000) 100/100 \n",
            "\n",
            "Epoch: 68\n",
            " [================================================================>]  Step: 35ms | Tot: 13s654ms | Loss: 0.245 | Acc: 91.614% (45807/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s135ms | Loss: 0.780 | Acc: 77.710% (7771/10000) 100/100 \n",
            "\n",
            "Epoch: 69\n",
            " [================================================================>]  Step: 25ms | Tot: 13s848ms | Loss: 0.243 | Acc: 91.768% (45884/50000) 391/391 \n",
            " [================================================================>]  Step: 13ms | Tot: 2s67ms | Loss: 0.381 | Acc: 87.790% (8779/10000) 100/100 \n",
            "\n",
            "Epoch: 70\n",
            " [================================================================>]  Step: 19ms | Tot: 13s751ms | Loss: 0.240 | Acc: 91.646% (45823/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s74ms | Loss: 0.345 | Acc: 88.230% (8823/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 71\n",
            " [================================================================>]  Step: 31ms | Tot: 13s905ms | Loss: 0.243 | Acc: 91.548% (45774/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s101ms | Loss: 0.524 | Acc: 83.860% (8386/10000) 100/100 \n",
            "\n",
            "Epoch: 72\n",
            " [================================================================>]  Step: 26ms | Tot: 13s568ms | Loss: 0.241 | Acc: 91.770% (45885/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s136ms | Loss: 0.462 | Acc: 84.820% (8482/10000) 100/100 \n",
            "\n",
            "Epoch: 73\n",
            " [================================================================>]  Step: 28ms | Tot: 13s624ms | Loss: 0.233 | Acc: 92.048% (46024/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s68ms | Loss: 0.397 | Acc: 87.100% (8710/10000) 100/100 \n",
            "\n",
            "Epoch: 74\n",
            " [================================================================>]  Step: 31ms | Tot: 13s573ms | Loss: 0.233 | Acc: 91.830% (45915/50000) 391/391 \n",
            " [================================================================>]  Step: 12ms | Tot: 2s85ms | Loss: 0.430 | Acc: 86.290% (8629/10000) 100/100 \n",
            "\n",
            "Epoch: 75\n",
            " [================================================================>]  Step: 32ms | Tot: 13s983ms | Loss: 0.234 | Acc: 91.896% (45948/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s55ms | Loss: 0.442 | Acc: 85.660% (8566/10000) 100/100 \n",
            "\n",
            "Epoch: 76\n",
            " [================================================================>]  Step: 30ms | Tot: 14s31ms | Loss: 0.227 | Acc: 92.180% (46090/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s168ms | Loss: 0.430 | Acc: 86.410% (8641/10000) 100/100 \n",
            "\n",
            "Epoch: 77\n",
            " [================================================================>]  Step: 25ms | Tot: 13s877ms | Loss: 0.232 | Acc: 92.006% (46003/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s59ms | Loss: 0.335 | Acc: 88.900% (8890/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 78\n",
            " [================================================================>]  Step: 28ms | Tot: 13s873ms | Loss: 0.224 | Acc: 92.366% (46183/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s167ms | Loss: 0.374 | Acc: 88.270% (8827/10000) 100/100 \n",
            "\n",
            "Epoch: 79\n",
            " [================================================================>]  Step: 28ms | Tot: 14s113ms | Loss: 0.222 | Acc: 92.464% (46232/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s137ms | Loss: 0.574 | Acc: 81.150% (8115/10000) 100/100 \n",
            "\n",
            "Epoch: 80\n",
            " [================================================================>]  Step: 26ms | Tot: 13s848ms | Loss: 0.223 | Acc: 92.400% (46200/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s23ms | Loss: 0.401 | Acc: 87.110% (8711/10000) 100/100 \n",
            "\n",
            "Epoch: 81\n",
            " [================================================================>]  Step: 26ms | Tot: 13s834ms | Loss: 0.217 | Acc: 92.524% (46262/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s79ms | Loss: 0.387 | Acc: 87.680% (8768/10000) 100/100 \n",
            "\n",
            "Epoch: 82\n",
            " [================================================================>]  Step: 27ms | Tot: 14s28ms | Loss: 0.214 | Acc: 92.772% (46386/50000) 391/391 \n",
            " [================================================================>]  Step: 12ms | Tot: 2s89ms | Loss: 0.367 | Acc: 87.930% (8793/10000) 100/100 \n",
            "\n",
            "Epoch: 83\n",
            " [================================================================>]  Step: 19ms | Tot: 13s765ms | Loss: 0.211 | Acc: 92.656% (46328/50000) 391/391 \n",
            " [================================================================>]  Step: 11ms | Tot: 2s84ms | Loss: 0.364 | Acc: 88.260% (8826/10000) 100/100 \n",
            "\n",
            "Epoch: 84\n",
            " [================================================================>]  Step: 29ms | Tot: 13s626ms | Loss: 0.210 | Acc: 92.702% (46351/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s117ms | Loss: 0.372 | Acc: 88.720% (8872/10000) 100/100 \n",
            "\n",
            "Epoch: 85\n",
            " [================================================================>]  Step: 27ms | Tot: 13s789ms | Loss: 0.207 | Acc: 92.940% (46470/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s111ms | Loss: 0.422 | Acc: 86.390% (8639/10000) 100/100 \n",
            "\n",
            "Epoch: 86\n",
            " [================================================================>]  Step: 20ms | Tot: 13s690ms | Loss: 0.206 | Acc: 92.952% (46476/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s152ms | Loss: 0.411 | Acc: 87.110% (8711/10000) 100/100 \n",
            "\n",
            "Epoch: 87\n",
            " [================================================================>]  Step: 35ms | Tot: 14s20ms | Loss: 0.208 | Acc: 92.810% (46405/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s277ms | Loss: 0.388 | Acc: 87.730% (8773/10000) 100/100 \n",
            "\n",
            "Epoch: 88\n",
            " [================================================================>]  Step: 31ms | Tot: 13s826ms | Loss: 0.190 | Acc: 93.532% (46766/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s200ms | Loss: 0.365 | Acc: 88.160% (8816/10000) 100/100 \n",
            "\n",
            "Epoch: 89\n",
            " [================================================================>]  Step: 29ms | Tot: 14s130ms | Loss: 0.203 | Acc: 92.958% (46479/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s32ms | Loss: 0.383 | Acc: 87.700% (8770/10000) 100/100 \n",
            "\n",
            "Epoch: 90\n",
            " [================================================================>]  Step: 34ms | Tot: 13s861ms | Loss: 0.200 | Acc: 93.186% (46593/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s25ms | Loss: 0.329 | Acc: 89.240% (8924/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 91\n",
            " [================================================================>]  Step: 33ms | Tot: 13s820ms | Loss: 0.188 | Acc: 93.560% (46780/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s226ms | Loss: 0.331 | Acc: 89.450% (8945/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 92\n",
            " [================================================================>]  Step: 22ms | Tot: 13s895ms | Loss: 0.192 | Acc: 93.290% (46645/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s103ms | Loss: 0.407 | Acc: 86.830% (8683/10000) 100/100 \n",
            "\n",
            "Epoch: 93\n",
            " [================================================================>]  Step: 28ms | Tot: 13s962ms | Loss: 0.192 | Acc: 93.490% (46745/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s172ms | Loss: 0.446 | Acc: 85.870% (8587/10000) 100/100 \n",
            "\n",
            "Epoch: 94\n",
            " [================================================================>]  Step: 27ms | Tot: 13s715ms | Loss: 0.184 | Acc: 93.764% (46882/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s22ms | Loss: 0.347 | Acc: 89.070% (8907/10000) 100/100 \n",
            "\n",
            "Epoch: 95\n",
            " [================================================================>]  Step: 25ms | Tot: 13s961ms | Loss: 0.183 | Acc: 93.758% (46879/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s136ms | Loss: 0.390 | Acc: 87.810% (8781/10000) 100/100 \n",
            "\n",
            "Epoch: 96\n",
            " [================================================================>]  Step: 27ms | Tot: 13s698ms | Loss: 0.180 | Acc: 93.912% (46956/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s136ms | Loss: 0.371 | Acc: 88.310% (8831/10000) 100/100 \n",
            "\n",
            "Epoch: 97\n",
            " [================================================================>]  Step: 31ms | Tot: 13s634ms | Loss: 0.179 | Acc: 93.952% (46976/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s100ms | Loss: 0.387 | Acc: 87.830% (8783/10000) 100/100 \n",
            "\n",
            "Epoch: 98\n",
            " [================================================================>]  Step: 28ms | Tot: 13s746ms | Loss: 0.178 | Acc: 93.832% (46916/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s62ms | Loss: 0.350 | Acc: 88.960% (8896/10000) 100/100 \n",
            "\n",
            "Epoch: 99\n",
            " [================================================================>]  Step: 31ms | Tot: 13s667ms | Loss: 0.171 | Acc: 94.054% (47027/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s43ms | Loss: 0.371 | Acc: 88.570% (8857/10000) 100/100 \n",
            "\n",
            "Epoch: 100\n",
            " [================================================================>]  Step: 25ms | Tot: 13s719ms | Loss: 0.169 | Acc: 94.180% (47090/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s93ms | Loss: 0.480 | Acc: 85.830% (8583/10000) 100/100 \n",
            "\n",
            "Epoch: 101\n",
            " [================================================================>]  Step: 35ms | Tot: 13s848ms | Loss: 0.167 | Acc: 94.220% (47110/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s279ms | Loss: 0.367 | Acc: 88.620% (8862/10000) 100/100 \n",
            "\n",
            "Epoch: 102\n",
            " [================================================================>]  Step: 30ms | Tot: 13s677ms | Loss: 0.169 | Acc: 94.196% (47098/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s110ms | Loss: 0.372 | Acc: 88.200% (8820/10000) 100/100 \n",
            "\n",
            "Epoch: 103\n",
            " [================================================================>]  Step: 31ms | Tot: 13s947ms | Loss: 0.160 | Acc: 94.398% (47199/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s273ms | Loss: 0.321 | Acc: 89.830% (8983/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 104\n",
            " [================================================================>]  Step: 35ms | Tot: 13s907ms | Loss: 0.160 | Acc: 94.392% (47196/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s42ms | Loss: 0.410 | Acc: 87.950% (8795/10000) 100/100 \n",
            "\n",
            "Epoch: 105\n",
            " [================================================================>]  Step: 30ms | Tot: 13s544ms | Loss: 0.159 | Acc: 94.532% (47266/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s139ms | Loss: 0.385 | Acc: 88.260% (8826/10000) 100/100 \n",
            "\n",
            "Epoch: 106\n",
            " [================================================================>]  Step: 27ms | Tot: 14s39ms | Loss: 0.154 | Acc: 94.722% (47361/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 2s117ms | Loss: 0.353 | Acc: 89.250% (8925/10000) 100/100 \n",
            "\n",
            "Epoch: 107\n",
            " [================================================================>]  Step: 23ms | Tot: 14s87ms | Loss: 0.159 | Acc: 94.528% (47264/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s165ms | Loss: 0.364 | Acc: 88.700% (8870/10000) 100/100 \n",
            "\n",
            "Epoch: 108\n",
            " [================================================================>]  Step: 29ms | Tot: 13s932ms | Loss: 0.146 | Acc: 95.078% (47539/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s44ms | Loss: 0.387 | Acc: 88.400% (8840/10000) 100/100 \n",
            "\n",
            "Epoch: 109\n",
            " [================================================================>]  Step: 32ms | Tot: 13s746ms | Loss: 0.149 | Acc: 94.826% (47413/50000) 391/391 \n",
            " [================================================================>]  Step: 11ms | Tot: 2s199ms | Loss: 0.351 | Acc: 89.140% (8914/10000) 100/100 \n",
            "\n",
            "Epoch: 110\n",
            " [================================================================>]  Step: 32ms | Tot: 13s999ms | Loss: 0.145 | Acc: 95.120% (47560/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s105ms | Loss: 0.328 | Acc: 89.680% (8968/10000) 100/100 \n",
            "\n",
            "Epoch: 111\n",
            " [================================================================>]  Step: 30ms | Tot: 13s916ms | Loss: 0.141 | Acc: 95.170% (47585/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s129ms | Loss: 0.350 | Acc: 88.840% (8884/10000) 100/100 \n",
            "\n",
            "Epoch: 112\n",
            " [================================================================>]  Step: 23ms | Tot: 13s892ms | Loss: 0.142 | Acc: 95.120% (47560/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s57ms | Loss: 0.313 | Acc: 90.410% (9041/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 113\n",
            " [================================================================>]  Step: 35ms | Tot: 13s888ms | Loss: 0.135 | Acc: 95.478% (47739/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s212ms | Loss: 0.334 | Acc: 89.870% (8987/10000) 100/100 \n",
            "\n",
            "Epoch: 114\n",
            " [================================================================>]  Step: 34ms | Tot: 13s628ms | Loss: 0.139 | Acc: 95.334% (47667/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s353ms | Loss: 0.378 | Acc: 88.640% (8864/10000) 100/100 \n",
            "\n",
            "Epoch: 115\n",
            " [================================================================>]  Step: 24ms | Tot: 13s574ms | Loss: 0.133 | Acc: 95.418% (47709/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s111ms | Loss: 0.341 | Acc: 89.510% (8951/10000) 100/100 \n",
            "\n",
            "Epoch: 116\n",
            " [================================================================>]  Step: 32ms | Tot: 13s663ms | Loss: 0.135 | Acc: 95.374% (47687/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s150ms | Loss: 0.401 | Acc: 88.330% (8833/10000) 100/100 \n",
            "\n",
            "Epoch: 117\n",
            " [================================================================>]  Step: 31ms | Tot: 13s926ms | Loss: 0.125 | Acc: 95.780% (47890/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s124ms | Loss: 0.321 | Acc: 90.540% (9054/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 118\n",
            " [================================================================>]  Step: 38ms | Tot: 13s843ms | Loss: 0.118 | Acc: 95.986% (47993/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s196ms | Loss: 0.330 | Acc: 90.030% (9003/10000) 100/100 \n",
            "\n",
            "Epoch: 119\n",
            " [================================================================>]  Step: 26ms | Tot: 13s665ms | Loss: 0.122 | Acc: 95.896% (47948/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s82ms | Loss: 0.328 | Acc: 89.930% (8993/10000) 100/100 \n",
            "\n",
            "Epoch: 120\n",
            " [================================================================>]  Step: 30ms | Tot: 13s960ms | Loss: 0.117 | Acc: 95.952% (47976/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s143ms | Loss: 0.361 | Acc: 89.530% (8953/10000) 100/100 \n",
            "\n",
            "Epoch: 121\n",
            " [================================================================>]  Step: 29ms | Tot: 13s670ms | Loss: 0.115 | Acc: 96.046% (48023/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s235ms | Loss: 0.327 | Acc: 90.310% (9031/10000) 100/100 \n",
            "\n",
            "Epoch: 122\n",
            " [================================================================>]  Step: 27ms | Tot: 14s33ms | Loss: 0.111 | Acc: 96.254% (48127/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s65ms | Loss: 0.309 | Acc: 90.850% (9085/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 123\n",
            " [================================================================>]  Step: 28ms | Tot: 13s973ms | Loss: 0.109 | Acc: 96.356% (48178/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s212ms | Loss: 0.342 | Acc: 89.860% (8986/10000) 100/100 \n",
            "\n",
            "Epoch: 124\n",
            " [================================================================>]  Step: 28ms | Tot: 13s820ms | Loss: 0.112 | Acc: 96.136% (48068/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s121ms | Loss: 0.348 | Acc: 89.800% (8980/10000) 100/100 \n",
            "\n",
            "Epoch: 125\n",
            " [================================================================>]  Step: 31ms | Tot: 13s978ms | Loss: 0.101 | Acc: 96.614% (48307/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s171ms | Loss: 0.368 | Acc: 90.150% (9015/10000) 100/100 \n",
            "\n",
            "Epoch: 126\n",
            " [================================================================>]  Step: 34ms | Tot: 13s960ms | Loss: 0.103 | Acc: 96.508% (48254/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s81ms | Loss: 0.357 | Acc: 89.240% (8924/10000) 100/100 \n",
            "\n",
            "Epoch: 127\n",
            " [================================================================>]  Step: 21ms | Tot: 13s773ms | Loss: 0.095 | Acc: 96.752% (48376/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s239ms | Loss: 0.324 | Acc: 90.600% (9060/10000) 100/100 \n",
            "\n",
            "Epoch: 128\n",
            " [================================================================>]  Step: 29ms | Tot: 13s746ms | Loss: 0.100 | Acc: 96.640% (48320/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s163ms | Loss: 0.313 | Acc: 90.540% (9054/10000) 100/100 \n",
            "\n",
            "Epoch: 129\n",
            " [================================================================>]  Step: 19ms | Tot: 13s762ms | Loss: 0.091 | Acc: 97.022% (48511/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s123ms | Loss: 0.322 | Acc: 90.570% (9057/10000) 100/100 \n",
            "\n",
            "Epoch: 130\n",
            " [================================================================>]  Step: 26ms | Tot: 14s45ms | Loss: 0.094 | Acc: 96.804% (48402/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s212ms | Loss: 0.298 | Acc: 91.200% (9120/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 131\n",
            " [================================================================>]  Step: 35ms | Tot: 14s | Loss: 0.088 | Acc: 97.052% (48526/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s130ms | Loss: 0.286 | Acc: 91.060% (9106/10000) 100/100 \n",
            "\n",
            "Epoch: 132\n",
            " [================================================================>]  Step: 30ms | Tot: 13s699ms | Loss: 0.083 | Acc: 97.248% (48624/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s176ms | Loss: 0.324 | Acc: 90.750% (9075/10000) 100/100 \n",
            "\n",
            "Epoch: 133\n",
            " [================================================================>]  Step: 37ms | Tot: 13s632ms | Loss: 0.079 | Acc: 97.354% (48677/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s234ms | Loss: 0.285 | Acc: 91.400% (9140/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 134\n",
            " [================================================================>]  Step: 30ms | Tot: 13s725ms | Loss: 0.082 | Acc: 97.312% (48656/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s138ms | Loss: 0.288 | Acc: 91.720% (9172/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 135\n",
            " [================================================================>]  Step: 25ms | Tot: 13s769ms | Loss: 0.071 | Acc: 97.650% (48825/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s229ms | Loss: 0.296 | Acc: 91.840% (9184/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 136\n",
            " [================================================================>]  Step: 30ms | Tot: 13s955ms | Loss: 0.071 | Acc: 97.624% (48812/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s171ms | Loss: 0.274 | Acc: 92.110% (9211/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 137\n",
            " [================================================================>]  Step: 25ms | Tot: 13s596ms | Loss: 0.072 | Acc: 97.600% (48800/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s179ms | Loss: 0.266 | Acc: 92.110% (9211/10000) 100/100 \n",
            "\n",
            "Epoch: 138\n",
            " [================================================================>]  Step: 28ms | Tot: 13s533ms | Loss: 0.067 | Acc: 97.820% (48910/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s83ms | Loss: 0.445 | Acc: 87.560% (8756/10000) 100/100 \n",
            "\n",
            "Epoch: 139\n",
            " [================================================================>]  Step: 28ms | Tot: 14s35ms | Loss: 0.071 | Acc: 97.562% (48781/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s155ms | Loss: 0.333 | Acc: 91.120% (9112/10000) 100/100 \n",
            "\n",
            "Epoch: 140\n",
            " [================================================================>]  Step: 24ms | Tot: 14s92ms | Loss: 0.064 | Acc: 97.940% (48970/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s116ms | Loss: 0.316 | Acc: 91.010% (9101/10000) 100/100 \n",
            "\n",
            "Epoch: 141\n",
            " [================================================================>]  Step: 28ms | Tot: 13s849ms | Loss: 0.059 | Acc: 98.040% (49020/50000) 391/391 \n",
            " [================================================================>]  Step: 12ms | Tot: 2s181ms | Loss: 0.302 | Acc: 91.820% (9182/10000) 100/100 \n",
            "\n",
            "Epoch: 142\n",
            " [================================================================>]  Step: 36ms | Tot: 13s626ms | Loss: 0.056 | Acc: 98.204% (49102/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s159ms | Loss: 0.298 | Acc: 91.780% (9178/10000) 100/100 \n",
            "\n",
            "Epoch: 143\n",
            " [================================================================>]  Step: 35ms | Tot: 14s44ms | Loss: 0.056 | Acc: 98.196% (49098/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s92ms | Loss: 0.296 | Acc: 91.820% (9182/10000) 100/100 \n",
            "\n",
            "Epoch: 144\n",
            " [================================================================>]  Step: 29ms | Tot: 13s856ms | Loss: 0.056 | Acc: 98.200% (49100/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s85ms | Loss: 0.289 | Acc: 91.310% (9131/10000) 100/100 \n",
            "\n",
            "Epoch: 145\n",
            " [================================================================>]  Step: 33ms | Tot: 13s772ms | Loss: 0.053 | Acc: 98.256% (49128/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s182ms | Loss: 0.287 | Acc: 92.230% (9223/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 146\n",
            " [================================================================>]  Step: 27ms | Tot: 13s932ms | Loss: 0.049 | Acc: 98.394% (49197/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s196ms | Loss: 0.277 | Acc: 92.340% (9234/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 147\n",
            " [================================================================>]  Step: 34ms | Tot: 13s794ms | Loss: 0.045 | Acc: 98.564% (49282/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s246ms | Loss: 0.344 | Acc: 90.960% (9096/10000) 100/100 \n",
            "\n",
            "Epoch: 148\n",
            " [================================================================>]  Step: 28ms | Tot: 13s879ms | Loss: 0.043 | Acc: 98.626% (49313/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s144ms | Loss: 0.344 | Acc: 91.190% (9119/10000) 100/100 \n",
            "\n",
            "Epoch: 149\n",
            " [================================================================>]  Step: 25ms | Tot: 14s16ms | Loss: 0.040 | Acc: 98.722% (49361/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s124ms | Loss: 0.287 | Acc: 91.910% (9191/10000) 100/100 \n",
            "\n",
            "Epoch: 150\n",
            " [================================================================>]  Step: 28ms | Tot: 13s689ms | Loss: 0.041 | Acc: 98.748% (49374/50000) 391/391 \n",
            " [================================================================>]  Step: 11ms | Tot: 2s89ms | Loss: 0.277 | Acc: 92.550% (9255/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 151\n",
            " [================================================================>]  Step: 30ms | Tot: 14s90ms | Loss: 0.033 | Acc: 99.024% (49512/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s260ms | Loss: 0.290 | Acc: 92.160% (9216/10000) 100/100 \n",
            "\n",
            "Epoch: 152\n",
            " [================================================================>]  Step: 32ms | Tot: 13s915ms | Loss: 0.031 | Acc: 99.056% (49528/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s75ms | Loss: 0.239 | Acc: 93.280% (9328/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 153\n",
            " [================================================================>]  Step: 19ms | Tot: 13s872ms | Loss: 0.028 | Acc: 99.082% (49541/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s211ms | Loss: 0.275 | Acc: 92.920% (9292/10000) 100/100 \n",
            "\n",
            "Epoch: 154\n",
            " [================================================================>]  Step: 29ms | Tot: 14s19ms | Loss: 0.025 | Acc: 99.242% (49621/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s88ms | Loss: 0.285 | Acc: 92.830% (9283/10000) 100/100 \n",
            "\n",
            "Epoch: 155\n",
            " [================================================================>]  Step: 29ms | Tot: 13s852ms | Loss: 0.025 | Acc: 99.280% (49640/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s187ms | Loss: 0.261 | Acc: 93.240% (9324/10000) 100/100 \n",
            "\n",
            "Epoch: 156\n",
            " [================================================================>]  Step: 31ms | Tot: 13s680ms | Loss: 0.023 | Acc: 99.318% (49659/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s221ms | Loss: 0.304 | Acc: 92.200% (9220/10000) 100/100 \n",
            "\n",
            "Epoch: 157\n",
            " [================================================================>]  Step: 28ms | Tot: 13s840ms | Loss: 0.022 | Acc: 99.362% (49681/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s110ms | Loss: 0.259 | Acc: 93.460% (9346/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 158\n",
            " [================================================================>]  Step: 32ms | Tot: 13s991ms | Loss: 0.019 | Acc: 99.446% (49723/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s159ms | Loss: 0.255 | Acc: 93.390% (9339/10000) 100/100 \n",
            "\n",
            "Epoch: 159\n",
            " [================================================================>]  Step: 27ms | Tot: 13s754ms | Loss: 0.018 | Acc: 99.502% (49751/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s89ms | Loss: 0.265 | Acc: 93.260% (9326/10000) 100/100 \n",
            "\n",
            "Epoch: 160\n",
            " [================================================================>]  Step: 30ms | Tot: 13s410ms | Loss: 0.017 | Acc: 99.468% (49734/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s208ms | Loss: 0.239 | Acc: 93.790% (9379/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 161\n",
            " [================================================================>]  Step: 27ms | Tot: 13s821ms | Loss: 0.013 | Acc: 99.632% (49816/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s240ms | Loss: 0.227 | Acc: 94.320% (9432/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 162\n",
            " [================================================================>]  Step: 29ms | Tot: 14s98ms | Loss: 0.011 | Acc: 99.736% (49868/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s80ms | Loss: 0.257 | Acc: 93.650% (9365/10000) 100/100 \n",
            "\n",
            "Epoch: 163\n",
            " [================================================================>]  Step: 30ms | Tot: 14s7ms | Loss: 0.009 | Acc: 99.782% (49891/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s274ms | Loss: 0.247 | Acc: 93.800% (9380/10000) 100/100 \n",
            "\n",
            "Epoch: 164\n",
            " [================================================================>]  Step: 30ms | Tot: 13s811ms | Loss: 0.010 | Acc: 99.718% (49859/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 2s70ms | Loss: 0.242 | Acc: 94.050% (9405/10000) 100/100 \n",
            "\n",
            "Epoch: 165\n",
            " [================================================================>]  Step: 21ms | Tot: 14s199ms | Loss: 0.007 | Acc: 99.864% (49932/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s78ms | Loss: 0.249 | Acc: 93.840% (9384/10000) 100/100 \n",
            "\n",
            "Epoch: 166\n",
            " [================================================================>]  Step: 28ms | Tot: 13s815ms | Loss: 0.008 | Acc: 99.842% (49921/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s137ms | Loss: 0.228 | Acc: 94.260% (9426/10000) 100/100 \n",
            "\n",
            "Epoch: 167\n",
            " [================================================================>]  Step: 31ms | Tot: 13s911ms | Loss: 0.006 | Acc: 99.888% (49944/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s165ms | Loss: 0.213 | Acc: 94.680% (9468/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 168\n",
            " [================================================================>]  Step: 20ms | Tot: 13s962ms | Loss: 0.005 | Acc: 99.920% (49960/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s139ms | Loss: 0.220 | Acc: 94.570% (9457/10000) 100/100 \n",
            "\n",
            "Epoch: 169\n",
            " [================================================================>]  Step: 43ms | Tot: 13s997ms | Loss: 0.003 | Acc: 99.962% (49981/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s148ms | Loss: 0.224 | Acc: 94.660% (9466/10000) 100/100 \n",
            "\n",
            "Epoch: 170\n",
            " [================================================================>]  Step: 33ms | Tot: 13s834ms | Loss: 0.004 | Acc: 99.938% (49969/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s51ms | Loss: 0.219 | Acc: 94.490% (9449/10000) 100/100 \n",
            "\n",
            "Epoch: 171\n",
            " [================================================================>]  Step: 27ms | Tot: 13s827ms | Loss: 0.004 | Acc: 99.934% (49967/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s127ms | Loss: 0.217 | Acc: 94.770% (9477/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 172\n",
            " [================================================================>]  Step: 26ms | Tot: 13s758ms | Loss: 0.003 | Acc: 99.976% (49988/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s165ms | Loss: 0.214 | Acc: 94.830% (9483/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 173\n",
            " [================================================================>]  Step: 28ms | Tot: 13s837ms | Loss: 0.003 | Acc: 99.972% (49986/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s203ms | Loss: 0.213 | Acc: 94.790% (9479/10000) 100/100 \n",
            "\n",
            "Epoch: 174\n",
            " [================================================================>]  Step: 20ms | Tot: 13s814ms | Loss: 0.002 | Acc: 99.988% (49994/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s184ms | Loss: 0.213 | Acc: 94.780% (9478/10000) 100/100 \n",
            "\n",
            "Epoch: 175\n",
            " [================================================================>]  Step: 28ms | Tot: 14s161ms | Loss: 0.002 | Acc: 99.984% (49992/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 2s119ms | Loss: 0.211 | Acc: 94.810% (9481/10000) 100/100 \n",
            "\n",
            "Epoch: 176\n",
            " [================================================================>]  Step: 32ms | Tot: 13s581ms | Loss: 0.002 | Acc: 99.982% (49991/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s67ms | Loss: 0.209 | Acc: 94.810% (9481/10000) 100/100 \n",
            "\n",
            "Epoch: 177\n",
            " [================================================================>]  Step: 32ms | Tot: 14s321ms | Loss: 0.002 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s111ms | Loss: 0.205 | Acc: 94.820% (9482/10000) 100/100 \n",
            "\n",
            "Epoch: 178\n",
            " [================================================================>]  Step: 27ms | Tot: 14s27ms | Loss: 0.002 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s59ms | Loss: 0.208 | Acc: 94.820% (9482/10000) 100/100 \n",
            "\n",
            "Epoch: 179\n",
            " [================================================================>]  Step: 30ms | Tot: 13s728ms | Loss: 0.002 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s274ms | Loss: 0.205 | Acc: 94.730% (9473/10000) 100/100 \n",
            "\n",
            "Epoch: 180\n",
            " [================================================================>]  Step: 32ms | Tot: 13s640ms | Loss: 0.002 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s157ms | Loss: 0.203 | Acc: 94.860% (9486/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 181\n",
            " [================================================================>]  Step: 18ms | Tot: 13s812ms | Loss: 0.002 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s71ms | Loss: 0.204 | Acc: 94.840% (9484/10000) 100/100 \n",
            "\n",
            "Epoch: 182\n",
            " [================================================================>]  Step: 31ms | Tot: 13s907ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s31ms | Loss: 0.203 | Acc: 94.870% (9487/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 183\n",
            " [================================================================>]  Step: 28ms | Tot: 13s845ms | Loss: 0.002 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s103ms | Loss: 0.202 | Acc: 94.960% (9496/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 184\n",
            " [================================================================>]  Step: 34ms | Tot: 13s970ms | Loss: 0.002 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s149ms | Loss: 0.198 | Acc: 94.920% (9492/10000) 100/100 \n",
            "\n",
            "Epoch: 185\n",
            " [================================================================>]  Step: 19ms | Tot: 13s574ms | Loss: 0.002 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s69ms | Loss: 0.200 | Acc: 94.900% (9490/10000) 100/100 \n",
            "\n",
            "Epoch: 186\n",
            " [================================================================>]  Step: 25ms | Tot: 13s599ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s42ms | Loss: 0.197 | Acc: 94.880% (9488/10000) 100/100 \n",
            "\n",
            "Epoch: 187\n",
            " [================================================================>]  Step: 27ms | Tot: 13s685ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s197ms | Loss: 0.198 | Acc: 94.880% (9488/10000) 100/100 \n",
            "\n",
            "Epoch: 188\n",
            " [================================================================>]  Step: 28ms | Tot: 13s851ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s179ms | Loss: 0.198 | Acc: 94.830% (9483/10000) 100/100 \n",
            "\n",
            "Epoch: 189\n",
            " [================================================================>]  Step: 25ms | Tot: 13s958ms | Loss: 0.002 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s131ms | Loss: 0.198 | Acc: 94.890% (9489/10000) 100/100 \n",
            "\n",
            "Epoch: 190\n",
            " [================================================================>]  Step: 33ms | Tot: 13s900ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s70ms | Loss: 0.198 | Acc: 94.890% (9489/10000) 100/100 \n",
            "\n",
            "Epoch: 191\n",
            " [================================================================>]  Step: 24ms | Tot: 13s481ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 13ms | Tot: 2s256ms | Loss: 0.197 | Acc: 94.940% (9494/10000) 100/100 \n",
            "\n",
            "Epoch: 192\n",
            " [================================================================>]  Step: 25ms | Tot: 13s983ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s79ms | Loss: 0.199 | Acc: 94.880% (9488/10000) 100/100 \n",
            "\n",
            "Epoch: 193\n",
            " [================================================================>]  Step: 23ms | Tot: 13s613ms | Loss: 0.002 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 12ms | Tot: 2s125ms | Loss: 0.198 | Acc: 94.890% (9489/10000) 100/100 \n",
            "\n",
            "Epoch: 194\n",
            " [================================================================>]  Step: 28ms | Tot: 13s488ms | Loss: 0.002 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 14ms | Tot: 2s134ms | Loss: 0.197 | Acc: 94.880% (9488/10000) 100/100 \n",
            "\n",
            "Epoch: 195\n",
            " [================================================================>]  Step: 31ms | Tot: 14s151ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s105ms | Loss: 0.199 | Acc: 94.960% (9496/10000) 100/100 \n",
            "\n",
            "Epoch: 196\n",
            " [================================================================>]  Step: 33ms | Tot: 13s568ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s68ms | Loss: 0.198 | Acc: 94.830% (9483/10000) 100/100 \n",
            "\n",
            "Epoch: 197\n",
            " [================================================================>]  Step: 35ms | Tot: 13s838ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 11ms | Tot: 2s255ms | Loss: 0.198 | Acc: 94.870% (9487/10000) 100/100 \n",
            "\n",
            "Epoch: 198\n",
            " [================================================================>]  Step: 24ms | Tot: 13s885ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s114ms | Loss: 0.197 | Acc: 94.920% (9492/10000) 100/100 \n",
            "\n",
            "Epoch: 199\n",
            " [================================================================>]  Step: 27ms | Tot: 13s775ms | Loss: 0.002 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s139ms | Loss: 0.199 | Acc: 94.920% (9492/10000) 100/100 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## resume training"
      ],
      "metadata": {
        "id": "DNc518fwgBB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load checkpoint.\n",
        "resume = True\n",
        "if resume:\n",
        "  print('==> Resuming from checkpoint..')\n",
        "  assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "  # checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "  checkpoint = torch.load(model_save_path)\n",
        "  net.load_state_dict(checkpoint['net'])\n",
        "  best_acc = checkpoint['acc']\n",
        "  start_epoch = checkpoint['epoch']\n",
        "print(\"best_epoch: \" ,start_epoch)\n",
        "print(\"best_acc: \",best_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIHDi8FPrjKk",
        "outputId": "53e37341-bcfa-4e23-f5a1-51fbf14d7b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Resuming from checkpoint..\n",
            "best_epoch:  214\n",
            "best_acc:  95.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 200\n",
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J8qrDQShgEn2",
        "outputId": "c43bda65-ad01-4a39-8ec2-3daaad2237e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 200\n",
            " [================================================================>]  Step: 30ms | Tot: 13s926ms | Loss: 0.002 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s143ms | Loss: 0.197 | Acc: 94.940% (9494/10000) 100/100 \n",
            "\n",
            "Epoch: 201\n",
            " [================================================================>]  Step: 26ms | Tot: 13s827ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s73ms | Loss: 0.199 | Acc: 94.860% (9486/10000) 100/100 \n",
            "\n",
            "Epoch: 202\n",
            " [================================================================>]  Step: 29ms | Tot: 13s731ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s76ms | Loss: 0.199 | Acc: 94.880% (9488/10000) 100/100 \n",
            "\n",
            "Epoch: 203\n",
            " [================================================================>]  Step: 26ms | Tot: 13s676ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s139ms | Loss: 0.197 | Acc: 94.920% (9492/10000) 100/100 \n",
            "\n",
            "Epoch: 204\n",
            " [================================================================>]  Step: 27ms | Tot: 13s748ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s105ms | Loss: 0.198 | Acc: 94.880% (9488/10000) 100/100 \n",
            "\n",
            "Epoch: 205\n",
            " [================================================================>]  Step: 30ms | Tot: 13s889ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s99ms | Loss: 0.199 | Acc: 94.900% (9490/10000) 100/100 \n",
            "\n",
            "Epoch: 206\n",
            " [================================================================>]  Step: 22ms | Tot: 14s37ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s23ms | Loss: 0.200 | Acc: 94.840% (9484/10000) 100/100 \n",
            "\n",
            "Epoch: 207\n",
            " [================================================================>]  Step: 36ms | Tot: 13s784ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s38ms | Loss: 0.198 | Acc: 94.870% (9487/10000) 100/100 \n",
            "\n",
            "Epoch: 208\n",
            " [================================================================>]  Step: 29ms | Tot: 14s88ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s81ms | Loss: 0.197 | Acc: 94.920% (9492/10000) 100/100 \n",
            "\n",
            "Epoch: 209\n",
            " [================================================================>]  Step: 21ms | Tot: 13s843ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 1s971ms | Loss: 0.196 | Acc: 94.880% (9488/10000) 100/100 \n",
            "\n",
            "Epoch: 210\n",
            " [================================================================>]  Step: 28ms | Tot: 14s2ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s21ms | Loss: 0.197 | Acc: 94.980% (9498/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 211\n",
            " [================================================================>]  Step: 28ms | Tot: 13s797ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 12ms | Tot: 2s138ms | Loss: 0.197 | Acc: 95.010% (9501/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 212\n",
            " [================================================================>]  Step: 37ms | Tot: 13s698ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s8ms | Loss: 0.196 | Acc: 94.890% (9489/10000) 100/100 \n",
            "\n",
            "Epoch: 213\n",
            " [================================================================>]  Step: 28ms | Tot: 13s771ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s154ms | Loss: 0.197 | Acc: 94.910% (9491/10000) 100/100 \n",
            "\n",
            "Epoch: 214\n",
            " [================================================================>]  Step: 32ms | Tot: 13s862ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s138ms | Loss: 0.199 | Acc: 95.030% (9503/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 215\n",
            " [================================================================>]  Step: 30ms | Tot: 13s814ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 2s30ms | Loss: 0.196 | Acc: 94.940% (9494/10000) 100/100 \n",
            "\n",
            "Epoch: 216\n",
            " [================================================================>]  Step: 26ms | Tot: 13s738ms | Loss: 0.002 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s61ms | Loss: 0.194 | Acc: 95.000% (9500/10000) 100/100 \n",
            "\n",
            "Epoch: 217\n",
            " [================================================================>]  Step: 29ms | Tot: 13s753ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s194ms | Loss: 0.198 | Acc: 94.920% (9492/10000) 100/100 \n",
            "\n",
            "Epoch: 218\n",
            " [================================================================>]  Step: 27ms | Tot: 13s898ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s65ms | Loss: 0.198 | Acc: 94.940% (9494/10000) 100/100 \n",
            "\n",
            "Epoch: 219\n",
            " [================================================================>]  Step: 30ms | Tot: 13s992ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 1s978ms | Loss: 0.200 | Acc: 94.840% (9484/10000) 100/100 \n",
            "\n",
            "Epoch: 220\n",
            " [================================================================>]  Step: 22ms | Tot: 13s660ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s197ms | Loss: 0.196 | Acc: 94.940% (9494/10000) 100/100 \n",
            "\n",
            "Epoch: 221\n",
            " [================================================================>]  Step: 28ms | Tot: 13s715ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s254ms | Loss: 0.196 | Acc: 94.970% (9497/10000) 100/100 \n",
            "\n",
            "Epoch: 222\n",
            " [================================================================>]  Step: 29ms | Tot: 13s621ms | Loss: 0.002 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s271ms | Loss: 0.193 | Acc: 94.980% (9498/10000) 100/100 \n",
            "\n",
            "Epoch: 223\n",
            " [================================================================>]  Step: 31ms | Tot: 13s894ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s97ms | Loss: 0.196 | Acc: 94.920% (9492/10000) 100/100 \n",
            "\n",
            "Epoch: 224\n",
            " [================================================================>]  Step: 29ms | Tot: 13s966ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s161ms | Loss: 0.195 | Acc: 94.940% (9494/10000) 100/100 \n",
            "\n",
            "Epoch: 225\n",
            " [================================================================>]  Step: 29ms | Tot: 13s755ms | Loss: 0.002 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s20ms | Loss: 0.200 | Acc: 94.790% (9479/10000) 100/100 \n",
            "\n",
            "Epoch: 226\n",
            " [================================================================>]  Step: 29ms | Tot: 14s17ms | Loss: 0.002 | Acc: 99.980% (49990/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s68ms | Loss: 0.206 | Acc: 94.780% (9478/10000) 100/100 \n",
            "\n",
            "Epoch: 227\n",
            " [================================================================>]  Step: 26ms | Tot: 13s864ms | Loss: 0.002 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s264ms | Loss: 0.204 | Acc: 94.620% (9462/10000) 100/100 \n",
            "\n",
            "Epoch: 228\n",
            " [================================================================>]  Step: 29ms | Tot: 13s571ms | Loss: 0.002 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 1s999ms | Loss: 0.203 | Acc: 94.830% (9483/10000) 100/100 \n",
            "\n",
            "Epoch: 229\n",
            " [================================================================>]  Step: 30ms | Tot: 13s690ms | Loss: 0.003 | Acc: 99.974% (49987/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s40ms | Loss: 0.208 | Acc: 94.590% (9459/10000) 100/100 \n",
            "\n",
            "Epoch: 230\n",
            " [================================================================>]  Step: 29ms | Tot: 13s925ms | Loss: 0.004 | Acc: 99.938% (49969/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s42ms | Loss: 0.243 | Acc: 94.020% (9402/10000) 100/100 \n",
            "\n",
            "Epoch: 231\n",
            " [================================================================>]  Step: 22ms | Tot: 14s135ms | Loss: 0.014 | Acc: 99.666% (49833/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s70ms | Loss: 0.261 | Acc: 93.100% (9310/10000) 100/100 \n",
            "\n",
            "Epoch: 232\n",
            " [================================================================>]  Step: 20ms | Tot: 14s361ms | Loss: 0.036 | Acc: 98.906% (49453/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s86ms | Loss: 0.296 | Acc: 92.090% (9209/10000) 100/100 \n",
            "\n",
            "Epoch: 233\n",
            " [================================================================>]  Step: 31ms | Tot: 13s584ms | Loss: 0.042 | Acc: 98.754% (49377/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s69ms | Loss: 0.246 | Acc: 93.270% (9327/10000) 100/100 \n",
            "\n",
            "Epoch: 234\n",
            " [================================================================>]  Step: 30ms | Tot: 13s568ms | Loss: 0.054 | Acc: 98.342% (49171/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s77ms | Loss: 0.295 | Acc: 91.950% (9195/10000) 100/100 \n",
            "\n",
            "Epoch: 235\n",
            " [================================================================>]  Step: 28ms | Tot: 14s72ms | Loss: 0.054 | Acc: 98.386% (49193/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s44ms | Loss: 0.314 | Acc: 91.320% (9132/10000) 100/100 \n",
            "\n",
            "Epoch: 236\n",
            " [================================================================>]  Step: 32ms | Tot: 13s730ms | Loss: 0.063 | Acc: 98.000% (49000/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s125ms | Loss: 0.326 | Acc: 90.620% (9062/10000) 100/100 \n",
            "\n",
            "Epoch: 237\n",
            " [================================================================>]  Step: 27ms | Tot: 14s106ms | Loss: 0.068 | Acc: 97.800% (48900/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s52ms | Loss: 0.311 | Acc: 91.250% (9125/10000) 100/100 \n",
            "\n",
            "Epoch: 238\n",
            " [================================================================>]  Step: 31ms | Tot: 13s838ms | Loss: 0.062 | Acc: 97.996% (48998/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s1ms | Loss: 0.327 | Acc: 91.320% (9132/10000) 100/100 \n",
            "\n",
            "Epoch: 239\n",
            " [================================================================>]  Step: 30ms | Tot: 13s819ms | Loss: 0.067 | Acc: 97.876% (48938/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s136ms | Loss: 0.298 | Acc: 91.460% (9146/10000) 100/100 \n",
            "\n",
            "Epoch: 240\n",
            " [================================================================>]  Step: 38ms | Tot: 13s740ms | Loss: 0.071 | Acc: 97.664% (48832/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s308ms | Loss: 0.316 | Acc: 90.850% (9085/10000) 100/100 \n",
            "\n",
            "Epoch: 241\n",
            " [================================================================>]  Step: 35ms | Tot: 14s65ms | Loss: 0.071 | Acc: 97.694% (48847/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s85ms | Loss: 0.308 | Acc: 91.580% (9158/10000) 100/100 \n",
            "\n",
            "Epoch: 242\n",
            " [================================================================>]  Step: 23ms | Tot: 13s631ms | Loss: 0.074 | Acc: 97.594% (48797/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s81ms | Loss: 0.325 | Acc: 91.070% (9107/10000) 100/100 \n",
            "\n",
            "Epoch: 243\n",
            " [================================================================>]  Step: 29ms | Tot: 13s898ms | Loss: 0.074 | Acc: 97.512% (48756/50000) 391/391 \n",
            " [================================================================>]  Step: 10ms | Tot: 2s112ms | Loss: 0.345 | Acc: 90.180% (9018/10000) 100/100 \n",
            "\n",
            "Epoch: 244\n",
            " [================================================================>]  Step: 27ms | Tot: 13s557ms | Loss: 0.077 | Acc: 97.466% (48733/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s202ms | Loss: 0.295 | Acc: 91.830% (9183/10000) 100/100 \n",
            "\n",
            "Epoch: 245\n",
            " [================================================================>]  Step: 26ms | Tot: 13s813ms | Loss: 0.074 | Acc: 97.624% (48812/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s173ms | Loss: 0.328 | Acc: 91.160% (9116/10000) 100/100 \n",
            "\n",
            "Epoch: 246\n",
            " [================================================================>]  Step: 28ms | Tot: 13s870ms | Loss: 0.072 | Acc: 97.624% (48812/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s114ms | Loss: 0.329 | Acc: 90.700% (9070/10000) 100/100 \n",
            "\n",
            "Epoch: 247\n",
            " [==========>.................................................."
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-7926cd9091af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-3745ca9cdbbe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n\u001b[0;32m---> 22\u001b[0;31m                      % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-5394b09f95f6>\u001b[0m in \u001b[0;36mprogress_bar\u001b[0;34m(current, total, msg)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m']'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saqk2jBnIX-w",
        "outputId": "92faf0d3-a14e-4540-f060-ebdc231d01b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}