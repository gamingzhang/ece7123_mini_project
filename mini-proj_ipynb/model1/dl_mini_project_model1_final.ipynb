{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp_GMIufARj9"
      },
      "source": [
        "# model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twDv2eW6ERW_"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "[2] Train CIFAR10 with PyTorch  \n",
        "https://github.com/kuangliu/pytorch-cifar\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"x_size: \", x.size())\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        # print(\"out1_size: \", out.size())\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        # print(\"out2_size: \", out.size())\n",
        "        out += self.shortcut(x)\n",
        "        # print(\"out3_size: \", out.size())\n",
        "        out = F.relu(out)\n",
        "        # print(\"out4_size: \", out.size())\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"x_size: \", x.size())\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        # print(\"out1_size: \", out.size())\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        # print(\"out2_size: \", out.size())\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        # print(\"out3_size: \", out.size())\n",
        "        out += self.shortcut(x)\n",
        "        # print(\"out4_size: \", out.size())\n",
        "        out = F.relu(out)\n",
        "        # print(\"out5_size: \", out.size())\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        # print(strides)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"x_size: \", x.size())\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        # print(\"out1_size: \", out.size())\n",
        "        out = self.layer1(out)\n",
        "        # print(\"out2_size: \", out.size())\n",
        "        out = self.layer2(out)\n",
        "        # print(\"out3_size: \", out.size())\n",
        "        out = self.layer3(out)\n",
        "        # print(\"out4_size: \", out.size())\n",
        "        out = self.layer4(out)\n",
        "        # print(\"out5_size: \", out.size())\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        # print(\"out6_size: \", out.size())\n",
        "        out = out.view(out.size(0), -1)\n",
        "        # print(\"out7_size: \", out.size())\n",
        "        out = self.linear(out)\n",
        "        # print(\"out8_size: \", out.size())\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bDWSvEpFdms"
      },
      "outputs": [],
      "source": [
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMCfLzKTFieJ"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "  net = ResNet18()\n",
        "  y = net(torch.randn(1, 3, 32, 32))\n",
        "  print(y.size())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3DmY1ktGDj0"
      },
      "outputs": [],
      "source": [
        "# from torchsummary import summary\n",
        "# model1 = ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "# # model2 = ResNet34()\n",
        "# # model3 = ResNet50()\n",
        "# # model4 = ResNet101()\n",
        "# # model5 = ResNet152()\n",
        "# y = model1(torch.randn(1, 3, 32, 32))\n",
        "# print(y.size())\n",
        "# summary(model1,(3,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPla4sMGAVSP"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCx33GwEAm5L"
      },
      "source": [
        "## utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5EICfQJAp4c"
      },
      "outputs": [],
      "source": [
        "'''Some helper functions for PyTorch, including:\n",
        "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
        "    - msr_init: net parameter initialization.\n",
        "    - progress_bar: progress bar mimic xlua.progress.\n",
        "'''\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import shutil\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "\n",
        "\n",
        "# _, term_width = os.popen('stty size', 'r').read().split()\n",
        "_, term_width = shutil.get_terminal_size()\n",
        "term_width = int(term_width)\n",
        "\n",
        "# term_width = 80\n",
        "\n",
        "TOTAL_BAR_LENGTH = 65.\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNGTpMnIAvM9"
      },
      "source": [
        "## load dataset and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myzukNr9Juoc"
      },
      "source": [
        "## libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiSCNiu8Jr21"
      },
      "outputs": [],
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--resume', '-r', action='store_true',\n",
        "                    help='resume from checkpoint')\n",
        "# args = parser.parse_args()\n",
        "args, unknown = parser.parse_known_args()\n",
        "args.resume = True\n",
        "\n",
        "# modify this if train on another platform.\n",
        "google_colab = True\n",
        "model_save_path = '/checkpoint/ckpt.pth'\n",
        "if google_colab:\n",
        "  model_save_path = \"/content/drive/MyDrive/ECE7123-deeplearning/mini-proj/checkpoint/ckpt.pth\"\n",
        "\n",
        "if not os.path.isdir('checkpoint'):\n",
        "    os.mkdir('checkpoint')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyxjzPCiLVpT"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "cb4daae353fb424c9c3c51e104fea8c2",
            "6020dd7fcdd14005ac12ca6412ea58ea",
            "efb2e1b5b74246b0b7c7d8cc1549997e",
            "82b7e452b22b4bf59380a5097e787a6b",
            "ec548b5224174a308119d6045e38f578",
            "015e13f103d74937a84fa8c3e0dfbfea",
            "34458d5ef05246228ef0a6f76900c453",
            "7c1c8e12cb8c49ac9a6317cc95108ea8",
            "81f20b2e08fe418ba95fe2a5a857da49",
            "a48d39913d2a4994b41a621b4fc88654",
            "f6fb7641424a4124b54f608140448f01"
          ]
        },
        "id": "MO36UnksLafp",
        "outputId": "80b40823-70a4-411b-fbd6-d62d6f4278b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb4daae353fb424c9c3c51e104fea8c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb0QqKuYLexY"
      },
      "source": [
        "## model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp6Uepc6Lgq8",
        "outputId": "250f7148-8807-4259-be45-18401ae28947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "# net = ResNet18()\n",
        "net = ResNet(BasicBlock, [1, 1, 1, 1])\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "args.resume = False\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    # checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    checkpoint = torch.load(model_save_path)\n",
        "    net.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2QKjWzaLiua"
      },
      "source": [
        "## training and testing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il3wtN7PLlf7"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        # torch.save(state, './checkpoint/ckpt.pth')\n",
        "        torch.save(state, model_save_path)\n",
        "        best_acc = acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeazF8cyFHqi",
        "outputId": "cfd69dcd-1831-498e-b351-ad2696df161f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [128, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2          [128, 64, 32, 32]             128\n",
            "            Conv2d-3          [128, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4          [128, 64, 32, 32]             128\n",
            "            Conv2d-5          [128, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6          [128, 64, 32, 32]             128\n",
            "        BasicBlock-7          [128, 64, 32, 32]               0\n",
            "            Conv2d-8         [128, 128, 16, 16]          73,728\n",
            "       BatchNorm2d-9         [128, 128, 16, 16]             256\n",
            "           Conv2d-10         [128, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-11         [128, 128, 16, 16]             256\n",
            "           Conv2d-12         [128, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-13         [128, 128, 16, 16]             256\n",
            "       BasicBlock-14         [128, 128, 16, 16]               0\n",
            "           Conv2d-15           [128, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-16           [128, 256, 8, 8]             512\n",
            "           Conv2d-17           [128, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-18           [128, 256, 8, 8]             512\n",
            "           Conv2d-19           [128, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-20           [128, 256, 8, 8]             512\n",
            "       BasicBlock-21           [128, 256, 8, 8]               0\n",
            "           Conv2d-22           [128, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-23           [128, 512, 4, 4]           1,024\n",
            "           Conv2d-24           [128, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-25           [128, 512, 4, 4]           1,024\n",
            "           Conv2d-26           [128, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-27           [128, 512, 4, 4]           1,024\n",
            "       BasicBlock-28           [128, 512, 4, 4]               0\n",
            "           Linear-29                  [128, 10]           5,130\n",
            "           ResNet-30                  [128, 10]               0\n",
            "================================================================\n",
            "Total params: 4,903,242\n",
            "Trainable params: 4,903,242\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.50\n",
            "Forward/backward pass size (MB): 840.02\n",
            "Params size (MB): 18.70\n",
            "Estimated Total Size (MB): 860.22\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(start_epoch)\n",
        "print(best_acc)\n",
        "from torchsummary import summary\n",
        "summary(net,(3,32,32),trainloader.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm1u05-iLoHw"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BDfk4THvAZO8",
        "outputId": "2681c21a-5c2a-40aa-9717-676ba125b881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_epoch:  0\n",
            "\n",
            "Epoch: 0\n",
            " [================================================================>]  Step: 457ms | Tot: 24s558ms | Loss: 1.587 | Acc: 41.626% (20813/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s883ms | Loss: 2.492 | Acc: 40.080% (4008/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 37ms | Tot: 24s686ms | Loss: 1.130 | Acc: 59.248% (29624/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s844ms | Loss: 1.060 | Acc: 62.620% (6262/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 40ms | Tot: 24s519ms | Loss: 0.906 | Acc: 67.578% (33789/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s850ms | Loss: 0.938 | Acc: 67.160% (6716/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [================================================================>]  Step: 41ms | Tot: 24s607ms | Loss: 0.763 | Acc: 73.260% (36630/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 3s | Loss: 1.194 | Acc: 63.290% (6329/10000) 100/100 \n",
            "\n",
            "Epoch: 4\n",
            " [================================================================>]  Step: 44ms | Tot: 24s846ms | Loss: 0.658 | Acc: 77.016% (38508/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s867ms | Loss: 0.724 | Acc: 75.760% (7576/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [================================================================>]  Step: 44ms | Tot: 24s856ms | Loss: 0.597 | Acc: 79.350% (39675/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s830ms | Loss: 0.697 | Acc: 76.280% (7628/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [================================================================>]  Step: 53ms | Tot: 25s12ms | Loss: 0.555 | Acc: 80.818% (40409/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s842ms | Loss: 0.728 | Acc: 75.640% (7564/10000) 100/100 \n",
            "\n",
            "Epoch: 7\n",
            " [================================================================>]  Step: 49ms | Tot: 24s967ms | Loss: 0.521 | Acc: 81.970% (40985/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s834ms | Loss: 0.584 | Acc: 80.220% (8022/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [================================================================>]  Step: 48ms | Tot: 25s137ms | Loss: 0.500 | Acc: 82.670% (41335/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s848ms | Loss: 0.670 | Acc: 77.460% (7746/10000) 100/100 \n",
            "\n",
            "Epoch: 9\n",
            " [================================================================>]  Step: 44ms | Tot: 25s43ms | Loss: 0.486 | Acc: 83.238% (41619/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s864ms | Loss: 0.642 | Acc: 78.970% (7897/10000) 100/100 \n",
            "\n",
            "Epoch: 10\n",
            " [================================================================>]  Step: 51ms | Tot: 25s204ms | Loss: 0.463 | Acc: 84.256% (42128/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s869ms | Loss: 0.553 | Acc: 80.890% (8089/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 11\n",
            " [================================================================>]  Step: 49ms | Tot: 25s301ms | Loss: 0.448 | Acc: 84.480% (42240/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s849ms | Loss: 0.792 | Acc: 74.920% (7492/10000) 100/100 \n",
            "\n",
            "Epoch: 12\n",
            " [================================================================>]  Step: 41ms | Tot: 25s56ms | Loss: 0.442 | Acc: 84.664% (42332/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s879ms | Loss: 0.664 | Acc: 78.310% (7831/10000) 100/100 \n",
            "\n",
            "Epoch: 13\n",
            " [================================================================>]  Step: 41ms | Tot: 25s197ms | Loss: 0.426 | Acc: 85.428% (42714/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s888ms | Loss: 0.551 | Acc: 82.080% (8208/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 14\n",
            " [================================================================>]  Step: 44ms | Tot: 25s149ms | Loss: 0.424 | Acc: 85.384% (42692/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s878ms | Loss: 0.588 | Acc: 80.360% (8036/10000) 100/100 \n",
            "\n",
            "Epoch: 15\n",
            " [================================================================>]  Step: 51ms | Tot: 25s353ms | Loss: 0.411 | Acc: 85.866% (42933/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s879ms | Loss: 0.530 | Acc: 82.540% (8254/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            " [================================================================>]  Step: 40ms | Tot: 25s96ms | Loss: 0.408 | Acc: 85.994% (42997/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s815ms | Loss: 0.562 | Acc: 80.960% (8096/10000) 100/100 \n",
            "\n",
            "Epoch: 17\n",
            " [================================================================>]  Step: 47ms | Tot: 25s184ms | Loss: 0.400 | Acc: 86.244% (43122/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s884ms | Loss: 0.502 | Acc: 83.000% (8300/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [================================================================>]  Step: 48ms | Tot: 25s332ms | Loss: 0.391 | Acc: 86.632% (43316/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s824ms | Loss: 0.540 | Acc: 81.890% (8189/10000) 100/100 \n",
            "\n",
            "Epoch: 19\n",
            " [================================================================>]  Step: 47ms | Tot: 25s291ms | Loss: 0.390 | Acc: 86.714% (43357/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s836ms | Loss: 0.526 | Acc: 82.180% (8218/10000) 100/100 \n",
            "\n",
            "Epoch: 20\n",
            " [================================================================>]  Step: 58ms | Tot: 25s284ms | Loss: 0.389 | Acc: 86.564% (43282/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s881ms | Loss: 0.454 | Acc: 84.610% (8461/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 21\n",
            " [================================================================>]  Step: 47ms | Tot: 25s210ms | Loss: 0.387 | Acc: 86.684% (43342/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s900ms | Loss: 0.536 | Acc: 81.770% (8177/10000) 100/100 \n",
            "\n",
            "Epoch: 22\n",
            " [================================================================>]  Step: 49ms | Tot: 25s266ms | Loss: 0.376 | Acc: 87.100% (43550/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s889ms | Loss: 0.705 | Acc: 78.420% (7842/10000) 100/100 \n",
            "\n",
            "Epoch: 23\n",
            " [================================================================>]  Step: 49ms | Tot: 25s120ms | Loss: 0.373 | Acc: 87.338% (43669/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s843ms | Loss: 0.554 | Acc: 82.230% (8223/10000) 100/100 \n",
            "\n",
            "Epoch: 24\n",
            " [================================================================>]  Step: 47ms | Tot: 25s175ms | Loss: 0.371 | Acc: 87.332% (43666/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 3s63ms | Loss: 0.545 | Acc: 82.180% (8218/10000) 100/100 \n",
            "\n",
            "Epoch: 25\n",
            " [================================================================>]  Step: 40ms | Tot: 25s224ms | Loss: 0.371 | Acc: 87.164% (43582/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s844ms | Loss: 0.626 | Acc: 80.030% (8003/10000) 100/100 \n",
            "\n",
            "Epoch: 26\n",
            " [================================================================>]  Step: 46ms | Tot: 25s170ms | Loss: 0.364 | Acc: 87.436% (43718/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s880ms | Loss: 0.612 | Acc: 80.300% (8030/10000) 100/100 \n",
            "\n",
            "Epoch: 27\n",
            " [================================================================>]  Step: 40ms | Tot: 25s285ms | Loss: 0.366 | Acc: 87.578% (43789/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s886ms | Loss: 0.563 | Acc: 81.970% (8197/10000) 100/100 \n",
            "\n",
            "Epoch: 28\n",
            " [================================================================>]  Step: 43ms | Tot: 25s91ms | Loss: 0.361 | Acc: 87.568% (43784/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s817ms | Loss: 0.482 | Acc: 84.330% (8433/10000) 100/100 \n",
            "\n",
            "Epoch: 29\n",
            " [================================================================>]  Step: 45ms | Tot: 25s247ms | Loss: 0.358 | Acc: 87.636% (43818/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s858ms | Loss: 0.595 | Acc: 81.200% (8120/10000) 100/100 \n",
            "\n",
            "Epoch: 30\n",
            " [================================================================>]  Step: 48ms | Tot: 25s213ms | Loss: 0.355 | Acc: 87.804% (43902/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s852ms | Loss: 0.450 | Acc: 84.750% (8475/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 31\n",
            " [================================================================>]  Step: 40ms | Tot: 25s251ms | Loss: 0.355 | Acc: 87.878% (43939/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s972ms | Loss: 0.609 | Acc: 80.100% (8010/10000) 100/100 \n",
            "\n",
            "Epoch: 32\n",
            " [================================================================>]  Step: 44ms | Tot: 25s256ms | Loss: 0.354 | Acc: 87.966% (43983/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s837ms | Loss: 0.716 | Acc: 78.500% (7850/10000) 100/100 \n",
            "\n",
            "Epoch: 33\n",
            " [================================================================>]  Step: 42ms | Tot: 25s86ms | Loss: 0.343 | Acc: 88.234% (44117/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s838ms | Loss: 0.579 | Acc: 81.570% (8157/10000) 100/100 \n",
            "\n",
            "Epoch: 34\n",
            " [================================================================>]  Step: 52ms | Tot: 25s237ms | Loss: 0.349 | Acc: 87.870% (43935/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s882ms | Loss: 0.610 | Acc: 80.650% (8065/10000) 100/100 \n",
            "\n",
            "Epoch: 35\n",
            " [================================================================>]  Step: 46ms | Tot: 25s137ms | Loss: 0.349 | Acc: 88.044% (44022/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s889ms | Loss: 0.425 | Acc: 85.870% (8587/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 36\n",
            " [================================================================>]  Step: 46ms | Tot: 25s399ms | Loss: 0.339 | Acc: 88.488% (44244/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s874ms | Loss: 0.573 | Acc: 81.580% (8158/10000) 100/100 \n",
            "\n",
            "Epoch: 37\n",
            " [================================================================>]  Step: 51ms | Tot: 25s90ms | Loss: 0.345 | Acc: 88.236% (44118/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s835ms | Loss: 0.483 | Acc: 84.630% (8463/10000) 100/100 \n",
            "\n",
            "Epoch: 38\n",
            " [================================================================>]  Step: 50ms | Tot: 25s264ms | Loss: 0.337 | Acc: 88.334% (44167/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s908ms | Loss: 0.422 | Acc: 86.040% (8604/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 39\n",
            " [================================================================>]  Step: 47ms | Tot: 25s164ms | Loss: 0.340 | Acc: 88.392% (44196/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s827ms | Loss: 0.492 | Acc: 83.700% (8370/10000) 100/100 \n",
            "\n",
            "Epoch: 40\n",
            " [================================================================>]  Step: 51ms | Tot: 25s247ms | Loss: 0.335 | Acc: 88.490% (44245/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s890ms | Loss: 0.446 | Acc: 85.630% (8563/10000) 100/100 \n",
            "\n",
            "Epoch: 41\n",
            " [================================================================>]  Step: 48ms | Tot: 25s282ms | Loss: 0.336 | Acc: 88.380% (44190/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s834ms | Loss: 0.492 | Acc: 84.530% (8453/10000) 100/100 \n",
            "\n",
            "Epoch: 42\n",
            " [================================================================>]  Step: 55ms | Tot: 25s232ms | Loss: 0.335 | Acc: 88.472% (44236/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s901ms | Loss: 0.503 | Acc: 83.470% (8347/10000) 100/100 \n",
            "\n",
            "Epoch: 43\n",
            " [================================================================>]  Step: 44ms | Tot: 25s396ms | Loss: 0.333 | Acc: 88.570% (44285/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s835ms | Loss: 0.469 | Acc: 84.900% (8490/10000) 100/100 \n",
            "\n",
            "Epoch: 44\n",
            " [================================================================>]  Step: 48ms | Tot: 25s193ms | Loss: 0.329 | Acc: 88.750% (44375/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s854ms | Loss: 0.516 | Acc: 83.230% (8323/10000) 100/100 \n",
            "\n",
            "Epoch: 45\n",
            " [================================================================>]  Step: 47ms | Tot: 25s372ms | Loss: 0.330 | Acc: 88.680% (44340/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s868ms | Loss: 0.367 | Acc: 87.570% (8757/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 46\n",
            " [================================================================>]  Step: 54ms | Tot: 25s193ms | Loss: 0.321 | Acc: 89.068% (44534/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s831ms | Loss: 0.709 | Acc: 77.490% (7749/10000) 100/100 \n",
            "\n",
            "Epoch: 47\n",
            " [================================================================>]  Step: 43ms | Tot: 25s166ms | Loss: 0.324 | Acc: 88.986% (44493/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s817ms | Loss: 0.495 | Acc: 84.290% (8429/10000) 100/100 \n",
            "\n",
            "Epoch: 48\n",
            " [================================================================>]  Step: 45ms | Tot: 25s256ms | Loss: 0.322 | Acc: 88.822% (44411/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s853ms | Loss: 0.409 | Acc: 86.340% (8634/10000) 100/100 \n",
            "\n",
            "Epoch: 49\n",
            " [================================================================>]  Step: 49ms | Tot: 25s217ms | Loss: 0.324 | Acc: 88.934% (44467/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 2s859ms | Loss: 0.434 | Acc: 85.520% (8552/10000) 100/100 \n",
            "\n",
            "Epoch: 50\n",
            " [================================================================>]  Step: 53ms | Tot: 25s273ms | Loss: 0.318 | Acc: 89.048% (44524/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s859ms | Loss: 0.491 | Acc: 84.370% (8437/10000) 100/100 \n",
            "\n",
            "Epoch: 51\n",
            " [================================================================>]  Step: 43ms | Tot: 25s150ms | Loss: 0.316 | Acc: 89.252% (44626/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s900ms | Loss: 0.567 | Acc: 82.470% (8247/10000) 100/100 \n",
            "\n",
            "Epoch: 52\n",
            " [================================================================>]  Step: 50ms | Tot: 25s285ms | Loss: 0.323 | Acc: 88.808% (44404/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s868ms | Loss: 0.514 | Acc: 83.150% (8315/10000) 100/100 \n",
            "\n",
            "Epoch: 53\n",
            " [================================================================>]  Step: 53ms | Tot: 25s179ms | Loss: 0.313 | Acc: 89.076% (44538/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s930ms | Loss: 0.563 | Acc: 81.520% (8152/10000) 100/100 \n",
            "\n",
            "Epoch: 54\n",
            " [================================================================>]  Step: 50ms | Tot: 25s248ms | Loss: 0.310 | Acc: 89.326% (44663/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s867ms | Loss: 0.444 | Acc: 84.600% (8460/10000) 100/100 \n",
            "\n",
            "Epoch: 55\n",
            " [================================================================>]  Step: 41ms | Tot: 25s456ms | Loss: 0.308 | Acc: 89.300% (44650/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s916ms | Loss: 0.458 | Acc: 85.090% (8509/10000) 100/100 \n",
            "\n",
            "Epoch: 56\n",
            " [================================================================>]  Step: 52ms | Tot: 25s410ms | Loss: 0.310 | Acc: 89.322% (44661/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s829ms | Loss: 0.486 | Acc: 83.920% (8392/10000) 100/100 \n",
            "\n",
            "Epoch: 57\n",
            " [================================================================>]  Step: 55ms | Tot: 25s260ms | Loss: 0.307 | Acc: 89.362% (44681/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s864ms | Loss: 0.524 | Acc: 83.290% (8329/10000) 100/100 \n",
            "\n",
            "Epoch: 58\n",
            " [================================================================>]  Step: 51ms | Tot: 25s229ms | Loss: 0.307 | Acc: 89.528% (44764/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s827ms | Loss: 0.479 | Acc: 84.310% (8431/10000) 100/100 \n",
            "\n",
            "Epoch: 59\n",
            " [================================================================>]  Step: 46ms | Tot: 25s376ms | Loss: 0.300 | Acc: 89.676% (44838/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s858ms | Loss: 0.450 | Acc: 84.920% (8492/10000) 100/100 \n",
            "\n",
            "Epoch: 60\n",
            " [================================================================>]  Step: 41ms | Tot: 25s145ms | Loss: 0.295 | Acc: 89.818% (44909/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s840ms | Loss: 0.561 | Acc: 82.880% (8288/10000) 100/100 \n",
            "\n",
            "Epoch: 61\n",
            " [================================================================>]  Step: 51ms | Tot: 25s230ms | Loss: 0.303 | Acc: 89.578% (44789/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 3s47ms | Loss: 0.539 | Acc: 83.390% (8339/10000) 100/100 \n",
            "\n",
            "Epoch: 62\n",
            " [================================================================>]  Step: 47ms | Tot: 25s144ms | Loss: 0.298 | Acc: 89.736% (44868/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s864ms | Loss: 0.685 | Acc: 79.400% (7940/10000) 100/100 \n",
            "\n",
            "Epoch: 63\n",
            " [================================================================>]  Step: 38ms | Tot: 25s130ms | Loss: 0.294 | Acc: 89.960% (44980/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s858ms | Loss: 0.490 | Acc: 84.740% (8474/10000) 100/100 \n",
            "\n",
            "Epoch: 64\n",
            " [================================================================>]  Step: 43ms | Tot: 25s307ms | Loss: 0.294 | Acc: 89.970% (44985/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s886ms | Loss: 0.435 | Acc: 85.690% (8569/10000) 100/100 \n",
            "\n",
            "Epoch: 65\n",
            " [================================================================>]  Step: 44ms | Tot: 25s140ms | Loss: 0.289 | Acc: 90.200% (45100/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s927ms | Loss: 0.464 | Acc: 84.520% (8452/10000) 100/100 \n",
            "\n",
            "Epoch: 66\n",
            " [================================================================>]  Step: 56ms | Tot: 25s294ms | Loss: 0.294 | Acc: 89.978% (44989/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s911ms | Loss: 0.428 | Acc: 86.110% (8611/10000) 100/100 \n",
            "\n",
            "Epoch: 67\n",
            " [================================================================>]  Step: 47ms | Tot: 25s212ms | Loss: 0.286 | Acc: 90.250% (45125/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 2s867ms | Loss: 0.452 | Acc: 85.700% (8570/10000) 100/100 \n",
            "\n",
            "Epoch: 68\n",
            " [================================================================>]  Step: 44ms | Tot: 25s335ms | Loss: 0.289 | Acc: 89.856% (44928/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s862ms | Loss: 0.404 | Acc: 86.670% (8667/10000) 100/100 \n",
            "\n",
            "Epoch: 69\n",
            " [================================================================>]  Step: 46ms | Tot: 25s123ms | Loss: 0.282 | Acc: 90.230% (45115/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s829ms | Loss: 0.492 | Acc: 84.310% (8431/10000) 100/100 \n",
            "\n",
            "Epoch: 70\n",
            " [================================================================>]  Step: 40ms | Tot: 25s223ms | Loss: 0.281 | Acc: 90.284% (45142/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 3s19ms | Loss: 0.559 | Acc: 82.480% (8248/10000) 100/100 \n",
            "\n",
            "Epoch: 71\n",
            " [================================================================>]  Step: 45ms | Tot: 25s245ms | Loss: 0.278 | Acc: 90.460% (45230/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s891ms | Loss: 0.388 | Acc: 87.280% (8728/10000) 100/100 \n",
            "\n",
            "Epoch: 72\n",
            " [================================================================>]  Step: 48ms | Tot: 25s232ms | Loss: 0.280 | Acc: 90.332% (45166/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s835ms | Loss: 0.511 | Acc: 84.170% (8417/10000) 100/100 \n",
            "\n",
            "Epoch: 73\n",
            " [================================================================>]  Step: 45ms | Tot: 25s250ms | Loss: 0.282 | Acc: 90.392% (45196/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s837ms | Loss: 0.462 | Acc: 85.320% (8532/10000) 100/100 \n",
            "\n",
            "Epoch: 74\n",
            " [================================================================>]  Step: 44ms | Tot: 25s193ms | Loss: 0.275 | Acc: 90.636% (45318/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s827ms | Loss: 0.422 | Acc: 86.000% (8600/10000) 100/100 \n",
            "\n",
            "Epoch: 75\n",
            " [================================================================>]  Step: 48ms | Tot: 25s411ms | Loss: 0.270 | Acc: 90.714% (45357/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s929ms | Loss: 0.448 | Acc: 85.300% (8530/10000) 100/100 \n",
            "\n",
            "Epoch: 76\n",
            " [================================================================>]  Step: 42ms | Tot: 25s243ms | Loss: 0.273 | Acc: 90.532% (45266/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s875ms | Loss: 0.589 | Acc: 81.120% (8112/10000) 100/100 \n",
            "\n",
            "Epoch: 77\n",
            " [================================================================>]  Step: 55ms | Tot: 25s325ms | Loss: 0.265 | Acc: 90.894% (45447/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 2s838ms | Loss: 0.418 | Acc: 86.870% (8687/10000) 100/100 \n",
            "\n",
            "Epoch: 78\n",
            " [================================================================>]  Step: 42ms | Tot: 25s102ms | Loss: 0.265 | Acc: 90.868% (45434/50000) 391/391 \n",
            " [================================================================>]  Step: 15ms | Tot: 2s855ms | Loss: 0.464 | Acc: 85.260% (8526/10000) 100/100 \n",
            "\n",
            "Epoch: 79\n",
            " [================================================================>]  Step: 42ms | Tot: 25s191ms | Loss: 0.264 | Acc: 90.906% (45453/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 2s867ms | Loss: 0.444 | Acc: 85.580% (8558/10000) 100/100 \n",
            "\n",
            "Epoch: 80\n",
            " [================================================================>]  Step: 43ms | Tot: 25s279ms | Loss: 0.266 | Acc: 90.810% (45405/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s916ms | Loss: 0.392 | Acc: 87.110% (8711/10000) 100/100 \n",
            "\n",
            "Epoch: 81\n",
            " [================================================================>]  Step: 44ms | Tot: 25s165ms | Loss: 0.257 | Acc: 91.048% (45524/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s862ms | Loss: 0.399 | Acc: 86.820% (8682/10000) 100/100 \n",
            "\n",
            "Epoch: 82\n",
            " [================================================================>]  Step: 48ms | Tot: 25s348ms | Loss: 0.256 | Acc: 91.206% (45603/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s861ms | Loss: 0.514 | Acc: 84.240% (8424/10000) 100/100 \n",
            "\n",
            "Epoch: 83\n",
            " [================================================================>]  Step: 41ms | Tot: 25s196ms | Loss: 0.251 | Acc: 91.380% (45690/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s821ms | Loss: 0.465 | Acc: 84.860% (8486/10000) 100/100 \n",
            "\n",
            "Epoch: 84\n",
            " [================================================================>]  Step: 39ms | Tot: 25s343ms | Loss: 0.255 | Acc: 91.324% (45662/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s902ms | Loss: 0.395 | Acc: 87.410% (8741/10000) 100/100 \n",
            "\n",
            "Epoch: 85\n",
            " [================================================================>]  Step: 41ms | Tot: 25s257ms | Loss: 0.244 | Acc: 91.588% (45794/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 2s894ms | Loss: 0.658 | Acc: 80.840% (8084/10000) 100/100 \n",
            "\n",
            "Epoch: 86\n",
            " [================================================================>]  Step: 48ms | Tot: 25s258ms | Loss: 0.251 | Acc: 91.278% (45639/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s915ms | Loss: 0.391 | Acc: 87.450% (8745/10000) 100/100 \n",
            "\n",
            "Epoch: 87\n",
            " [================================================================>]  Step: 48ms | Tot: 25s368ms | Loss: 0.245 | Acc: 91.476% (45738/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s881ms | Loss: 0.501 | Acc: 84.020% (8402/10000) 100/100 \n",
            "\n",
            "Epoch: 88\n",
            " [================================================================>]  Step: 44ms | Tot: 25s219ms | Loss: 0.242 | Acc: 91.654% (45827/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s865ms | Loss: 0.451 | Acc: 85.740% (8574/10000) 100/100 \n",
            "\n",
            "Epoch: 89\n",
            " [================================================================>]  Step: 50ms | Tot: 25s319ms | Loss: 0.235 | Acc: 92.030% (46015/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s855ms | Loss: 0.414 | Acc: 86.730% (8673/10000) 100/100 \n",
            "\n",
            "Epoch: 90\n",
            " [================================================================>]  Step: 44ms | Tot: 25s251ms | Loss: 0.237 | Acc: 91.866% (45933/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s917ms | Loss: 0.449 | Acc: 85.510% (8551/10000) 100/100 \n",
            "\n",
            "Epoch: 91\n",
            " [================================================================>]  Step: 46ms | Tot: 25s396ms | Loss: 0.241 | Acc: 91.654% (45827/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s915ms | Loss: 0.576 | Acc: 82.590% (8259/10000) 100/100 \n",
            "\n",
            "Epoch: 92\n",
            " [================================================================>]  Step: 46ms | Tot: 25s226ms | Loss: 0.229 | Acc: 92.078% (46039/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s987ms | Loss: 0.398 | Acc: 87.060% (8706/10000) 100/100 \n",
            "\n",
            "Epoch: 93\n",
            " [================================================================>]  Step: 40ms | Tot: 25s290ms | Loss: 0.236 | Acc: 91.952% (45976/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 3s96ms | Loss: 0.402 | Acc: 86.630% (8663/10000) 100/100 \n",
            "\n",
            "Epoch: 94\n",
            " [================================================================>]  Step: 51ms | Tot: 25s245ms | Loss: 0.228 | Acc: 92.240% (46120/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s970ms | Loss: 0.418 | Acc: 86.890% (8689/10000) 100/100 \n",
            "\n",
            "Epoch: 95\n",
            " [================================================================>]  Step: 38ms | Tot: 25s197ms | Loss: 0.224 | Acc: 92.272% (46136/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s920ms | Loss: 0.436 | Acc: 86.540% (8654/10000) 100/100 \n",
            "\n",
            "Epoch: 96\n",
            " [================================================================>]  Step: 51ms | Tot: 25s338ms | Loss: 0.225 | Acc: 92.380% (46190/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s918ms | Loss: 0.429 | Acc: 86.390% (8639/10000) 100/100 \n",
            "\n",
            "Epoch: 97\n",
            " [================================================================>]  Step: 48ms | Tot: 25s319ms | Loss: 0.222 | Acc: 92.240% (46120/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s889ms | Loss: 0.406 | Acc: 86.860% (8686/10000) 100/100 \n",
            "\n",
            "Epoch: 98\n",
            " [================================================================>]  Step: 53ms | Tot: 25s346ms | Loss: 0.218 | Acc: 92.410% (46205/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s892ms | Loss: 0.437 | Acc: 86.030% (8603/10000) 100/100 \n",
            "\n",
            "Epoch: 99\n",
            " [================================================================>]  Step: 42ms | Tot: 25s283ms | Loss: 0.218 | Acc: 92.532% (46266/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s838ms | Loss: 0.350 | Acc: 88.440% (8844/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 100\n",
            " [================================================================>]  Step: 48ms | Tot: 25s408ms | Loss: 0.214 | Acc: 92.630% (46315/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 2s871ms | Loss: 0.398 | Acc: 87.370% (8737/10000) 100/100 \n",
            "\n",
            "Epoch: 101\n",
            " [================================================================>]  Step: 44ms | Tot: 25s185ms | Loss: 0.210 | Acc: 92.788% (46394/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s916ms | Loss: 0.504 | Acc: 84.730% (8473/10000) 100/100 \n",
            "\n",
            "Epoch: 102\n",
            " [================================================================>]  Step: 38ms | Tot: 25s456ms | Loss: 0.207 | Acc: 92.846% (46423/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s900ms | Loss: 0.348 | Acc: 88.670% (8867/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 103\n",
            " [================================================================>]  Step: 52ms | Tot: 25s239ms | Loss: 0.211 | Acc: 92.800% (46400/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s885ms | Loss: 0.352 | Acc: 88.700% (8870/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 104\n",
            " [================================================================>]  Step: 50ms | Tot: 25s367ms | Loss: 0.207 | Acc: 92.864% (46432/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 3s22ms | Loss: 0.549 | Acc: 84.130% (8413/10000) 100/100 \n",
            "\n",
            "Epoch: 105\n",
            " [================================================================>]  Step: 45ms | Tot: 25s232ms | Loss: 0.202 | Acc: 93.084% (46542/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s890ms | Loss: 0.385 | Acc: 88.080% (8808/10000) 100/100 \n",
            "\n",
            "Epoch: 106\n",
            " [================================================================>]  Step: 39ms | Tot: 25s269ms | Loss: 0.196 | Acc: 93.284% (46642/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s862ms | Loss: 0.354 | Acc: 88.830% (8883/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 107\n",
            " [================================================================>]  Step: 48ms | Tot: 25s430ms | Loss: 0.196 | Acc: 93.224% (46612/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s862ms | Loss: 0.406 | Acc: 87.430% (8743/10000) 100/100 \n",
            "\n",
            "Epoch: 108\n",
            " [================================================================>]  Step: 51ms | Tot: 25s381ms | Loss: 0.192 | Acc: 93.478% (46739/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s880ms | Loss: 0.328 | Acc: 89.540% (8954/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 109\n",
            " [================================================================>]  Step: 39ms | Tot: 25s430ms | Loss: 0.188 | Acc: 93.436% (46718/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s880ms | Loss: 0.414 | Acc: 86.630% (8663/10000) 100/100 \n",
            "\n",
            "Epoch: 110\n",
            " [================================================================>]  Step: 46ms | Tot: 25s281ms | Loss: 0.187 | Acc: 93.594% (46797/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s852ms | Loss: 0.402 | Acc: 87.610% (8761/10000) 100/100 \n",
            "\n",
            "Epoch: 111\n",
            " [================================================================>]  Step: 45ms | Tot: 25s350ms | Loss: 0.184 | Acc: 93.698% (46849/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s948ms | Loss: 0.377 | Acc: 88.240% (8824/10000) 100/100 \n",
            "\n",
            "Epoch: 112\n",
            " [================================================================>]  Step: 43ms | Tot: 25s315ms | Loss: 0.181 | Acc: 93.790% (46895/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s866ms | Loss: 0.334 | Acc: 89.740% (8974/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 113\n",
            " [================================================================>]  Step: 53ms | Tot: 25s369ms | Loss: 0.177 | Acc: 93.954% (46977/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s860ms | Loss: 0.348 | Acc: 89.370% (8937/10000) 100/100 \n",
            "\n",
            "Epoch: 114\n",
            " [================================================================>]  Step: 43ms | Tot: 25s198ms | Loss: 0.176 | Acc: 93.816% (46908/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s871ms | Loss: 0.328 | Acc: 89.260% (8926/10000) 100/100 \n",
            "\n",
            "Epoch: 115\n",
            " [================================================================>]  Step: 54ms | Tot: 25s585ms | Loss: 0.175 | Acc: 94.012% (47006/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s855ms | Loss: 0.419 | Acc: 87.260% (8726/10000) 100/100 \n",
            "\n",
            "Epoch: 116\n",
            " [================================================================>]  Step: 39ms | Tot: 25s599ms | Loss: 0.167 | Acc: 94.348% (47174/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s916ms | Loss: 0.335 | Acc: 89.580% (8958/10000) 100/100 \n",
            "\n",
            "Epoch: 117\n",
            " [================================================================>]  Step: 46ms | Tot: 25s472ms | Loss: 0.164 | Acc: 94.284% (47142/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 3s103ms | Loss: 0.409 | Acc: 87.650% (8765/10000) 100/100 \n",
            "\n",
            "Epoch: 118\n",
            " [================================================================>]  Step: 50ms | Tot: 25s761ms | Loss: 0.164 | Acc: 94.342% (47171/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s852ms | Loss: 0.365 | Acc: 88.620% (8862/10000) 100/100 \n",
            "\n",
            "Epoch: 119\n",
            " [================================================================>]  Step: 53ms | Tot: 25s575ms | Loss: 0.161 | Acc: 94.498% (47249/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s824ms | Loss: 0.437 | Acc: 87.100% (8710/10000) 100/100 \n",
            "\n",
            "Epoch: 120\n",
            " [================================================================>]  Step: 40ms | Tot: 25s543ms | Loss: 0.160 | Acc: 94.424% (47212/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s857ms | Loss: 0.381 | Acc: 88.000% (8800/10000) 100/100 \n",
            "\n",
            "Epoch: 121\n",
            " [================================================================>]  Step: 52ms | Tot: 25s713ms | Loss: 0.155 | Acc: 94.762% (47381/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s900ms | Loss: 0.348 | Acc: 89.340% (8934/10000) 100/100 \n",
            "\n",
            "Epoch: 122\n",
            " [================================================================>]  Step: 52ms | Tot: 25s825ms | Loss: 0.149 | Acc: 94.830% (47415/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s866ms | Loss: 0.343 | Acc: 89.230% (8923/10000) 100/100 \n",
            "\n",
            "Epoch: 123\n",
            " [================================================================>]  Step: 47ms | Tot: 25s612ms | Loss: 0.148 | Acc: 94.948% (47474/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s857ms | Loss: 0.403 | Acc: 87.540% (8754/10000) 100/100 \n",
            "\n",
            "Epoch: 124\n",
            " [================================================================>]  Step: 53ms | Tot: 25s750ms | Loss: 0.148 | Acc: 94.898% (47449/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s890ms | Loss: 0.326 | Acc: 90.280% (9028/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 125\n",
            " [================================================================>]  Step: 39ms | Tot: 25s695ms | Loss: 0.146 | Acc: 95.012% (47506/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s851ms | Loss: 0.331 | Acc: 89.580% (8958/10000) 100/100 \n",
            "\n",
            "Epoch: 126\n",
            " [================================================================>]  Step: 52ms | Tot: 25s968ms | Loss: 0.135 | Acc: 95.420% (47710/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s925ms | Loss: 0.363 | Acc: 89.040% (8904/10000) 100/100 \n",
            "\n",
            "Epoch: 127\n",
            " [================================================================>]  Step: 51ms | Tot: 25s714ms | Loss: 0.130 | Acc: 95.582% (47791/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s899ms | Loss: 0.356 | Acc: 89.490% (8949/10000) 100/100 \n",
            "\n",
            "Epoch: 128\n",
            " [================================================================>]  Step: 48ms | Tot: 25s999ms | Loss: 0.132 | Acc: 95.460% (47730/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s875ms | Loss: 0.376 | Acc: 89.180% (8918/10000) 100/100 \n",
            "\n",
            "Epoch: 129\n",
            " [================================================================>]  Step: 51ms | Tot: 25s864ms | Loss: 0.129 | Acc: 95.556% (47778/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s933ms | Loss: 0.379 | Acc: 88.500% (8850/10000) 100/100 \n",
            "\n",
            "Epoch: 130\n",
            " [================================================================>]  Step: 51ms | Tot: 25s960ms | Loss: 0.126 | Acc: 95.698% (47849/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 2s956ms | Loss: 0.334 | Acc: 89.890% (8989/10000) 100/100 \n",
            "\n",
            "Epoch: 131\n",
            " [================================================================>]  Step: 54ms | Tot: 25s720ms | Loss: 0.120 | Acc: 95.886% (47943/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s968ms | Loss: 0.345 | Acc: 89.180% (8918/10000) 100/100 \n",
            "\n",
            "Epoch: 132\n",
            " [================================================================>]  Step: 48ms | Tot: 25s795ms | Loss: 0.118 | Acc: 95.854% (47927/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s839ms | Loss: 0.362 | Acc: 89.400% (8940/10000) 100/100 \n",
            "\n",
            "Epoch: 133\n",
            " [================================================================>]  Step: 45ms | Tot: 25s697ms | Loss: 0.118 | Acc: 96.008% (48004/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s893ms | Loss: 0.304 | Acc: 90.450% (9045/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 134\n",
            " [================================================================>]  Step: 52ms | Tot: 25s808ms | Loss: 0.112 | Acc: 96.210% (48105/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s863ms | Loss: 0.401 | Acc: 88.720% (8872/10000) 100/100 \n",
            "\n",
            "Epoch: 135\n",
            " [================================================================>]  Step: 45ms | Tot: 25s671ms | Loss: 0.108 | Acc: 96.284% (48142/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s925ms | Loss: 0.315 | Acc: 90.240% (9024/10000) 100/100 \n",
            "\n",
            "Epoch: 136\n",
            " [================================================================>]  Step: 40ms | Tot: 25s861ms | Loss: 0.103 | Acc: 96.394% (48197/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 3s25ms | Loss: 0.277 | Acc: 91.390% (9139/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 137\n",
            " [================================================================>]  Step: 43ms | Tot: 25s981ms | Loss: 0.098 | Acc: 96.588% (48294/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s886ms | Loss: 0.322 | Acc: 90.080% (9008/10000) 100/100 \n",
            "\n",
            "Epoch: 138\n",
            " [================================================================>]  Step: 45ms | Tot: 25s976ms | Loss: 0.100 | Acc: 96.596% (48298/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s971ms | Loss: 0.317 | Acc: 90.610% (9061/10000) 100/100 \n",
            "\n",
            "Epoch: 139\n",
            " [================================================================>]  Step: 47ms | Tot: 25s968ms | Loss: 0.097 | Acc: 96.740% (48370/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s955ms | Loss: 0.348 | Acc: 89.480% (8948/10000) 100/100 \n",
            "\n",
            "Epoch: 140\n",
            " [================================================================>]  Step: 47ms | Tot: 26s21ms | Loss: 0.093 | Acc: 96.838% (48419/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 3s8ms | Loss: 0.334 | Acc: 90.490% (9049/10000) 100/100 \n",
            "\n",
            "Epoch: 141\n",
            " [================================================================>]  Step: 45ms | Tot: 26s19ms | Loss: 0.088 | Acc: 97.056% (48528/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s932ms | Loss: 0.302 | Acc: 91.320% (9132/10000) 100/100 \n",
            "\n",
            "Epoch: 142\n",
            " [================================================================>]  Step: 49ms | Tot: 25s949ms | Loss: 0.079 | Acc: 97.404% (48702/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s956ms | Loss: 0.317 | Acc: 91.050% (9105/10000) 100/100 \n",
            "\n",
            "Epoch: 143\n",
            " [================================================================>]  Step: 50ms | Tot: 26s90ms | Loss: 0.079 | Acc: 97.380% (48690/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s905ms | Loss: 0.311 | Acc: 91.120% (9112/10000) 100/100 \n",
            "\n",
            "Epoch: 144\n",
            " [================================================================>]  Step: 46ms | Tot: 25s969ms | Loss: 0.078 | Acc: 97.316% (48658/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s922ms | Loss: 0.338 | Acc: 90.010% (9001/10000) 100/100 \n",
            "\n",
            "Epoch: 145\n",
            " [================================================================>]  Step: 59ms | Tot: 26s120ms | Loss: 0.071 | Acc: 97.690% (48845/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s944ms | Loss: 0.296 | Acc: 91.130% (9113/10000) 100/100 \n",
            "\n",
            "Epoch: 146\n",
            " [================================================================>]  Step: 48ms | Tot: 25s931ms | Loss: 0.071 | Acc: 97.650% (48825/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s908ms | Loss: 0.318 | Acc: 90.810% (9081/10000) 100/100 \n",
            "\n",
            "Epoch: 147\n",
            " [================================================================>]  Step: 38ms | Tot: 26s8ms | Loss: 0.069 | Acc: 97.738% (48869/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s922ms | Loss: 0.349 | Acc: 90.450% (9045/10000) 100/100 \n",
            "\n",
            "Epoch: 148\n",
            " [================================================================>]  Step: 42ms | Tot: 25s942ms | Loss: 0.061 | Acc: 98.052% (49026/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s893ms | Loss: 0.293 | Acc: 91.520% (9152/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 149\n",
            " [================================================================>]  Step: 56ms | Tot: 26s25ms | Loss: 0.059 | Acc: 98.044% (49022/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s927ms | Loss: 0.331 | Acc: 90.680% (9068/10000) 100/100 \n",
            "\n",
            "Epoch: 150\n",
            " [================================================================>]  Step: 46ms | Tot: 25s963ms | Loss: 0.057 | Acc: 98.140% (49070/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 3s38ms | Loss: 0.300 | Acc: 91.560% (9156/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 151\n",
            " [================================================================>]  Step: 44ms | Tot: 26s189ms | Loss: 0.053 | Acc: 98.368% (49184/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s910ms | Loss: 0.306 | Acc: 91.280% (9128/10000) 100/100 \n",
            "\n",
            "Epoch: 152\n",
            " [================================================================>]  Step: 51ms | Tot: 25s870ms | Loss: 0.050 | Acc: 98.406% (49203/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s927ms | Loss: 0.303 | Acc: 91.180% (9118/10000) 100/100 \n",
            "\n",
            "Epoch: 153\n",
            " [================================================================>]  Step: 42ms | Tot: 25s919ms | Loss: 0.042 | Acc: 98.762% (49381/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s945ms | Loss: 0.261 | Acc: 92.770% (9277/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 154\n",
            " [================================================================>]  Step: 47ms | Tot: 25s754ms | Loss: 0.042 | Acc: 98.740% (49370/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 2s885ms | Loss: 0.289 | Acc: 91.640% (9164/10000) 100/100 \n",
            "\n",
            "Epoch: 155\n",
            " [================================================================>]  Step: 43ms | Tot: 25s980ms | Loss: 0.037 | Acc: 98.946% (49473/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s903ms | Loss: 0.292 | Acc: 92.010% (9201/10000) 100/100 \n",
            "\n",
            "Epoch: 156\n",
            " [================================================================>]  Step: 47ms | Tot: 25s808ms | Loss: 0.036 | Acc: 98.900% (49450/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s990ms | Loss: 0.278 | Acc: 91.850% (9185/10000) 100/100 \n",
            "\n",
            "Epoch: 157\n",
            " [================================================================>]  Step: 44ms | Tot: 25s980ms | Loss: 0.033 | Acc: 99.038% (49519/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s897ms | Loss: 0.258 | Acc: 92.570% (9257/10000) 100/100 \n",
            "\n",
            "Epoch: 158\n",
            " [================================================================>]  Step: 49ms | Tot: 25s831ms | Loss: 0.027 | Acc: 99.262% (49631/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s929ms | Loss: 0.269 | Acc: 92.630% (9263/10000) 100/100 \n",
            "\n",
            "Epoch: 159\n",
            " [================================================================>]  Step: 52ms | Tot: 25s942ms | Loss: 0.025 | Acc: 99.282% (49641/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 3s35ms | Loss: 0.260 | Acc: 93.060% (9306/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 160\n",
            " [================================================================>]  Step: 41ms | Tot: 25s940ms | Loss: 0.019 | Acc: 99.536% (49768/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s892ms | Loss: 0.242 | Acc: 93.040% (9304/10000) 100/100 \n",
            "\n",
            "Epoch: 161\n",
            " [================================================================>]  Step: 50ms | Tot: 25s868ms | Loss: 0.018 | Acc: 99.634% (49817/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 3s64ms | Loss: 0.241 | Acc: 93.440% (9344/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 162\n",
            " [================================================================>]  Step: 48ms | Tot: 25s895ms | Loss: 0.015 | Acc: 99.724% (49862/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s921ms | Loss: 0.237 | Acc: 93.490% (9349/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 163\n",
            " [================================================================>]  Step: 56ms | Tot: 25s850ms | Loss: 0.015 | Acc: 99.640% (49820/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s979ms | Loss: 0.235 | Acc: 93.480% (9348/10000) 100/100 \n",
            "\n",
            "Epoch: 164\n",
            " [================================================================>]  Step: 46ms | Tot: 25s943ms | Loss: 0.015 | Acc: 99.682% (49841/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s880ms | Loss: 0.227 | Acc: 93.560% (9356/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 165\n",
            " [================================================================>]  Step: 43ms | Tot: 25s956ms | Loss: 0.012 | Acc: 99.768% (49884/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s905ms | Loss: 0.225 | Acc: 93.300% (9330/10000) 100/100 \n",
            "\n",
            "Epoch: 166\n",
            " [================================================================>]  Step: 46ms | Tot: 25s989ms | Loss: 0.010 | Acc: 99.854% (49927/50000) 391/391 \n",
            " [================================================================>]  Step: 37ms | Tot: 2s925ms | Loss: 0.227 | Acc: 93.700% (9370/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 167\n",
            " [================================================================>]  Step: 44ms | Tot: 26s38ms | Loss: 0.009 | Acc: 99.890% (49945/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s946ms | Loss: 0.219 | Acc: 93.880% (9388/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 168\n",
            " [================================================================>]  Step: 53ms | Tot: 26s130ms | Loss: 0.008 | Acc: 99.882% (49941/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s920ms | Loss: 0.217 | Acc: 93.910% (9391/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 169\n",
            " [================================================================>]  Step: 50ms | Tot: 26s66ms | Loss: 0.008 | Acc: 99.898% (49949/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s944ms | Loss: 0.214 | Acc: 93.800% (9380/10000) 100/100 \n",
            "\n",
            "Epoch: 170\n",
            " [================================================================>]  Step: 52ms | Tot: 26s144ms | Loss: 0.007 | Acc: 99.936% (49968/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s995ms | Loss: 0.216 | Acc: 93.960% (9396/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 171\n",
            " [================================================================>]  Step: 46ms | Tot: 26s87ms | Loss: 0.006 | Acc: 99.946% (49973/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s939ms | Loss: 0.214 | Acc: 93.920% (9392/10000) 100/100 \n",
            "\n",
            "Epoch: 172\n",
            " [================================================================>]  Step: 54ms | Tot: 26s238ms | Loss: 0.005 | Acc: 99.956% (49978/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s912ms | Loss: 0.212 | Acc: 94.070% (9407/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 173\n",
            " [================================================================>]  Step: 46ms | Tot: 26s39ms | Loss: 0.005 | Acc: 99.960% (49980/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 3s17ms | Loss: 0.214 | Acc: 94.040% (9404/10000) 100/100 \n",
            "\n",
            "Epoch: 174\n",
            " [================================================================>]  Step: 44ms | Tot: 26s164ms | Loss: 0.005 | Acc: 99.956% (49978/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s919ms | Loss: 0.210 | Acc: 93.990% (9399/10000) 100/100 \n",
            "\n",
            "Epoch: 175\n",
            " [================================================================>]  Step: 57ms | Tot: 25s916ms | Loss: 0.005 | Acc: 99.958% (49979/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s922ms | Loss: 0.210 | Acc: 94.120% (9412/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 176\n",
            " [================================================================>]  Step: 48ms | Tot: 26s39ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s972ms | Loss: 0.201 | Acc: 94.160% (9416/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 177\n",
            " [================================================================>]  Step: 49ms | Tot: 25s851ms | Loss: 0.004 | Acc: 99.984% (49992/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 3s16ms | Loss: 0.205 | Acc: 94.230% (9423/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 178\n",
            " [================================================================>]  Step: 56ms | Tot: 26s40ms | Loss: 0.004 | Acc: 99.986% (49993/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s922ms | Loss: 0.203 | Acc: 94.170% (9417/10000) 100/100 \n",
            "\n",
            "Epoch: 179\n",
            " [================================================================>]  Step: 52ms | Tot: 25s984ms | Loss: 0.004 | Acc: 99.978% (49989/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s938ms | Loss: 0.204 | Acc: 94.300% (9430/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 180\n",
            " [================================================================>]  Step: 50ms | Tot: 26s215ms | Loss: 0.004 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s951ms | Loss: 0.204 | Acc: 94.270% (9427/10000) 100/100 \n",
            "\n",
            "Epoch: 181\n",
            " [================================================================>]  Step: 49ms | Tot: 25s884ms | Loss: 0.004 | Acc: 99.972% (49986/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s916ms | Loss: 0.201 | Acc: 94.350% (9435/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 182\n",
            " [================================================================>]  Step: 52ms | Tot: 26s159ms | Loss: 0.004 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 3s16ms | Loss: 0.200 | Acc: 94.320% (9432/10000) 100/100 \n",
            "\n",
            "Epoch: 183\n",
            " [================================================================>]  Step: 58ms | Tot: 25s959ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s960ms | Loss: 0.199 | Acc: 94.240% (9424/10000) 100/100 \n",
            "\n",
            "Epoch: 184\n",
            " [================================================================>]  Step: 46ms | Tot: 26s47ms | Loss: 0.004 | Acc: 99.984% (49992/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s931ms | Loss: 0.199 | Acc: 94.210% (9421/10000) 100/100 \n",
            "\n",
            "Epoch: 185\n",
            " [================================================================>]  Step: 47ms | Tot: 25s888ms | Loss: 0.004 | Acc: 99.986% (49993/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s913ms | Loss: 0.197 | Acc: 94.330% (9433/10000) 100/100 \n",
            "\n",
            "Epoch: 186\n",
            " [================================================================>]  Step: 48ms | Tot: 26s129ms | Loss: 0.004 | Acc: 99.986% (49993/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s905ms | Loss: 0.200 | Acc: 94.230% (9423/10000) 100/100 \n",
            "\n",
            "Epoch: 187\n",
            " [================================================================>]  Step: 49ms | Tot: 25s968ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s894ms | Loss: 0.200 | Acc: 94.240% (9424/10000) 100/100 \n",
            "\n",
            "Epoch: 188\n",
            " [================================================================>]  Step: 49ms | Tot: 26s56ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s925ms | Loss: 0.202 | Acc: 94.240% (9424/10000) 100/100 \n",
            "\n",
            "Epoch: 189\n",
            " [================================================================>]  Step: 52ms | Tot: 25s924ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s905ms | Loss: 0.200 | Acc: 94.220% (9422/10000) 100/100 \n",
            "\n",
            "Epoch: 190\n",
            " [================================================================>]  Step: 44ms | Tot: 25s994ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s915ms | Loss: 0.202 | Acc: 94.240% (9424/10000) 100/100 \n",
            "\n",
            "Epoch: 191\n",
            " [================================================================>]  Step: 48ms | Tot: 25s931ms | Loss: 0.004 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s922ms | Loss: 0.199 | Acc: 94.180% (9418/10000) 100/100 \n",
            "\n",
            "Epoch: 192\n",
            " [================================================================>]  Step: 52ms | Tot: 25s992ms | Loss: 0.003 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s908ms | Loss: 0.202 | Acc: 94.270% (9427/10000) 100/100 \n",
            "\n",
            "Epoch: 193\n",
            " [================================================================>]  Step: 48ms | Tot: 26s22ms | Loss: 0.004 | Acc: 99.986% (49993/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s933ms | Loss: 0.200 | Acc: 94.260% (9426/10000) 100/100 \n",
            "\n",
            "Epoch: 194\n",
            " [================================================================>]  Step: 48ms | Tot: 26s68ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 2s908ms | Loss: 0.199 | Acc: 94.240% (9424/10000) 100/100 \n",
            "\n",
            "Epoch: 195\n",
            " [================================================================>]  Step: 52ms | Tot: 25s873ms | Loss: 0.004 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s926ms | Loss: 0.198 | Acc: 94.230% (9423/10000) 100/100 \n",
            "\n",
            "Epoch: 196\n",
            " [================================================================>]  Step: 49ms | Tot: 26s99ms | Loss: 0.004 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s891ms | Loss: 0.197 | Acc: 94.290% (9429/10000) 100/100 \n",
            "\n",
            "Epoch: 197\n",
            " [================================================================>]  Step: 41ms | Tot: 25s894ms | Loss: 0.004 | Acc: 99.988% (49994/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s901ms | Loss: 0.198 | Acc: 94.180% (9418/10000) 100/100 \n",
            "\n",
            "Epoch: 198\n",
            " [================================================================>]  Step: 50ms | Tot: 25s955ms | Loss: 0.003 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s952ms | Loss: 0.197 | Acc: 94.180% (9418/10000) 100/100 \n",
            "\n",
            "Epoch: 199\n",
            " [================================================================>]  Step: 56ms | Tot: 26s203ms | Loss: 0.004 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 3s55ms | Loss: 0.198 | Acc: 94.230% (9423/10000) 100/100 \n",
            "\n",
            "Epoch: 200\n",
            " [================================================================>]  Step: 40ms | Tot: 26s659ms | Loss: 0.003 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 3s225ms | Loss: 0.197 | Acc: 94.190% (9419/10000) 100/100 \n",
            "\n",
            "Epoch: 201\n",
            " [================================================================>]  Step: 52ms | Tot: 26s500ms | Loss: 0.003 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 3s242ms | Loss: 0.200 | Acc: 94.160% (9416/10000) 100/100 \n",
            "\n",
            "Epoch: 202\n",
            " [================================================================>]  Step: 50ms | Tot: 26s664ms | Loss: 0.003 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 3s186ms | Loss: 0.200 | Acc: 94.180% (9418/10000) 100/100 \n",
            "\n",
            "Epoch: 203\n",
            " [================================================================>]  Step: 42ms | Tot: 26s453ms | Loss: 0.004 | Acc: 99.988% (49994/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 3s284ms | Loss: 0.198 | Acc: 94.130% (9413/10000) 100/100 \n",
            "\n",
            "Epoch: 204\n",
            " [================================================================>]  Step: 56ms | Tot: 26s578ms | Loss: 0.003 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 3s240ms | Loss: 0.198 | Acc: 94.200% (9420/10000) 100/100 \n",
            "\n",
            "Epoch: 205\n",
            " [================================================================>]  Step: 56ms | Tot: 26s520ms | Loss: 0.003 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 3s232ms | Loss: 0.199 | Acc: 94.250% (9425/10000) 100/100 \n",
            "\n",
            "Epoch: 206\n",
            " [================================================================>]  Step: 48ms | Tot: 26s560ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 3s110ms | Loss: 0.197 | Acc: 94.210% (9421/10000) 100/100 \n",
            "\n",
            "Epoch: 207\n",
            " [================================================================>]  Step: 46ms | Tot: 26s666ms | Loss: 0.003 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 3s349ms | Loss: 0.199 | Acc: 94.250% (9425/10000) 100/100 \n",
            "\n",
            "Epoch: 208\n",
            " [================================================================>]  Step: 48ms | Tot: 26s976ms | Loss: 0.003 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 3s273ms | Loss: 0.196 | Acc: 94.220% (9422/10000) 100/100 \n",
            "\n",
            "Epoch: 209\n",
            " [================================================================>]  Step: 49ms | Tot: 26s473ms | Loss: 0.003 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 3s198ms | Loss: 0.196 | Acc: 94.250% (9425/10000) 100/100 \n",
            "\n",
            "Epoch: 210\n",
            " [================================================================>]  Step: 50ms | Tot: 26s690ms | Loss: 0.004 | Acc: 99.986% (49993/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 3s201ms | Loss: 0.198 | Acc: 94.170% (9417/10000) 100/100 \n",
            "\n",
            "Epoch: 211\n",
            " [================================================================>]  Step: 48ms | Tot: 26s414ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 3s243ms | Loss: 0.197 | Acc: 94.240% (9424/10000) 100/100 \n",
            "\n",
            "Epoch: 212\n",
            " [================================================================>]  Step: 52ms | Tot: 26s547ms | Loss: 0.004 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 3s119ms | Loss: 0.196 | Acc: 94.230% (9423/10000) 100/100 \n",
            "\n",
            "Epoch: 213\n",
            " [================================================================>]  Step: 54ms | Tot: 26s274ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 3s80ms | Loss: 0.196 | Acc: 94.250% (9425/10000) 100/100 \n",
            "\n",
            "Epoch: 214\n",
            " [================================================================>]  Step: 51ms | Tot: 26s244ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s960ms | Loss: 0.197 | Acc: 94.270% (9427/10000) 100/100 \n",
            "\n",
            "Epoch: 215\n",
            " [================================================================>]  Step: 58ms | Tot: 25s971ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s958ms | Loss: 0.197 | Acc: 94.230% (9423/10000) 100/100 \n",
            "\n",
            "Epoch: 216\n",
            " [================================================================>]  Step: 58ms | Tot: 26s125ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s940ms | Loss: 0.198 | Acc: 94.080% (9408/10000) 100/100 \n",
            "\n",
            "Epoch: 217\n",
            " [================================================================>]  Step: 45ms | Tot: 26s20ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 3s18ms | Loss: 0.200 | Acc: 94.110% (9411/10000) 100/100 \n",
            "\n",
            "Epoch: 218\n",
            " [================================================================>]  Step: 50ms | Tot: 26s245ms | Loss: 0.004 | Acc: 99.988% (49994/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 3s9ms | Loss: 0.200 | Acc: 94.150% (9415/10000) 100/100 \n",
            "\n",
            "Epoch: 219\n",
            " [================================================================>]  Step: 52ms | Tot: 26s57ms | Loss: 0.004 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s976ms | Loss: 0.199 | Acc: 94.220% (9422/10000) 100/100 \n",
            "\n",
            "Epoch: 220\n",
            " [================================================================>]  Step: 46ms | Tot: 26s64ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s958ms | Loss: 0.195 | Acc: 94.330% (9433/10000) 100/100 \n",
            "\n",
            "Epoch: 221\n",
            " [================================================================>]  Step: 45ms | Tot: 26s18ms | Loss: 0.004 | Acc: 99.992% (49996/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s924ms | Loss: 0.195 | Acc: 94.270% (9427/10000) 100/100 \n",
            "\n",
            "Epoch: 222\n",
            " [================================================================>]  Step: 44ms | Tot: 26s115ms | Loss: 0.004 | Acc: 99.990% (49995/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 3s1ms | Loss: 0.200 | Acc: 94.180% (9418/10000) 100/100 \n",
            "\n",
            "Epoch: 223\n",
            " [================================================================>]  Step: 50ms | Tot: 26s18ms | Loss: 0.004 | Acc: 99.996% (49998/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 3s1ms | Loss: 0.195 | Acc: 94.070% (9407/10000) 100/100 \n",
            "\n",
            "Epoch: 224\n",
            " [================================================================>]  Step: 51ms | Tot: 26s211ms | Loss: 0.004 | Acc: 99.984% (49992/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 3s11ms | Loss: 0.199 | Acc: 94.150% (9415/10000) 100/100 \n",
            "\n",
            "Epoch: 225\n",
            " [================================================================>]  Step: 48ms | Tot: 26s44ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s986ms | Loss: 0.193 | Acc: 94.310% (9431/10000) 100/100 \n",
            "\n",
            "Epoch: 226\n",
            " [================================================================>]  Step: 44ms | Tot: 26s142ms | Loss: 0.004 | Acc: 99.998% (49999/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s941ms | Loss: 0.198 | Acc: 94.110% (9411/10000) 100/100 \n",
            "\n",
            "Epoch: 227\n",
            " [================================================================>]  Step: 47ms | Tot: 26s42ms | Loss: 0.004 | Acc: 100.000% (50000/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 3s6ms | Loss: 0.193 | Acc: 94.120% (9412/10000) 100/100 \n",
            "\n",
            "Epoch: 228\n",
            " [================================================================>]  Step: 50ms | Tot: 26s151ms | Loss: 0.004 | Acc: 99.994% (49997/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s965ms | Loss: 0.197 | Acc: 94.190% (9419/10000) 100/100 \n",
            "\n",
            "Epoch: 229\n",
            " [================================================================>]  Step: 55ms | Tot: 26s166ms | Loss: 0.004 | Acc: 99.988% (49994/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 3s33ms | Loss: 0.199 | Acc: 94.070% (9407/10000) 100/100 \n",
            "\n",
            "Epoch: 230\n",
            " [================================================================>]  Step: 46ms | Tot: 26s223ms | Loss: 0.004 | Acc: 99.986% (49993/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 3s30ms | Loss: 0.204 | Acc: 94.000% (9400/10000) 100/100 \n",
            "\n",
            "Epoch: 231\n",
            " [================================================================>]  Step: 42ms | Tot: 26s110ms | Loss: 0.006 | Acc: 99.968% (49984/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s963ms | Loss: 0.197 | Acc: 94.090% (9409/10000) 100/100 \n",
            "\n",
            "Epoch: 232\n",
            " [================================================================>]  Step: 53ms | Tot: 26s183ms | Loss: 0.006 | Acc: 99.980% (49990/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s963ms | Loss: 0.200 | Acc: 94.110% (9411/10000) 100/100 \n",
            "\n",
            "Epoch: 233\n",
            " [================================================================>]  Step: 38ms | Tot: 26s | Loss: 0.007 | Acc: 99.942% (49971/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 3s9ms | Loss: 0.224 | Acc: 93.560% (9356/10000) 100/100 \n",
            "\n",
            "Epoch: 234\n",
            " [================================================================>]  Step: 48ms | Tot: 26s141ms | Loss: 0.014 | Acc: 99.780% (49890/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s987ms | Loss: 0.313 | Acc: 91.440% (9144/10000) 100/100 \n",
            "\n",
            "Epoch: 235\n",
            " [================================================================>]  Step: 45ms | Tot: 26s100ms | Loss: 0.045 | Acc: 98.734% (49367/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s961ms | Loss: 0.325 | Acc: 90.390% (9039/10000) 100/100 \n",
            "\n",
            "Epoch: 236\n",
            " [================================================================>]  Step: 43ms | Tot: 26s264ms | Loss: 0.092 | Acc: 96.960% (48480/50000) 391/391 \n",
            " [================================================================>]  Step: 37ms | Tot: 3s14ms | Loss: 0.383 | Acc: 89.380% (8938/10000) 100/100 \n",
            "\n",
            "Epoch: 237\n",
            " [================================================================>]  Step: 51ms | Tot: 26s262ms | Loss: 0.108 | Acc: 96.430% (48215/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 3s11ms | Loss: 0.308 | Acc: 90.670% (9067/10000) 100/100 \n",
            "\n",
            "Epoch: 238\n",
            " [================================================================>]  Step: 46ms | Tot: 26s279ms | Loss: 0.104 | Acc: 96.574% (48287/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 3s28ms | Loss: 0.361 | Acc: 89.740% (8974/10000) 100/100 \n",
            "\n",
            "Epoch: 239\n",
            " [================================================================>]  Step: 49ms | Tot: 26s219ms | Loss: 0.095 | Acc: 96.860% (48430/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 3s138ms | Loss: 0.335 | Acc: 90.320% (9032/10000) 100/100 \n",
            "\n",
            "Epoch: 240\n",
            " [================================================================>]  Step: 51ms | Tot: 26s299ms | Loss: 0.099 | Acc: 96.668% (48334/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 3s16ms | Loss: 0.355 | Acc: 89.730% (8973/10000) 100/100 \n",
            "\n",
            "Epoch: 241\n",
            " [================================================================>]  Step: 50ms | Tot: 26s181ms | Loss: 0.101 | Acc: 96.558% (48279/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 3s125ms | Loss: 0.351 | Acc: 90.170% (9017/10000) 100/100 \n",
            "\n",
            "Epoch: 242\n",
            " [================================================================>]  Step: 52ms | Tot: 26s285ms | Loss: 0.106 | Acc: 96.344% (48172/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 3s | Loss: 0.415 | Acc: 87.860% (8786/10000) 100/100 \n",
            "\n",
            "Epoch: 243\n",
            " [================================================================>]  Step: 49ms | Tot: 26s223ms | Loss: 0.109 | Acc: 96.356% (48178/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 3s39ms | Loss: 0.377 | Acc: 89.480% (8948/10000) 100/100 \n",
            "\n",
            "Epoch: 244\n",
            " [================================================================>]  Step: 51ms | Tot: 26s208ms | Loss: 0.105 | Acc: 96.436% (48218/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s948ms | Loss: 0.377 | Acc: 89.350% (8935/10000) 100/100 \n",
            "\n",
            "Epoch: 245\n",
            " [================================================================>]  Step: 39ms | Tot: 26s245ms | Loss: 0.095 | Acc: 96.904% (48452/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 3s17ms | Loss: 0.452 | Acc: 87.690% (8769/10000) 100/100 \n",
            "\n",
            "Epoch: 246\n",
            " [================================================================>]  Step: 50ms | Tot: 26s121ms | Loss: 0.106 | Acc: 96.422% (48211/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s948ms | Loss: 0.424 | Acc: 88.200% (8820/10000) 100/100 \n",
            "\n",
            "Epoch: 247\n",
            " [================>....................."
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-003bf8765246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3745ca9cdbbe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n\u001b[0;32m---> 22\u001b[0;31m                      % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-45d83f3c9612>\u001b[0m in \u001b[0;36mprogress_bar\u001b[0;34m(current, total, msg)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m']'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"start_epoch: \",start_epoch)\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + 400):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWPXL3OBrhU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saqk2jBnIX-w",
        "outputId": "333d7807-2843-406e-b454-721be00549c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb4daae353fb424c9c3c51e104fea8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6020dd7fcdd14005ac12ca6412ea58ea",
              "IPY_MODEL_efb2e1b5b74246b0b7c7d8cc1549997e",
              "IPY_MODEL_82b7e452b22b4bf59380a5097e787a6b"
            ],
            "layout": "IPY_MODEL_ec548b5224174a308119d6045e38f578"
          }
        },
        "6020dd7fcdd14005ac12ca6412ea58ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_015e13f103d74937a84fa8c3e0dfbfea",
            "placeholder": "​",
            "style": "IPY_MODEL_34458d5ef05246228ef0a6f76900c453",
            "value": "100%"
          }
        },
        "efb2e1b5b74246b0b7c7d8cc1549997e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c1c8e12cb8c49ac9a6317cc95108ea8",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81f20b2e08fe418ba95fe2a5a857da49",
            "value": 170498071
          }
        },
        "82b7e452b22b4bf59380a5097e787a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a48d39913d2a4994b41a621b4fc88654",
            "placeholder": "​",
            "style": "IPY_MODEL_f6fb7641424a4124b54f608140448f01",
            "value": " 170498071/170498071 [00:11&lt;00:00, 17362505.20it/s]"
          }
        },
        "ec548b5224174a308119d6045e38f578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015e13f103d74937a84fa8c3e0dfbfea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34458d5ef05246228ef0a6f76900c453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c1c8e12cb8c49ac9a6317cc95108ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81f20b2e08fe418ba95fe2a5a857da49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a48d39913d2a4994b41a621b4fc88654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6fb7641424a4124b54f608140448f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}